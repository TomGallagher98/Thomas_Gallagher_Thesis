{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,roc_auc_score,confusion_matrix,accuracy_score,f1_score,roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from IPython.display import display\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:3: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2012 = pd.read_csv(games_folder_path + '2012.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:4: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2013 = pd.read_csv(games_folder_path + '2013.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:5: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2014 = pd.read_csv(games_folder_path + '2014.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:6: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2015 = pd.read_csv(games_folder_path + '2015.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:7: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2016 = pd.read_csv(games_folder_path + '2016.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:8: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2017 = pd.read_csv(games_folder_path + '2017.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:9: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2018 = pd.read_csv(games_folder_path + '2018.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:10: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2019 = pd.read_csv(games_folder_path + '2019.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:11: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2020 = pd.read_csv(games_folder_path + '2020.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_3296\\3458396436.py:12: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2021 = pd.read_csv(games_folder_path + '2021.csv', index_col=False, parse_dates=['date'])\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "games_folder_path = \"C:/Users/Craig/Documents/Thesis/Thomas_Gallagher_Thesis/Data/AFL_Stats_sorted/Year/Games/\"\n",
    "games_2012 = pd.read_csv(games_folder_path + '2012.csv', index_col=False, parse_dates=['date'])\n",
    "games_2013 = pd.read_csv(games_folder_path + '2013.csv', index_col=False, parse_dates=['date'])\n",
    "games_2014 = pd.read_csv(games_folder_path + '2014.csv', index_col=False, parse_dates=['date'])\n",
    "games_2015 = pd.read_csv(games_folder_path + '2015.csv', index_col=False, parse_dates=['date'])\n",
    "games_2016 = pd.read_csv(games_folder_path + '2016.csv', index_col=False, parse_dates=['date'])\n",
    "games_2017 = pd.read_csv(games_folder_path + '2017.csv', index_col=False, parse_dates=['date'])\n",
    "games_2018 = pd.read_csv(games_folder_path + '2018.csv', index_col=False, parse_dates=['date'])\n",
    "games_2019 = pd.read_csv(games_folder_path + '2019.csv', index_col=False, parse_dates=['date'])\n",
    "games_2020 = pd.read_csv(games_folder_path + '2020.csv', index_col=False, parse_dates=['date'])\n",
    "games_2021 = pd.read_csv(games_folder_path + '2021.csv', index_col=False, parse_dates=['date'])\n",
    "\n",
    "\n",
    "all_games = pd.read_csv(games_folder_path + 'games_sorted.csv', index_col=False, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_2012 = games_2012['homeWin']\n",
    "y_true_2013 = games_2013['homeWin']\n",
    "y_true_2014 = games_2014['homeWin']\n",
    "y_true_2015 = games_2015['homeWin']\n",
    "y_true_2016 = games_2016['homeWin']\n",
    "y_true_2017 = games_2017['homeWin']\n",
    "y_true_2018 = games_2018['homeWin']\n",
    "y_true_2019 = games_2019['homeWin']\n",
    "y_true_2020 = games_2020['homeWin']\n",
    "y_true_2021 = games_2021['homeWin']\n",
    "y_true = all_games['homeWin']\n",
    "\n",
    "drop_values = ['gameId', 'venue', 'homeWin', 'homeTeam', 'awayTeam', 'year','date','startTime', 'attendance', 'homeTeamScore', 'awayTeamScore', 'round']\n",
    "with open(\"features.txt\") as f:\n",
    "    features = f.read().split('\\n')\n",
    "features.append('venue')\n",
    "features.append('homeTeam')\n",
    "features.append('awayTeam')\n",
    "\n",
    "def set_columns(game_list):\n",
    "    game_list = game_list[features]\n",
    "    game_list.columns = game_list.columns.astype(str)\n",
    "    return game_list\n",
    "\n",
    "games_2012 = set_columns(games_2012)\n",
    "games_2013 = set_columns(games_2013)\n",
    "games_2014 = set_columns(games_2014)\n",
    "games_2015 = set_columns(games_2015)\n",
    "games_2016 = set_columns(games_2016)\n",
    "games_2017 = set_columns(games_2017)\n",
    "games_2018 = set_columns(games_2018)\n",
    "games_2019 = set_columns(games_2019)\n",
    "games_2020 = set_columns(games_2020)\n",
    "games_2021 = set_columns(games_2021)\n",
    "\n",
    "all_games = set_columns(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Teams\n",
    "encoding = LabelEncoder()\n",
    "encoding.fit(all_games[\"homeTeam\"].values)\n",
    "\n",
    "\n",
    "def OHE_Teams(games):\n",
    "    home_teams = encoding.transform(games[\"homeTeam\"].values)\n",
    "    away_teams = encoding.transform(games[\"awayTeam\"].values)\n",
    "\n",
    "    all_teams = np.vstack([home_teams, away_teams]).T\n",
    " \n",
    "    oneHot = OneHotEncoder()\n",
    "    X_teams = oneHot.fit_transform(all_teams).todense()\n",
    "    X_teams = pd.DataFrame(X_teams)\n",
    "    games = pd.concat([games, pd.DataFrame(X_teams)],axis=1)\n",
    "    return games\n",
    "\n",
    "games_2012 = OHE_Teams(games_2012)\n",
    "games_2013 = OHE_Teams(games_2013)\n",
    "games_2014 = OHE_Teams(games_2014)\n",
    "games_2015 = OHE_Teams(games_2015)\n",
    "games_2016 = OHE_Teams(games_2016)\n",
    "games_2017 = OHE_Teams(games_2017)\n",
    "games_2018 = OHE_Teams(games_2018)\n",
    "games_2019 = OHE_Teams(games_2019)\n",
    "games_2020 = OHE_Teams(games_2020)\n",
    "games_2021 = OHE_Teams(games_2021)\n",
    "\n",
    "all_games = OHE_Teams(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Venues\n",
    "encoding = LabelEncoder()\n",
    "encoding.fit(all_games[\"venue\"].values)\n",
    "all_venues = all_games[\"venue\"].values\n",
    "\n",
    "all_venues = all_venues.reshape(-1,1)\n",
    "\n",
    "def OHE_Venues(games):\n",
    "    venues = games['venue'].values\n",
    "    # all_venues = all_venues.reshape(-1,1)\n",
    "    venues = venues.reshape(-1,1)\n",
    "    oneHot = OneHotEncoder()\n",
    "\n",
    "    oneHot.fit(all_venues)\n",
    "    X_venues = oneHot.transform(venues).toarray()\n",
    "    X_venues = pd.DataFrame(X_venues, columns=oneHot.categories_[0])\n",
    "    games = pd.concat([games, X_venues], axis=1)\n",
    "    return games\n",
    "\n",
    "games_2012 = OHE_Venues(games_2012)\n",
    "games_2013 = OHE_Venues(games_2013)\n",
    "games_2014 = OHE_Venues(games_2014)\n",
    "games_2015 = OHE_Venues(games_2015)\n",
    "games_2016 = OHE_Venues(games_2016)\n",
    "games_2017 = OHE_Venues(games_2017)\n",
    "games_2018 = OHE_Venues(games_2018)\n",
    "games_2019 = OHE_Venues(games_2019)\n",
    "games_2020 = OHE_Venues(games_2020)\n",
    "games_2021 = OHE_Venues(games_2021)\n",
    "\n",
    "all_games = OHE_Venues(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(game_list):\n",
    "    game_list = game_list.drop(['venue', 'homeTeam', 'awayTeam'],axis=1)\n",
    "    game_list.columns = game_list.columns.astype(str)\n",
    "    return game_list\n",
    "\n",
    "games_2012 = drop_columns(games_2012)\n",
    "games_2013 = drop_columns(games_2013)\n",
    "games_2014 = drop_columns(games_2014)\n",
    "games_2015 = drop_columns(games_2015)\n",
    "games_2016 = drop_columns(games_2016)\n",
    "games_2017 = drop_columns(games_2017)\n",
    "games_2018 = drop_columns(games_2018)\n",
    "games_2019 = drop_columns(games_2019)\n",
    "games_2020 = drop_columns(games_2020)\n",
    "games_2021 = drop_columns(games_2021)\n",
    "\n",
    "all_games = drop_columns(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "games_2012 = scaler.fit_transform(games_2012)\n",
    "games_2013 = scaler.fit_transform(games_2013)\n",
    "games_2014 = scaler.fit_transform(games_2014)\n",
    "games_2015 = scaler.fit_transform(games_2015)\n",
    "games_2016 = scaler.fit_transform(games_2016)\n",
    "games_2017 = scaler.fit_transform(games_2017)\n",
    "games_2018 = scaler.fit_transform(games_2018)\n",
    "games_2019 = scaler.fit_transform(games_2019)\n",
    "games_2020 = scaler.fit_transform(games_2020)\n",
    "games_2021 = scaler.fit_transform(games_2021)\n",
    "\n",
    "all_games = scaler.fit_transform(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2012 = y_true_2012[18:171]\n",
    "y_valid_2012 = y_true_2012[171:]\n",
    "\n",
    "y_train_2013 = y_true_2013[18:171]\n",
    "y_valid_2013 = y_true_2013[171:]\n",
    "\n",
    "y_train_2014 = y_true_2014[18:171]\n",
    "y_valid_2014 = y_true_2014[171:]\n",
    "\n",
    "y_train_2015 = y_true_2015[18:170]\n",
    "y_valid_2015 = y_true_2015[170:]\n",
    "\n",
    "y_train_2016 = y_true_2016[18:171]\n",
    "y_valid_2016 = y_true_2016[171:]\n",
    "\n",
    "y_train_2017 = y_true_2017[18:171]\n",
    "y_valid_2017 = y_true_2017[171:]\n",
    "\n",
    "y_train_2018 = y_true_2018[18:171]\n",
    "y_valid_2018 = y_true_2018[171:]\n",
    "\n",
    "y_train_2019 = y_true_2019[18:171]\n",
    "y_valid_2019 = y_true_2019[171:]\n",
    "\n",
    "y_train_2020 = y_true_2020[18:127]\n",
    "y_valid_2020 = y_true_2020[127:]\n",
    "\n",
    "y_train_2021 = y_true_2021[18:171]\n",
    "y_valid_2021 = y_true_2021[171:]\n",
    "\n",
    "y_train = y_true[:1447]\n",
    "y_valid = y_true[1447:1655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE Y values\n",
    "oneHot = OneHotEncoder()\n",
    "def OHE_y_values(y_val):\n",
    "    y = np.vstack([y_val]).T\n",
    "    \n",
    "    # for i in range(len(y)):\n",
    "    #     if y[i] == 1:\n",
    "    #         y[i] = 0\n",
    "\n",
    "    y_OHE = oneHot.fit_transform(y).toarray()\n",
    "\n",
    "    return y_OHE\n",
    "\n",
    "\n",
    "y_train_2012_OHE = OHE_y_values(y_train_2012)\n",
    "y_valid_2012_OHE = OHE_y_values(y_valid_2012)\n",
    "\n",
    "y_train_2013_OHE = OHE_y_values(y_train_2013)\n",
    "y_valid_2013_OHE = OHE_y_values(y_valid_2013)\n",
    "\n",
    "y_train_2014_OHE = OHE_y_values(y_train_2014)\n",
    "y_valid_2014_OHE = OHE_y_values(y_valid_2014)\n",
    "\n",
    "y_train_2015_OHE = OHE_y_values(y_train_2015)\n",
    "y_valid_2015_OHE = OHE_y_values(y_valid_2015)\n",
    "\n",
    "y_train_2016_OHE = OHE_y_values(y_train_2016)\n",
    "y_valid_2016_OHE = OHE_y_values(y_valid_2016)\n",
    "\n",
    "y_train_2017_OHE = OHE_y_values(y_train_2017)\n",
    "y_valid_2017_OHE = OHE_y_values(y_valid_2017)\n",
    "\n",
    "y_train_2018_OHE = OHE_y_values(y_train_2018)\n",
    "y_valid_2018_OHE = OHE_y_values(y_valid_2018)\n",
    "\n",
    "y_train_2019_OHE = OHE_y_values(y_train_2019)\n",
    "y_valid_2019_OHE = OHE_y_values(y_valid_2019)\n",
    "\n",
    "y_train_2020_OHE = OHE_y_values(y_train_2020)\n",
    "y_valid_2020_OHE = OHE_y_values(y_valid_2020)\n",
    "\n",
    "y_train_2021_OHE = OHE_y_values(y_train_2021)\n",
    "y_valid_2021_OHE = OHE_y_values(y_valid_2021)\n",
    "\n",
    "y_train_OHE = OHE_y_values(y_train)\n",
    "y_valid_OHE = OHE_y_values(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_window(games):\n",
    "    y = 0 #\n",
    "    p = 0 # round 0\n",
    "    # d_full = np.zeros(shape=(1980,75))\n",
    "    d_full = np.zeros(shape=(3591,75)) # (207 - 18) * 18 + (207 - 18)\n",
    "    for x in range(0,d_full.shape[0],19): # For games in each round corresponds to d_full, when a round is ended it jumps over the added games\n",
    "        y = 18 # link to previous rounds\n",
    "        if x % 171 == 0: # Games in each round * added games\n",
    "            p += 1 # move to next round when 90 index is reached\n",
    "        for i in range(18): # fills out the first 18 posistions in the window with previous games\n",
    "            d_full[x+i] = games[p+i] # at pos x add corresponding previous game\n",
    "        d_full[x+y] = games[x//19 + y] # add game in question to final position\n",
    "    \n",
    "    d_Train = d_full[:2907]\n",
    "    d_valid = d_full[2907:]\n",
    "    d_Train = np.reshape(d_Train, (153, 19,75))\n",
    "    d_valid = np.reshape(d_valid, (36, 19, 75))\n",
    "    return d_Train, d_valid\n",
    "\n",
    "x_train_2012, x_valid_2012 = set_window(games_2012)\n",
    "x_train_2013, x_valid_2013 = set_window(games_2013)\n",
    "x_train_2014, x_valid_2014 = set_window(games_2014)\n",
    "# x_train_2015, x_valid_2015 = set_window(games_2015)\n",
    "x_train_2016, x_valid_2016 = set_window(games_2016)\n",
    "x_train_2017, x_valid_2017 = set_window(games_2017)\n",
    "x_train_2018, x_valid_2018 = set_window(games_2018)\n",
    "x_train_2019, x_valid_2019 = set_window(games_2019)\n",
    "# x_train_2020, x_valid_2020 = set_window(games_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_window_2015(games):\n",
    "    y = 0\n",
    "    p = 0\n",
    "    d_full = np.zeros(shape=(3572,75))\n",
    "    for x in range(0,d_full.shape[0],19): # Goes through index for each round\n",
    "        y = 18 # link to previous round\n",
    "        if x % 171 == 0:\n",
    "            p += 1 # move to next round when 90 index is reached\n",
    "        for i in range(18): # fills out the first nine posistions in the window with previous games\n",
    "                d_full[x+i] = games[p+i] # at pos x add corresponding previous game\n",
    "            \n",
    "        d_full[x+y] = games[x//19 + y] # add game in question to final position\n",
    "        \n",
    "    d_Train = d_full[:2888]\n",
    "    d_valid = d_full[2888:]\n",
    "    d_Train = np.reshape(d_Train, (152, 19,75))\n",
    "    d_valid = np.reshape(d_valid, (36, 19, 75))\n",
    "    return d_Train, d_valid\n",
    "\n",
    "x_train_2015, x_valid_2015 = set_window_2015(games_2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_2( xTrain, yTrain, xValid , yValid):\n",
    "    random.seed(26)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM( 128 ,input_shape = (19,75), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "    model.build()   \n",
    "    model.summary()\n",
    "    model.compile( optimizer = \"rmsprop\" , loss = 'mean_squared_error' , metrics = ['accuracy', 'mse'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau( monitor = 'accuracy', factor = 0.01, patience=10, cooldown=0)\n",
    "    \n",
    "    callbacks = [ reduce_lr ]\n",
    "    model.fit( xTrain, yTrain , epochs = 50, shuffle=False, callbacks=callbacks, verbose = 2)\n",
    "\n",
    "    # train_history = model.fit( x_train_2012 , y_train_2012 , epochs = 10, validation_split = 0.1 , verbose = 1 )\n",
    "    score = model.evaluate( xValid , yValid )\n",
    "    pred = model.predict(xValid)\n",
    "    model.save(\"LSTM_w\")\n",
    "    # print( f\"Train Accuracy: {train_history.history}\" )\n",
    "    \n",
    "    print( \"Accuracy: {:0.4}\".format( score[1] ))\n",
    "    print( \"Loss:\", score[0] )\n",
    "    return score, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_26 (LSTM)              (None, 128)               104448    \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,706\n",
      "Trainable params: 104,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3477 - accuracy: 0.5033 - mse: 0.3477 - lr: 0.0010 - 3s/epoch - 647ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2612 - accuracy: 0.5033 - mse: 0.2612 - lr: 0.0010 - 184ms/epoch - 37ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2537 - accuracy: 0.4902 - mse: 0.2537 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5163 - mse: 0.2485 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5686 - mse: 0.2465 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5425 - mse: 0.2416 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.5686 - mse: 0.2406 - lr: 0.0010 - 149ms/epoch - 30ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2329 - accuracy: 0.5882 - mse: 0.2329 - lr: 0.0010 - 140ms/epoch - 28ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2284 - accuracy: 0.6013 - mse: 0.2284 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2255 - accuracy: 0.6797 - mse: 0.2255 - lr: 0.0010 - 145ms/epoch - 29ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2261 - accuracy: 0.6667 - mse: 0.2261 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2183 - accuracy: 0.6928 - mse: 0.2183 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2122 - accuracy: 0.6993 - mse: 0.2122 - lr: 0.0010 - 140ms/epoch - 28ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2118 - accuracy: 0.6993 - mse: 0.2118 - lr: 0.0010 - 140ms/epoch - 28ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2173 - accuracy: 0.6601 - mse: 0.2173 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2011 - accuracy: 0.7190 - mse: 0.2011 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2061 - accuracy: 0.7255 - mse: 0.2061 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1869 - accuracy: 0.7386 - mse: 0.1869 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1911 - accuracy: 0.7386 - mse: 0.1911 - lr: 0.0010 - 123ms/epoch - 25ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1897 - accuracy: 0.7712 - mse: 0.1897 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1913 - accuracy: 0.7320 - mse: 0.1913 - lr: 0.0010 - 139ms/epoch - 28ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1824 - accuracy: 0.7386 - mse: 0.1824 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1729 - accuracy: 0.7647 - mse: 0.1729 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1700 - accuracy: 0.7908 - mse: 0.1700 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1766 - accuracy: 0.7386 - mse: 0.1766 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1783 - accuracy: 0.7320 - mse: 0.1783 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1666 - accuracy: 0.7386 - mse: 0.1666 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1683 - accuracy: 0.7582 - mse: 0.1683 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1564 - accuracy: 0.7974 - mse: 0.1564 - lr: 0.0010 - 205ms/epoch - 41ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1580 - accuracy: 0.7516 - mse: 0.1580 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1574 - accuracy: 0.7647 - mse: 0.1574 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1572 - accuracy: 0.8105 - mse: 0.1572 - lr: 0.0010 - 126ms/epoch - 25ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1451 - accuracy: 0.8497 - mse: 0.1451 - lr: 0.0010 - 125ms/epoch - 25ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1564 - accuracy: 0.8170 - mse: 0.1564 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1614 - accuracy: 0.7712 - mse: 0.1614 - lr: 0.0010 - 127ms/epoch - 25ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1491 - accuracy: 0.7843 - mse: 0.1491 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1504 - accuracy: 0.7843 - mse: 0.1504 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1450 - accuracy: 0.8105 - mse: 0.1450 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1579 - accuracy: 0.7843 - mse: 0.1579 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1439 - accuracy: 0.8105 - mse: 0.1439 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1342 - accuracy: 0.8497 - mse: 0.1342 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1371 - accuracy: 0.8366 - mse: 0.1371 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1399 - accuracy: 0.8562 - mse: 0.1399 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1427 - accuracy: 0.8039 - mse: 0.1427 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1401 - accuracy: 0.8235 - mse: 0.1401 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1354 - accuracy: 0.8301 - mse: 0.1354 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1537 - accuracy: 0.8105 - mse: 0.1537 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1439 - accuracy: 0.8235 - mse: 0.1439 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1319 - accuracy: 0.8301 - mse: 0.1319 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1497 - accuracy: 0.8170 - mse: 0.1497 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2156 - accuracy: 0.6389 - mse: 0.2156\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6389\n",
      "Loss: 0.2156301587820053\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_27 (LSTM)              (None, 128)               104448    \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,706\n",
      "Trainable params: 104,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 4s - loss: 0.3490 - accuracy: 0.4771 - mse: 0.3490 - lr: 0.0010 - 4s/epoch - 721ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2566 - accuracy: 0.5229 - mse: 0.2566 - lr: 0.0010 - 164ms/epoch - 33ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2445 - accuracy: 0.6013 - mse: 0.2445 - lr: 0.0010 - 166ms/epoch - 33ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2375 - accuracy: 0.6078 - mse: 0.2375 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2344 - accuracy: 0.6144 - mse: 0.2344 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2293 - accuracy: 0.6275 - mse: 0.2293 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2228 - accuracy: 0.6340 - mse: 0.2228 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2214 - accuracy: 0.6405 - mse: 0.2214 - lr: 0.0010 - 139ms/epoch - 28ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2173 - accuracy: 0.6797 - mse: 0.2173 - lr: 0.0010 - 140ms/epoch - 28ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2087 - accuracy: 0.6667 - mse: 0.2087 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.1972 - accuracy: 0.7320 - mse: 0.1972 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2019 - accuracy: 0.7190 - mse: 0.2019 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2050 - accuracy: 0.6928 - mse: 0.2050 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2021 - accuracy: 0.6993 - mse: 0.2021 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.1852 - accuracy: 0.7124 - mse: 0.1852 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1977 - accuracy: 0.6928 - mse: 0.1977 - lr: 0.0010 - 144ms/epoch - 29ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1917 - accuracy: 0.6928 - mse: 0.1917 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1883 - accuracy: 0.7582 - mse: 0.1883 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1832 - accuracy: 0.6993 - mse: 0.1832 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1786 - accuracy: 0.7582 - mse: 0.1786 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1816 - accuracy: 0.7647 - mse: 0.1816 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1675 - accuracy: 0.7778 - mse: 0.1675 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1721 - accuracy: 0.7647 - mse: 0.1721 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1608 - accuracy: 0.7647 - mse: 0.1608 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1703 - accuracy: 0.7712 - mse: 0.1703 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1734 - accuracy: 0.7386 - mse: 0.1734 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1620 - accuracy: 0.8039 - mse: 0.1620 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1611 - accuracy: 0.7712 - mse: 0.1611 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1646 - accuracy: 0.7974 - mse: 0.1646 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1642 - accuracy: 0.7647 - mse: 0.1642 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1614 - accuracy: 0.7582 - mse: 0.1614 - lr: 0.0010 - 140ms/epoch - 28ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1628 - accuracy: 0.7843 - mse: 0.1628 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1494 - accuracy: 0.8105 - mse: 0.1494 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1584 - accuracy: 0.8039 - mse: 0.1584 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1633 - accuracy: 0.7712 - mse: 0.1633 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1439 - accuracy: 0.8431 - mse: 0.1439 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1630 - accuracy: 0.7516 - mse: 0.1630 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1465 - accuracy: 0.7843 - mse: 0.1465 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1541 - accuracy: 0.8170 - mse: 0.1541 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1558 - accuracy: 0.7974 - mse: 0.1558 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1572 - accuracy: 0.7778 - mse: 0.1572 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1564 - accuracy: 0.7974 - mse: 0.1564 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1449 - accuracy: 0.8301 - mse: 0.1449 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1557 - accuracy: 0.7712 - mse: 0.1557 - lr: 0.0010 - 122ms/epoch - 24ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1487 - accuracy: 0.8170 - mse: 0.1487 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1468 - accuracy: 0.7843 - mse: 0.1468 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1578 - accuracy: 0.8105 - mse: 0.1578 - lr: 1.0000e-05 - 122ms/epoch - 24ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1397 - accuracy: 0.8301 - mse: 0.1397 - lr: 1.0000e-05 - 122ms/epoch - 24ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1486 - accuracy: 0.7843 - mse: 0.1486 - lr: 1.0000e-05 - 120ms/epoch - 24ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1442 - accuracy: 0.8039 - mse: 0.1442 - lr: 1.0000e-05 - 121ms/epoch - 24ms/step\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2170 - accuracy: 0.6667 - mse: 0.2170\n",
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6667\n",
      "Loss: 0.216975137591362\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_28 (LSTM)              (None, 128)               104448    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,706\n",
      "Trainable params: 104,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3397 - accuracy: 0.5294 - mse: 0.3397 - lr: 0.0010 - 3s/epoch - 625ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5817 - mse: 0.2427 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2402 - accuracy: 0.6078 - mse: 0.2402 - lr: 0.0010 - 140ms/epoch - 28ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2335 - accuracy: 0.6536 - mse: 0.2335 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2302 - accuracy: 0.6013 - mse: 0.2302 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2219 - accuracy: 0.6797 - mse: 0.2219 - lr: 0.0010 - 139ms/epoch - 28ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2174 - accuracy: 0.6209 - mse: 0.2174 - lr: 0.0010 - 139ms/epoch - 28ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2154 - accuracy: 0.6928 - mse: 0.2154 - lr: 0.0010 - 139ms/epoch - 28ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2138 - accuracy: 0.6601 - mse: 0.2138 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2078 - accuracy: 0.6863 - mse: 0.2078 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.1925 - accuracy: 0.7255 - mse: 0.1925 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2030 - accuracy: 0.6993 - mse: 0.2030 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2006 - accuracy: 0.6993 - mse: 0.2006 - lr: 0.0010 - 242ms/epoch - 48ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.1953 - accuracy: 0.6928 - mse: 0.1953 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.1920 - accuracy: 0.6993 - mse: 0.1920 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1930 - accuracy: 0.6993 - mse: 0.1930 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1835 - accuracy: 0.7386 - mse: 0.1835 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1772 - accuracy: 0.7516 - mse: 0.1772 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1893 - accuracy: 0.7124 - mse: 0.1893 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1780 - accuracy: 0.7647 - mse: 0.1780 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1756 - accuracy: 0.6863 - mse: 0.1756 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1694 - accuracy: 0.7516 - mse: 0.1694 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1763 - accuracy: 0.7124 - mse: 0.1763 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1731 - accuracy: 0.7582 - mse: 0.1731 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1613 - accuracy: 0.7778 - mse: 0.1613 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1723 - accuracy: 0.7451 - mse: 0.1723 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1773 - accuracy: 0.7712 - mse: 0.1773 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1722 - accuracy: 0.7712 - mse: 0.1722 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1725 - accuracy: 0.7255 - mse: 0.1725 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1633 - accuracy: 0.7778 - mse: 0.1633 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1600 - accuracy: 0.7647 - mse: 0.1600 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1692 - accuracy: 0.7190 - mse: 0.1692 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1715 - accuracy: 0.7451 - mse: 0.1715 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1557 - accuracy: 0.8039 - mse: 0.1557 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1620 - accuracy: 0.7712 - mse: 0.1620 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1566 - accuracy: 0.7647 - mse: 0.1566 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1589 - accuracy: 0.7647 - mse: 0.1589 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1543 - accuracy: 0.7843 - mse: 0.1543 - lr: 0.0010 - 145ms/epoch - 29ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1524 - accuracy: 0.7908 - mse: 0.1524 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1498 - accuracy: 0.7908 - mse: 0.1498 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1547 - accuracy: 0.7843 - mse: 0.1547 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1470 - accuracy: 0.7974 - mse: 0.1470 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1512 - accuracy: 0.8301 - mse: 0.1512 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1544 - accuracy: 0.7647 - mse: 0.1544 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1536 - accuracy: 0.8039 - mse: 0.1536 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1603 - accuracy: 0.7451 - mse: 0.1603 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1527 - accuracy: 0.7712 - mse: 0.1527 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1422 - accuracy: 0.8170 - mse: 0.1422 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1517 - accuracy: 0.7843 - mse: 0.1517 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1552 - accuracy: 0.7908 - mse: 0.1552 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2136 - accuracy: 0.7500 - mse: 0.2136\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Loss: 0.2136385440826416\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_29 (LSTM)              (None, 128)               104448    \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,706\n",
      "Trainable params: 104,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3449 - accuracy: 0.4934 - mse: 0.3449 - lr: 0.0010 - 3s/epoch - 621ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2643 - accuracy: 0.4671 - mse: 0.2643 - lr: 0.0010 - 146ms/epoch - 29ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2512 - accuracy: 0.4803 - mse: 0.2512 - lr: 0.0010 - 184ms/epoch - 37ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2400 - accuracy: 0.5658 - mse: 0.2400 - lr: 0.0010 - 178ms/epoch - 36ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2397 - accuracy: 0.5724 - mse: 0.2397 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2391 - accuracy: 0.5658 - mse: 0.2391 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2309 - accuracy: 0.6513 - mse: 0.2309 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2284 - accuracy: 0.6447 - mse: 0.2284 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2266 - accuracy: 0.6118 - mse: 0.2266 - lr: 0.0010 - 178ms/epoch - 36ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2203 - accuracy: 0.6842 - mse: 0.2203 - lr: 0.0010 - 162ms/epoch - 32ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2116 - accuracy: 0.6711 - mse: 0.2116 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2082 - accuracy: 0.7039 - mse: 0.2082 - lr: 0.0010 - 140ms/epoch - 28ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2040 - accuracy: 0.7303 - mse: 0.2040 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.1932 - accuracy: 0.7500 - mse: 0.1932 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.1959 - accuracy: 0.7632 - mse: 0.1959 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1898 - accuracy: 0.7632 - mse: 0.1898 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1906 - accuracy: 0.7566 - mse: 0.1906 - lr: 0.0010 - 124ms/epoch - 25ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1814 - accuracy: 0.7763 - mse: 0.1814 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1827 - accuracy: 0.7829 - mse: 0.1827 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1758 - accuracy: 0.7697 - mse: 0.1758 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1682 - accuracy: 0.8158 - mse: 0.1682 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1827 - accuracy: 0.7632 - mse: 0.1827 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1699 - accuracy: 0.7500 - mse: 0.1699 - lr: 0.0010 - 126ms/epoch - 25ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1742 - accuracy: 0.7895 - mse: 0.1742 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1665 - accuracy: 0.7434 - mse: 0.1665 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1748 - accuracy: 0.7500 - mse: 0.1748 - lr: 0.0010 - 125ms/epoch - 25ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1746 - accuracy: 0.7171 - mse: 0.1746 - lr: 0.0010 - 126ms/epoch - 25ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1551 - accuracy: 0.8355 - mse: 0.1551 - lr: 0.0010 - 127ms/epoch - 25ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1567 - accuracy: 0.7895 - mse: 0.1567 - lr: 0.0010 - 126ms/epoch - 25ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1577 - accuracy: 0.7763 - mse: 0.1577 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1557 - accuracy: 0.8158 - mse: 0.1557 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1601 - accuracy: 0.8026 - mse: 0.1601 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1483 - accuracy: 0.8026 - mse: 0.1483 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1570 - accuracy: 0.7829 - mse: 0.1570 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1516 - accuracy: 0.8224 - mse: 0.1516 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1664 - accuracy: 0.7566 - mse: 0.1664 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1522 - accuracy: 0.8092 - mse: 0.1522 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1711 - accuracy: 0.7500 - mse: 0.1711 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1516 - accuracy: 0.8092 - mse: 0.1516 - lr: 1.0000e-05 - 134ms/epoch - 27ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1419 - accuracy: 0.8158 - mse: 0.1419 - lr: 1.0000e-05 - 128ms/epoch - 26ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1493 - accuracy: 0.7895 - mse: 0.1493 - lr: 1.0000e-05 - 129ms/epoch - 26ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1490 - accuracy: 0.8092 - mse: 0.1490 - lr: 1.0000e-05 - 132ms/epoch - 26ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1437 - accuracy: 0.7895 - mse: 0.1437 - lr: 1.0000e-05 - 133ms/epoch - 27ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1393 - accuracy: 0.8355 - mse: 0.1393 - lr: 1.0000e-05 - 131ms/epoch - 26ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1527 - accuracy: 0.7763 - mse: 0.1527 - lr: 1.0000e-05 - 129ms/epoch - 26ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1560 - accuracy: 0.8026 - mse: 0.1560 - lr: 1.0000e-05 - 129ms/epoch - 26ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1504 - accuracy: 0.7697 - mse: 0.1504 - lr: 1.0000e-05 - 132ms/epoch - 26ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1489 - accuracy: 0.8158 - mse: 0.1489 - lr: 1.0000e-05 - 131ms/epoch - 26ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1478 - accuracy: 0.8158 - mse: 0.1478 - lr: 1.0000e-07 - 129ms/epoch - 26ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1522 - accuracy: 0.8092 - mse: 0.1522 - lr: 1.0000e-07 - 165ms/epoch - 33ms/step\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2189 - accuracy: 0.6111 - mse: 0.2189\n",
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6111\n",
      "Loss: 0.21894660592079163\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 128)               104448    \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,706\n",
      "Trainable params: 104,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3523 - accuracy: 0.5033 - mse: 0.3523 - lr: 0.0010 - 3s/epoch - 626ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2403 - accuracy: 0.6013 - mse: 0.2403 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2344 - accuracy: 0.6275 - mse: 0.2344 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2315 - accuracy: 0.6340 - mse: 0.2315 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2289 - accuracy: 0.6144 - mse: 0.2289 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2166 - accuracy: 0.6471 - mse: 0.2166 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2173 - accuracy: 0.6863 - mse: 0.2173 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2151 - accuracy: 0.6536 - mse: 0.2151 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2018 - accuracy: 0.6993 - mse: 0.2018 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2024 - accuracy: 0.7059 - mse: 0.2024 - lr: 0.0010 - 127ms/epoch - 25ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.1921 - accuracy: 0.6993 - mse: 0.1921 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.1964 - accuracy: 0.7124 - mse: 0.1964 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.1962 - accuracy: 0.6863 - mse: 0.1962 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.1907 - accuracy: 0.7451 - mse: 0.1907 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.1859 - accuracy: 0.7255 - mse: 0.1859 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1824 - accuracy: 0.7712 - mse: 0.1824 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1790 - accuracy: 0.7582 - mse: 0.1790 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1736 - accuracy: 0.7712 - mse: 0.1736 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1731 - accuracy: 0.7386 - mse: 0.1731 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1770 - accuracy: 0.7516 - mse: 0.1770 - lr: 0.0010 - 126ms/epoch - 25ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1713 - accuracy: 0.7451 - mse: 0.1713 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1670 - accuracy: 0.7451 - mse: 0.1670 - lr: 0.0010 - 127ms/epoch - 25ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1629 - accuracy: 0.7386 - mse: 0.1629 - lr: 0.0010 - 127ms/epoch - 25ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1712 - accuracy: 0.7386 - mse: 0.1712 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1492 - accuracy: 0.7843 - mse: 0.1492 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1613 - accuracy: 0.7451 - mse: 0.1613 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1610 - accuracy: 0.7908 - mse: 0.1610 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1565 - accuracy: 0.8170 - mse: 0.1565 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1494 - accuracy: 0.7843 - mse: 0.1494 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1522 - accuracy: 0.8301 - mse: 0.1522 - lr: 0.0010 - 215ms/epoch - 43ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1506 - accuracy: 0.7843 - mse: 0.1506 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1581 - accuracy: 0.7712 - mse: 0.1581 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1509 - accuracy: 0.7908 - mse: 0.1509 - lr: 0.0010 - 126ms/epoch - 25ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1557 - accuracy: 0.7908 - mse: 0.1557 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1510 - accuracy: 0.7843 - mse: 0.1510 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1537 - accuracy: 0.7647 - mse: 0.1537 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1408 - accuracy: 0.8105 - mse: 0.1408 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1510 - accuracy: 0.7778 - mse: 0.1510 - lr: 0.0010 - 124ms/epoch - 25ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1546 - accuracy: 0.7582 - mse: 0.1546 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1512 - accuracy: 0.7778 - mse: 0.1512 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1444 - accuracy: 0.7974 - mse: 0.1444 - lr: 1.0000e-05 - 128ms/epoch - 26ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1359 - accuracy: 0.8366 - mse: 0.1359 - lr: 1.0000e-05 - 126ms/epoch - 25ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1423 - accuracy: 0.8105 - mse: 0.1423 - lr: 1.0000e-05 - 148ms/epoch - 30ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1328 - accuracy: 0.8105 - mse: 0.1328 - lr: 1.0000e-05 - 135ms/epoch - 27ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1425 - accuracy: 0.7908 - mse: 0.1425 - lr: 1.0000e-05 - 128ms/epoch - 26ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1448 - accuracy: 0.8105 - mse: 0.1448 - lr: 1.0000e-05 - 128ms/epoch - 26ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1508 - accuracy: 0.7974 - mse: 0.1508 - lr: 1.0000e-05 - 143ms/epoch - 29ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1461 - accuracy: 0.8039 - mse: 0.1461 - lr: 1.0000e-05 - 134ms/epoch - 27ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1368 - accuracy: 0.8366 - mse: 0.1368 - lr: 1.0000e-05 - 139ms/epoch - 28ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1335 - accuracy: 0.8105 - mse: 0.1335 - lr: 1.0000e-05 - 144ms/epoch - 29ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2332 - accuracy: 0.5556 - mse: 0.2332\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5556\n",
      "Loss: 0.23323681950569153\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_31 (LSTM)              (None, 128)               104448    \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,706\n",
      "Trainable params: 104,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3591 - accuracy: 0.4510 - mse: 0.3591 - lr: 0.0010 - 3s/epoch - 629ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2523 - accuracy: 0.5229 - mse: 0.2523 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2509 - accuracy: 0.5229 - mse: 0.2509 - lr: 0.0010 - 181ms/epoch - 36ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2450 - accuracy: 0.5556 - mse: 0.2450 - lr: 0.0010 - 184ms/epoch - 37ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5294 - mse: 0.2452 - lr: 0.0010 - 139ms/epoch - 28ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2366 - accuracy: 0.5752 - mse: 0.2366 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2391 - accuracy: 0.5490 - mse: 0.2391 - lr: 0.0010 - 139ms/epoch - 28ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2325 - accuracy: 0.5948 - mse: 0.2325 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2298 - accuracy: 0.6275 - mse: 0.2298 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2281 - accuracy: 0.6144 - mse: 0.2281 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2263 - accuracy: 0.6275 - mse: 0.2263 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2295 - accuracy: 0.5882 - mse: 0.2295 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2216 - accuracy: 0.6471 - mse: 0.2216 - lr: 0.0010 - 127ms/epoch - 25ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2203 - accuracy: 0.6078 - mse: 0.2203 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2177 - accuracy: 0.6144 - mse: 0.2177 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2156 - accuracy: 0.6601 - mse: 0.2156 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2160 - accuracy: 0.6993 - mse: 0.2160 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2082 - accuracy: 0.6471 - mse: 0.2082 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2151 - accuracy: 0.6601 - mse: 0.2151 - lr: 0.0010 - 127ms/epoch - 25ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2042 - accuracy: 0.6863 - mse: 0.2042 - lr: 0.0010 - 128ms/epoch - 26ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2052 - accuracy: 0.6797 - mse: 0.2052 - lr: 0.0010 - 126ms/epoch - 25ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2061 - accuracy: 0.6797 - mse: 0.2061 - lr: 0.0010 - 129ms/epoch - 26ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2056 - accuracy: 0.6797 - mse: 0.2056 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1990 - accuracy: 0.6797 - mse: 0.1990 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2025 - accuracy: 0.6601 - mse: 0.2025 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2017 - accuracy: 0.6275 - mse: 0.2017 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2120 - accuracy: 0.6405 - mse: 0.2120 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1992 - accuracy: 0.7059 - mse: 0.1992 - lr: 1.0000e-05 - 132ms/epoch - 26ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1968 - accuracy: 0.6863 - mse: 0.1968 - lr: 1.0000e-05 - 133ms/epoch - 27ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1969 - accuracy: 0.6797 - mse: 0.1969 - lr: 1.0000e-05 - 134ms/epoch - 27ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1911 - accuracy: 0.6797 - mse: 0.1911 - lr: 1.0000e-05 - 133ms/epoch - 27ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1924 - accuracy: 0.6993 - mse: 0.1924 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1864 - accuracy: 0.6993 - mse: 0.1864 - lr: 1.0000e-05 - 132ms/epoch - 26ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1942 - accuracy: 0.6797 - mse: 0.1942 - lr: 1.0000e-05 - 131ms/epoch - 26ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1970 - accuracy: 0.6993 - mse: 0.1970 - lr: 1.0000e-05 - 130ms/epoch - 26ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1968 - accuracy: 0.7059 - mse: 0.1968 - lr: 1.0000e-05 - 136ms/epoch - 27ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2029 - accuracy: 0.6732 - mse: 0.2029 - lr: 1.0000e-05 - 135ms/epoch - 27ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1926 - accuracy: 0.6928 - mse: 0.1926 - lr: 1.0000e-05 - 140ms/epoch - 28ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1941 - accuracy: 0.7255 - mse: 0.1941 - lr: 1.0000e-07 - 139ms/epoch - 28ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2072 - accuracy: 0.6667 - mse: 0.2072 - lr: 1.0000e-07 - 130ms/epoch - 26ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1974 - accuracy: 0.7059 - mse: 0.1974 - lr: 1.0000e-07 - 131ms/epoch - 26ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1939 - accuracy: 0.6928 - mse: 0.1939 - lr: 1.0000e-07 - 135ms/epoch - 27ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1895 - accuracy: 0.7320 - mse: 0.1895 - lr: 1.0000e-07 - 130ms/epoch - 26ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1890 - accuracy: 0.7386 - mse: 0.1890 - lr: 1.0000e-07 - 126ms/epoch - 25ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1996 - accuracy: 0.6797 - mse: 0.1996 - lr: 1.0000e-07 - 134ms/epoch - 27ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1990 - accuracy: 0.6601 - mse: 0.1990 - lr: 1.0000e-07 - 135ms/epoch - 27ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1934 - accuracy: 0.7059 - mse: 0.1934 - lr: 1.0000e-07 - 131ms/epoch - 26ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1997 - accuracy: 0.7255 - mse: 0.1997 - lr: 1.0000e-07 - 132ms/epoch - 26ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2020 - accuracy: 0.6732 - mse: 0.2020 - lr: 1.0000e-07 - 131ms/epoch - 26ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1916 - accuracy: 0.7124 - mse: 0.1916 - lr: 1.0000e-07 - 131ms/epoch - 26ms/step\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2053 - accuracy: 0.6944 - mse: 0.2053\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6944\n",
      "Loss: 0.20525223016738892\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_32 (LSTM)              (None, 128)               104448    \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,706\n",
      "Trainable params: 104,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3347 - accuracy: 0.4902 - mse: 0.3347 - lr: 0.0010 - 3s/epoch - 620ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5686 - mse: 0.2432 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2402 - accuracy: 0.6340 - mse: 0.2402 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2319 - accuracy: 0.6471 - mse: 0.2319 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2301 - accuracy: 0.6144 - mse: 0.2301 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2308 - accuracy: 0.6536 - mse: 0.2308 - lr: 0.0010 - 126ms/epoch - 25ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2294 - accuracy: 0.6471 - mse: 0.2294 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2239 - accuracy: 0.6667 - mse: 0.2239 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2158 - accuracy: 0.6601 - mse: 0.2158 - lr: 0.0010 - 123ms/epoch - 25ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2178 - accuracy: 0.6471 - mse: 0.2178 - lr: 0.0010 - 118ms/epoch - 24ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2146 - accuracy: 0.6536 - mse: 0.2146 - lr: 0.0010 - 121ms/epoch - 24ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2083 - accuracy: 0.6732 - mse: 0.2083 - lr: 0.0010 - 125ms/epoch - 25ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2103 - accuracy: 0.6928 - mse: 0.2103 - lr: 0.0010 - 124ms/epoch - 25ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.1972 - accuracy: 0.7778 - mse: 0.1972 - lr: 0.0010 - 122ms/epoch - 24ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.1985 - accuracy: 0.7320 - mse: 0.1985 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2027 - accuracy: 0.6928 - mse: 0.2027 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1961 - accuracy: 0.7386 - mse: 0.1961 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1990 - accuracy: 0.6928 - mse: 0.1990 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1902 - accuracy: 0.7255 - mse: 0.1902 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1970 - accuracy: 0.7582 - mse: 0.1970 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1878 - accuracy: 0.7386 - mse: 0.1878 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1904 - accuracy: 0.7582 - mse: 0.1904 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1707 - accuracy: 0.7712 - mse: 0.1707 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1780 - accuracy: 0.7386 - mse: 0.1780 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1816 - accuracy: 0.7712 - mse: 0.1816 - lr: 1.0000e-05 - 133ms/epoch - 27ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1801 - accuracy: 0.6993 - mse: 0.1801 - lr: 1.0000e-05 - 133ms/epoch - 27ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1803 - accuracy: 0.7778 - mse: 0.1803 - lr: 1.0000e-05 - 134ms/epoch - 27ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1844 - accuracy: 0.7124 - mse: 0.1844 - lr: 1.0000e-05 - 130ms/epoch - 26ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1737 - accuracy: 0.7451 - mse: 0.1737 - lr: 1.0000e-05 - 131ms/epoch - 26ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1760 - accuracy: 0.7908 - mse: 0.1760 - lr: 1.0000e-05 - 137ms/epoch - 27ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1783 - accuracy: 0.7516 - mse: 0.1783 - lr: 1.0000e-05 - 132ms/epoch - 26ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1716 - accuracy: 0.7778 - mse: 0.1716 - lr: 1.0000e-05 - 128ms/epoch - 26ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1818 - accuracy: 0.7647 - mse: 0.1818 - lr: 1.0000e-05 - 131ms/epoch - 26ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1696 - accuracy: 0.7712 - mse: 0.1696 - lr: 1.0000e-05 - 130ms/epoch - 26ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1760 - accuracy: 0.7320 - mse: 0.1760 - lr: 1.0000e-05 - 131ms/epoch - 26ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1664 - accuracy: 0.7778 - mse: 0.1664 - lr: 1.0000e-05 - 189ms/epoch - 38ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1716 - accuracy: 0.7712 - mse: 0.1716 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1833 - accuracy: 0.7516 - mse: 0.1833 - lr: 1.0000e-05 - 131ms/epoch - 26ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1784 - accuracy: 0.7516 - mse: 0.1784 - lr: 1.0000e-05 - 129ms/epoch - 26ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1691 - accuracy: 0.7843 - mse: 0.1691 - lr: 1.0000e-05 - 132ms/epoch - 26ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1713 - accuracy: 0.7712 - mse: 0.1713 - lr: 1.0000e-07 - 134ms/epoch - 27ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1714 - accuracy: 0.7712 - mse: 0.1714 - lr: 1.0000e-07 - 137ms/epoch - 27ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1792 - accuracy: 0.7255 - mse: 0.1792 - lr: 1.0000e-07 - 139ms/epoch - 28ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1710 - accuracy: 0.7647 - mse: 0.1710 - lr: 1.0000e-07 - 135ms/epoch - 27ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1787 - accuracy: 0.7712 - mse: 0.1787 - lr: 1.0000e-07 - 133ms/epoch - 27ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1712 - accuracy: 0.7974 - mse: 0.1712 - lr: 1.0000e-07 - 132ms/epoch - 26ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1742 - accuracy: 0.7778 - mse: 0.1742 - lr: 1.0000e-07 - 140ms/epoch - 28ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1766 - accuracy: 0.7320 - mse: 0.1766 - lr: 1.0000e-07 - 139ms/epoch - 28ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1739 - accuracy: 0.7843 - mse: 0.1739 - lr: 1.0000e-07 - 132ms/epoch - 26ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1738 - accuracy: 0.7843 - mse: 0.1738 - lr: 1.0000e-07 - 135ms/epoch - 27ms/step\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1851 - accuracy: 0.7222 - mse: 0.1851\n",
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7222\n",
      "Loss: 0.18512102961540222\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (None, 128)               104448    \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,706\n",
      "Trainable params: 104,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3309 - accuracy: 0.5686 - mse: 0.3309 - lr: 0.0010 - 3s/epoch - 627ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2623 - accuracy: 0.4706 - mse: 0.2623 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5621 - mse: 0.2471 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5882 - mse: 0.2431 - lr: 0.0010 - 133ms/epoch - 27ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5621 - mse: 0.2475 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2388 - accuracy: 0.6340 - mse: 0.2388 - lr: 0.0010 - 139ms/epoch - 28ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2382 - accuracy: 0.6013 - mse: 0.2382 - lr: 0.0010 - 136ms/epoch - 27ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2310 - accuracy: 0.6144 - mse: 0.2310 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2302 - accuracy: 0.6209 - mse: 0.2302 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2260 - accuracy: 0.6144 - mse: 0.2260 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2260 - accuracy: 0.6209 - mse: 0.2260 - lr: 0.0010 - 140ms/epoch - 28ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2152 - accuracy: 0.6863 - mse: 0.2152 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2173 - accuracy: 0.6667 - mse: 0.2173 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2141 - accuracy: 0.6536 - mse: 0.2141 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2133 - accuracy: 0.6797 - mse: 0.2133 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2187 - accuracy: 0.6340 - mse: 0.2187 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2141 - accuracy: 0.6601 - mse: 0.2141 - lr: 0.0010 - 137ms/epoch - 27ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2095 - accuracy: 0.6797 - mse: 0.2095 - lr: 0.0010 - 206ms/epoch - 41ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2069 - accuracy: 0.6601 - mse: 0.2069 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2026 - accuracy: 0.6863 - mse: 0.2026 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2092 - accuracy: 0.6797 - mse: 0.2092 - lr: 0.0010 - 126ms/epoch - 25ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2041 - accuracy: 0.6667 - mse: 0.2041 - lr: 0.0010 - 131ms/epoch - 26ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1935 - accuracy: 0.7190 - mse: 0.1935 - lr: 1.0000e-05 - 127ms/epoch - 25ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2008 - accuracy: 0.6863 - mse: 0.2008 - lr: 1.0000e-05 - 129ms/epoch - 26ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1976 - accuracy: 0.6863 - mse: 0.1976 - lr: 1.0000e-05 - 167ms/epoch - 33ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1997 - accuracy: 0.6993 - mse: 0.1997 - lr: 1.0000e-05 - 176ms/epoch - 35ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1887 - accuracy: 0.6732 - mse: 0.1887 - lr: 1.0000e-05 - 162ms/epoch - 32ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1874 - accuracy: 0.7320 - mse: 0.1874 - lr: 1.0000e-05 - 167ms/epoch - 33ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1952 - accuracy: 0.7124 - mse: 0.1952 - lr: 1.0000e-05 - 271ms/epoch - 54ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1914 - accuracy: 0.6797 - mse: 0.1914 - lr: 1.0000e-05 - 209ms/epoch - 42ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1950 - accuracy: 0.6667 - mse: 0.1950 - lr: 1.0000e-05 - 228ms/epoch - 46ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1905 - accuracy: 0.7451 - mse: 0.1905 - lr: 1.0000e-05 - 217ms/epoch - 43ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1987 - accuracy: 0.6863 - mse: 0.1987 - lr: 1.0000e-05 - 217ms/epoch - 43ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1899 - accuracy: 0.7386 - mse: 0.1899 - lr: 1.0000e-05 - 188ms/epoch - 38ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1941 - accuracy: 0.7386 - mse: 0.1941 - lr: 1.0000e-05 - 181ms/epoch - 36ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1911 - accuracy: 0.6993 - mse: 0.1911 - lr: 1.0000e-05 - 159ms/epoch - 32ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1963 - accuracy: 0.6863 - mse: 0.1963 - lr: 1.0000e-05 - 164ms/epoch - 33ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2029 - accuracy: 0.7124 - mse: 0.2029 - lr: 1.0000e-05 - 170ms/epoch - 34ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1949 - accuracy: 0.7255 - mse: 0.1949 - lr: 1.0000e-05 - 185ms/epoch - 37ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1991 - accuracy: 0.6797 - mse: 0.1991 - lr: 1.0000e-05 - 191ms/epoch - 38ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1922 - accuracy: 0.7255 - mse: 0.1922 - lr: 1.0000e-05 - 142ms/epoch - 28ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1992 - accuracy: 0.6928 - mse: 0.1992 - lr: 1.0000e-05 - 151ms/epoch - 30ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1892 - accuracy: 0.6928 - mse: 0.1892 - lr: 1.0000e-07 - 164ms/epoch - 33ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1985 - accuracy: 0.6863 - mse: 0.1985 - lr: 1.0000e-07 - 158ms/epoch - 32ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1919 - accuracy: 0.7451 - mse: 0.1919 - lr: 1.0000e-07 - 155ms/epoch - 31ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1990 - accuracy: 0.7059 - mse: 0.1990 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1962 - accuracy: 0.6928 - mse: 0.1962 - lr: 1.0000e-07 - 145ms/epoch - 29ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1892 - accuracy: 0.7582 - mse: 0.1892 - lr: 1.0000e-07 - 168ms/epoch - 34ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2018 - accuracy: 0.6732 - mse: 0.2018 - lr: 1.0000e-07 - 154ms/epoch - 31ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2017 - accuracy: 0.6863 - mse: 0.2017 - lr: 1.0000e-07 - 223ms/epoch - 45ms/step\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.2285 - accuracy: 0.6944 - mse: 0.2285\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_w\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6944\n",
      "Loss: 0.22853268682956696\n"
     ]
    }
   ],
   "source": [
    "results_2012, pred_2012 = train_model_2(x_train_2012, y_train_2012_OHE, x_valid_2012, y_valid_2012_OHE) \n",
    "results_2013, pred_2013 = train_model_2(x_train_2013, y_train_2013_OHE, x_valid_2013, y_valid_2013_OHE) \n",
    "results_2014, pred_2014 = train_model_2(x_train_2014, y_train_2014_OHE, x_valid_2014, y_valid_2014_OHE) \n",
    "results_2015, pred_2015 = train_model_2(x_train_2015, y_train_2015_OHE, x_valid_2015, y_valid_2015_OHE) \n",
    "results_2016, pred_2016 = train_model_2(x_train_2016, y_train_2016_OHE, x_valid_2016, y_valid_2016_OHE) \n",
    "results_2017, pred_2017 = train_model_2(x_train_2017, y_train_2017_OHE, x_valid_2017, y_valid_2017_OHE) \n",
    "results_2018, pred_2018 = train_model_2(x_train_2018, y_train_2018_OHE, x_valid_2018, y_valid_2018_OHE) \n",
    "results_2019, pred_2019 = train_model_2(x_train_2019, y_train_2019_OHE, x_valid_2019, y_valid_2019_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666641831398"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data = [results_2012[:2],results_2013[:2],results_2014[:2],results_2015[:2],results_2016[:2],\n",
    "                               results_2017[:2],results_2018[:2],results_2019[:2]],\n",
    "                            index = ['2012', '2013', '2014','2015','2016','2017','2018','2019'],\n",
    "                            columns = ['loss', 'accuracy'])\n",
    "sum(results['accuracy'])/8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 1.0, '2018'), Text(0.5, 1.0, '2019'))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0wAAAQ/CAYAAAAnjGxWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXwM5x8H8M8mkU1EEglyLLncV4S6ipakjkiJu6ijcZbWfdMWccbRIy1KVSuotNoqrVKKIhQlSPVwCyLELZGQw+78/vDbbVay7Oy9k8/79ZpXm9lnZ57ZbD7mO/PMjEwQBAFERERERERUhIO1O0BERERERGSrWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDBRiXXu3Dm0a9cOnp6ekMlk2Lx5s0mXf+nSJchkMiQkJJh0ufYsPDwc4eHh1u4GWYhMJkNsbKzo90npb2fAgAEIDg426L2xsbGQyWSm7ZAVPf19SEhIgEwmw6VLl5773uDgYAwYMMCk/THmd0NEJQsLJrKqCxcuYNiwYahcuTJcXFzg4eGBFi1a4OOPP8ajR4/Muu6YmBj89ddfmDdvHtatW4dGjRqZdX2WNGDAAMhkMnh4eBT7OZ47dw4ymQwymQzvv/++6OVfu3YNsbGxSElJMUFvbZdMJsPIkSOf2UalUmHt2rVo2rQpvL294e7ujurVq+ONN97A4cOHATzZ2VN/3s+a1AWC+uchQ4YUu853331X0+b27dvP7J96p1Qmk+HAgQNFXhcEAQEBAZDJZOjYsaMen4rtOH36NCZPnoz69evD3d0d/v7+6NChA5KTk5/7Xn1+HzKZDHv37jX/htiIJUuWwNPTE2+99RZkMhnOnz+vs636O3jy5EkL9lA8W82qW7duYcyYMahZsyZcXV3h4+ODJk2aYMqUKcjOzha9vIMHDyI2Nhb3798X9b4NGzagWbNmcHNzQ9myZdG8eXP89ttvRdrduHEDw4YNQ8WKFeHi4oLg4GAMHjxY7/UcP34cnTp1gre3N0qXLo26devik08+0Wrz2WefISQkBN7e3ujfvz+ysrK0XlepVGjQoAHmz58vahuJTMHJ2h2gkmvr1q147bXXIJfL8cYbb6Bu3brIz8/HgQMHMGnSJPzzzz9YuXKlWdb96NEjHDp0CO++++5zd4gNFRQUhEePHqFUqVJmWf7zODk54eHDh9iyZQt69uyp9dr69evh4uKC3Nxcg5Z97do1zJo1C8HBwahfv77e7/v1118NWp8tGz16NJYtW4bOnTujb9++cHJywpkzZ/DLL7+gcuXKePHFFxEfH6+1E7Rt2zZ8/fXX+Oijj1C+fHnN/ObNm2v+38XFBRs3bsSnn34KZ2dnrXV+/fXXon9/Li4uSExMxEsvvaQ1f9++fbh69SrkcrnYTbe6VatW4YsvvkD37t3x9ttvIzMzE5999hlefPFFbN++HW3atNH53nXr1mn9vHbtWuzcubPI/Fq1ahnVx88//xwqlcqg97733nuYOnWqUesXY+vWrWjXrh0GDBiAFStWIDExETNmzCi27ddff43Q0FDUq1fP4PX1798fvXv3Nut371lZZczvxhh3795Fo0aNkJWVhUGDBqFmzZq4c+cOTp48ieXLl+Ott95CmTJlRC3z4MGDmDVrFgYMGICyZcvq9Z7Y2FjMnj0bPXr0wIABA1BQUIC///4b6enpWu3S0tLQokULAMDw4cNRsWJFXLt2DUeOHNFrPb/++iuio6PRoEEDTJ8+HWXKlMGFCxdw9epVTZsDBw7grbfewujRo1G5cmXExcVh0qRJ+OyzzzRtPv/8c2RmZmLChAl6rZfIpAQiK7h48aJQpkwZoWbNmsK1a9eKvH7u3DkhPj7ebOu/fPmyAEBYvHix2dZhTTExMYKbm5vQrl07oUuXLkVer1atmtC9e3eDP4OjR48KAITVq1fr1T4nJ0f0OmwBAGHEiBE6X8/IyBBkMpkwdOjQIq+pVCrhxo0bxb5v8eLFAgAhNTVV53q7dOkiODg4CJs3b9Z67ffffxcAaH5/t27deuY2rF69WgAgdOvWTShfvrxQUFCg9frQoUOFhg0bCkFBQUKHDh2euSyxAAgzZ84U/b7U1FS9vl/JycnCgwcPtObdvn1bqFChgtCiRQtR6xwxYoSgzz+J9vpdfp6cnBzBxcVF85lXrVpVqFmzZrFtDx48KAAQFixYIGodhn4fBEEQgoKChJiYGNHvE5tVlrBo0SIBgPD7778XeS0zM1N49OiR6GU+L1OedujQIUEmkwkffvjhc9tGRUUJISEhwu3bt0X3KzMzU/D19RW6du0qKJVKne2mTJkiREREaH5evXq14Ofnp/n53r17Qvny5YWNGzeK7gORKXBIHlnFokWLkJ2djS+++AL+/v5FXq9atSrGjBmj+fnx48eYM2cOqlSpArlcjuDgYLzzzjvIy8vTel9wcDA6duyIAwcOoEmTJnBxcUHlypWxdu1aTZvY2FgEBQUBACZNmgSZTKYZx65rTHtx1xLs3LkTL730EsqWLYsyZcqgRo0aeOeddzSv67oO47fffsPLL7+sGQLRuXNnnDp1qtj1nT9/XnPE0NPTEwMHDsTDhw91f7BP6dOnD3755RetYRpHjx7FuXPn0KdPnyLt7969i4kTJyI0NBRlypSBh4cHoqKi8Oeff2ra7N27F40bNwYADBw4sMhwsvDwcNStWxfHjh1Dy5YtUbp0ac3nUtw1TLm5uYiNjUX16tXh4uICf39/dOvWDRcuXNC0UalUiI+PR506deDi4gJfX18MGzYM9+7d01pWcnIyIiMjUb58ebi6uiIkJASDBg3SanP9+nWcPn0aBQUFen+OuqSmpkIQBM3R18JkMhl8fHwMXnbFihXRsmVLJCYmas1fv349QkNDUbduXVHLe/3113Hnzh3s3LlTMy8/Px/ff/99sd8FAMjJycGECRMQEBAAuVyOGjVq4P3334cgCFrt8vLyMG7cOFSoUAHu7u7o1KmT1tHjwtLT0zFo0CD4+vpCLpejTp06+PLLL0Vti1rDhg2LHIkvV64cXn755SJ/U4Z41nf5xx9/RIcOHaBQKCCXy1GlShXMmTMHSqVSaxlPZ4o6F95//32sXLlSk2mNGzfG0aNHtd5bXO6oh4lu3rwZdevW1XyG27dvL9L/vXv3olGjRnBxcUGVKlXw2Wef6bwuavfu3cjLy0NUVBQAoG/fvjh9+jSOHz9epG1iYiJkMhlef/115OfnY8aMGWjYsCE8PT3h5uaGl19+GXv27Hnu51vcNUyCIGDu3LmoVKkSSpcujYiICPzzzz9F3muKrCou7/X9zov5PTztwoULcHR0xIsvvljkNQ8PD7i4uGjN++OPP9C+fXt4enqidOnSaNWqFX7//XfN67GxsZg0aRIAICQkRLOdz7o2LD4+Hn5+fhgzZgwEQdA5DPD06dP45ZdfMGnSJJQrVw65ubmisjMxMRE3btzAvHnz4ODggJycnGLP6j169AheXl6an729vbX+rYuNjUVoaCi6deum97qJTIkFE1nFli1bULlyZa0hSM8yZMgQzJgxAy+88AI++ugjtGrVCnFxcejdu3eRtufPn0ePHj3Qtm1bfPDBB/Dy8sKAAQM0/+h269YNH330EYAnO5Hr1q1DfHy8qP7/888/6NixI/Ly8jB79mx88MEH6NSpk9Y/YsXZtWsXIiMjcfPmTcTGxmL8+PE4ePAgWrRoUew/bj179sSDBw8QFxeHnj17IiEhAbNmzdK7n926dYNMJsMPP/ygmZeYmIiaNWvihRdeKNL+4sWL2Lx5Mzp27IgPP/wQkyZNwl9//YVWrVrh2rVrAJ4MUZo9ezYA4M0338S6deuwbt06tGzZUrOcO3fuICoqCvXr10d8fDwiIiKK7Z9SqUTHjh0xa9YsNGzYEB988AHGjBmDzMxM/P3335p2w4YNw6RJkzTXtw0cOBDr169HZGSk5h/vmzdvol27drh06RKmTp2KJUuWoG/fvprriNSmTZuGWrVqFRl2Ygh14f3dd9+JKmT11adPH2zZskWzM/P48WN89913OgucZwkODkazZs3w9ddfa+b98ssvyMzMLPbvSBAEdOrUCR999BHat2+PDz/8EDVq1MCkSZMwfvx4rbZDhgxBfHw82rVrhwULFqBUqVLo0KFDkWXeuHEDL774Inbt2oWRI0fi448/RtWqVTF48GDRf4PPkpGRoTXU0Ri6vssJCQkoU6YMxo8fj48//hgNGzbEjBkz9B5Cl5iYiMWLF2PYsGGYO3cuLl26hG7duum1M3rgwAG8/fbb6N27NxYtWoTc3Fx0794dd+7c0bQ5ceIE2rdvjzt37mDWrFkYPHgwZs+erfPmNtu2bUPDhg3h6+sL4EnBpO5nYUqlEt9++y1efvllBAYGIisrC6tWrUJ4eDgWLlyI2NhY3Lp1C5GRkQZdNzRjxgxMnz4dYWFhWLx4MSpXrox27dohJydHq52psqowMd95QL/fQ3GCgoKgVCqLDP8szm+//YaWLVsiKysLM2fOxPz583H//n288sormiFx3bp1w+uvvw4A+OijjzTbWaFCBZ3L3b17Nxo3boxPPvlEc6DD398fS5cu1Wq3a9cuAICvry9at24NV1dXuLq6IioqSq+bdezatQseHh5IT09HjRo1NMXtW2+9pTWkuHHjxti+fTt+/fVXnDt3Dh988AGaNGkCAPj333+xYsUKk2YEkWhWPLtFJVRmZqYAQOjcubNe7VNSUgQAwpAhQ7TmT5w4UQAg/Pbbb5p5QUFBAgAhKSlJM+/mzZuCXC4XJkyYoJmnHvLz9HC0mJgYISgoqEgfZs6cqTVc56OPPnrucKjihhXVr19f8PHxEe7cuaOZ9+effwoODg7CG2+8UWR9gwYN0lpm165dhXLlyulcZ+HtcHNzEwRBEHr06CG0bt1aEARBUCqVgp+fnzBr1qxiP4Pc3NwiwyZSU1MFuVwuzJ49WzPvWcNcWrVqJQAQVqxYUexrrVq10vz85ZdfCgCKHRaiUqkEQRCE/fv3CwCE9evXa72+fft2rfmbNm0SAAhHjx591kcjxMTE6D10Bc8ZkicIgvDGG28IAAQvLy+ha9euwvvvvy+cOnXqme/RZ0jeiBEjhLt37wrOzs7CunXrBEEQhK1btwoymUy4dOmS5jui75C8o0ePCkuXLhXc3d2Fhw8fCoIgCK+99ppmGMzTQ/I2b94sABDmzp2rtbwePXoIMplMOH/+vCAI//19vv3221rt+vTpU2QI1uDBgwV/f/8iQ3t69+4teHp6avql75C84iQlJQkymUyYPn26qPcVNyTvWd9ldV8LGzZsmFC6dGkhNzdXM+/pTFFvW7ly5YS7d+9q5v/4448CAGHLli2aeU/njiA8+W44OztrPn9BeJIhAIQlS5Zo5kVHRwulS5cW0tPTNfPOnTsnODk5FTv0MDAwsMhwucaNGwuVKlXSygT1391nn30mCIIgPH78WMjLy9N637179wRfX98i+fX090H93VT/Hdy8eVNwdnYWOnTooPn7FwRBeOeddwQAWkPyTJFVT/9u9P3Oq7dFn99DcTIyMoQKFSoIAISaNWsKw4cPFxITE4X79+9rtVOpVEK1atWEyMhIrc/j4cOHQkhIiNC2bVvNPDFD8u7evav5DpYpU0ZYvHixsGHDBqF9+/ZFvu+jR4/WtG3fvr2wYcMGYfHixUKZMmWEKlWqPHeIar169YTSpUsLpUuXFkaNGiVs3LhRGDVqlABA6N27t6bd48ePhW7dugkABABCQECAcPLkSUEQBKFdu3bC8OHDn7tdRObEM0xkceo737i7u+vVftu2bQBQ5Aif+sLPrVu3as2vXbs2Xn75Zc3PFSpUQI0aNXDx4kWD+/w09UW1P/74o94XDV+/fh0pKSkYMGAAvL29NfPr1auHtm3barazsOHDh2v9/PLLL+POnTtF7h70LH369MHevXuRkZGB3377DRkZGTrPUMjlcjg4PIkFpVKJO3fuaIYbFjc0Rxe5XI6BAwc+t93GjRtRvnx5jBo1qshr6mFD3333HTw9PdG2bVvcvn1bM6mHY6mH/qh/Jz///PMzj9InJCRAEAST3U549erVWLp0KUJCQrBp0yZMnDgRtWrVQuvWrY0+i+Xl5YX27dtrzgolJiaiefPmmjNbYvXs2ROPHj3Czz//jAcPHuDnn3/W+V3Ytm0bHB0dMXr0aK35EyZMgCAI+OWXXzTtABRpN3bsWK2fBUHAxo0bER0dDUEQtH6XkZGRyMzMFPUdK87NmzfRp08fhISEYPLkyUYtS03Xd9nV1VXz/w8ePMDt27fx8ssv4+HDhzh9+vRzl9urVy+tIUjqzNInp9q0aYMqVapofq5Xrx48PDw071Uqldi1axe6dOkChUKhaVe1alXNkLvC/v77b1y5cqXIWcF+/frh6tWrSEpK0sxLTEyEs7MzXnvtNQCAo6Oj5qYkKpUKd+/exePHj9GoUSPRv89du3YhPz8fo0aN0ho2+PR3CTBdVhWm73de7Xm/B118fX3x559/Yvjw4bh37x5WrFiBPn36wMfHB3PmzNEM/0tJSdEMn75z547m7yUnJwetW7dGUlKSQTetUJ+xvnPnDlatWoWJEyeiZ8+e2Lp1K2rXro25c+cWaevn54etW7eiZ8+emDhxIj7//HNcuHChyBnI4tb18OFDvPHGG/jkk0/QrVs3fPLJJxg2bBi++eYbnDt3DsCT79HGjRtx7tw5JCcn4+zZswgNDcVPP/2EI0eOYM6cOUhPT0d0dDQUCgWio6M1ZxKJLIEFE1mch4cHgCc7Gfq4fPkyHBwcULVqVa35fn5+KFu2LC5fvqw1PzAwsMgyvLy8ilzvYoxevXqhRYsWGDJkCHx9fdG7d298++23z/zHS93PGjVqFHmtVq1amn8IC3t6W9Q7WGK25dVXX4W7uzs2bNiA9evXo3HjxkU+SzWVSoWPPvoI1apVg1wuR/ny5VGhQgWcPHkSmZmZeq+zYsWKRe7sVpwLFy6gRo0acHLSfcPOc+fOITMzEz4+PqhQoYLWlJ2djZs3bwIAWrVqhe7du2PWrFkoX748OnfujNWrVxe5zs3UHBwcMGLECBw7dgy3b9/Gjz/+iKioKPz222/FDnUTq0+fPti5cyeuXLmCzZs3GzQcT61ChQpo06YNEhMT8cMPP0CpVKJHjx7Ftr18+TIUCkWRAxvqu8apv8/qv8/CO45A0e/5rVu3cP/+faxcubLI71FdkKh/l4bIyclBx44d8eDBA/z444+i7zKmi67v8j///IOuXbvC09MTHh4eqFChAvr16wcAev2tGPO3/byMu3nzJh49elTs33lx87Zu3QpfX98ij1bo3bs3HB0dNTvFubm52LRpE6KiorSKvTVr1qBevXpwcXFBuXLlUKFCBWzdulVUZgD/faeqVaumNb9ChQpa6wNMl1VPr1+f77yaMf/W+Pv7Y/ny5bh+/TrOnDmjGRo3Y8YMfPHFFwCgKSZiYmKK/M2sWrUKeXl5Bm2rutgvVaqU1t+/g4MDevXqhatXr+LKlStabXv27KkpUAHgtddeg5OTEw4ePKjXutRDBtXUOXbo0CGt+VWrVkXDhg3h4uKC/Px8TJgwATNnzkT58uXRu3dvuLq6YsuWLXBxcTEqC4nE4m3FyeI8PDygUCi0rlHRh74PcHR0dCx2vvDURbti1vH0hdyurq5ISkrCnj17sHXrVmzfvh0bNmzAK6+8gl9//VVnH8QyZlvU5HI5unXrhjVr1uDixYvPfJDo/PnzMX36dAwaNAhz5syBt7c3HBwcMHbsWFFHMgsffTeWSqWCj48P1q9fX+zr6nH6MpkM33//PQ4fPowtW7Zgx44dGDRoED744AMcPnzYZDvQz1KuXDl06tQJnTp1Qnh4OPbt24fLly8bfEYIADp16gS5XI6YmBjk5eUVuUW8WH369MHQoUORkZGBqKgovW9BbCz196dfv36IiYkpto2ht6jOz89Ht27dcPLkSezYsUP0DTGepbjv8v3799GqVSt4eHhg9uzZqFKlClxcXHD8+HFMmTJFr78VY/62TZELhW3btg3t27cvkn8+Pj5o27YtNm7ciGXLlmHLli148OCB5vomAPjqq68wYMAAdOnSBZMmTYKPjw8cHR0RFxendeMWUzNVVhnDFL8HmUyG6tWro3r16ujQoQOqVauG9evXY8iQIZrtWLx4sc7HNxiSa97e3nBxcUHZsmWLbIP6RjX37t1DYGCg5gyl+to2NUdHR5QrV+65xaFCocA///xT5P2F16PLRx99BCcnJ4wcORJpaWk4cOAAUlNTERwcjEWLFqFy5cq4evUqKlWqpN+GExmBBRNZRceOHbFy5UocOnQIzZo1e2bboKAgqFQqnDt3TuuZKDdu3MD9+/eN2hl9mpeXV7EP/nv6yCLw5Ghc69at0bp1a3z44YeYP38+3n33XezZs6fY57+o+3nmzJkir50+fRrly5eHm5ub8RtRjD59+uDLL7+Eg4PDM896fP/994iIiNAc4VS7f/++1kX0+havz1OlShX88ccfKCgo0Pm8qipVqmDXrl1o0aKFXoXYiy++iBdffBHz5s1DYmIi+vbti2+++UbnQ2DNpVGjRti3bx+uX79u1HfU1dUVXbp0wVdffYWoqCijb2bQtWtXDBs2DIcPH8aGDRt0tgsKCsKuXbvw4MEDrSPu6uFm6m1S/32qzxaqPf09V19YrlQqn/l8JLFUKhXeeOMN7N69G99++y1atWplsmXrsnfvXty5cwc//PCD1g0EUlNTzb5uffj4+MDFxaXYB88+Pe/+/fs4ePCgzufR9e3bF9u3b8cvv/yCxMREeHh4IDo6WvP6999/j8qVK+OHH37QyoWZM2eK7rf6O3Xu3DlUrlxZM//WrVtFdqzNkVX6fufNpXLlyvDy8sL169cBQHPW1sPD47l/M2K208HBAfXr18fRo0eRn5+vdQZVPcxNfSCqYcOGAFBkeHF+fj5u3779zBtLqN+/c+dOzU0fdK3nadevX8fcuXPx3XffwcnJSdNeXcCp/5uens6CiSyCQ/LIKiZPngw3NzcMGTIEN27cKPL6hQsX8PHHHwN4MqQMQJE75Hz44YcAUOzduAxVpUoVZGZmaj29/vr169i0aZNWu7t37xZ5r/oIoK4hYP7+/qhfvz7WrFmjVZT9/fff+PXXXzXbaQ4RERGYM2cOli5dCj8/P53tHB0dixwd/e6774r8Y6ku7MQ+Vf5p3bt3x+3bt4vcmQn47yhtz549oVQqMWfOnCJtHj9+rOnDvXv3ivS9uN+JKW8rnpGRgX///bfI/Pz8fOzevbvYoaSGmDhxImbOnInp06cbvawyZcpg+fLliI2N1drxfdqrr74KpVJZ5Hfz0UcfQSaTaa6FUf/3k08+0Wr39N+ro6Mjunfvjo0bNxZ7dvnWrVuGbA5GjRqFDRs24NNPP7XYLYfVR+ULf9/y8/Px6aefWmT9z+Po6Ig2bdpg8+bNWtd5nD9/vsh1OOqHSbdr167YZXXp0gWlS5fGp59+il9++QXdunXTuu11cZ/FH3/8UWSolT7atGmDUqVKYcmSJVrLK+7uaObIKn2/88b6448/igy/BoAjR47gzp07msKiYcOGqFKlCt5///1ib/td+G9GbCb36tULSqUSa9as0czLzc3F+vXrUbt2bU1BEh4erjnDX/iudgkJCVAqlWjbtq1m3u3bt3H69GmtO4aqz4g/XdiuWrUKTk5ORR4zoTZ16lS0bNkS7du3B/DfGS518ap+bMCz/j0jMiWeYSKrqFKlChITE9GrVy/UqlULb7zxBurWrYv8/HwcPHgQ3333HQYMGAAACAsLQ0xMDFauXKkZCnPkyBGsWbMGXbp00XnLakP07t0bU6ZMQdeuXTF69Gg8fPgQy5cvR/Xq1bUuJJ49ezaSkpLQoUMHBAUF4ebNm/j0009RqVIlvPTSSzqXv3jxYkRFRaFZs2YYPHgwHj16hCVLlsDT0/OZQ+WM5eDggPfee++57Tp27IjZs2dj4MCBaN68Of766y+sX79e62gv8OT3V7ZsWaxYsQLu7u5wc3ND06ZNERISIqpfb7zxBtauXYvx48fjyJEjePnll5GTk4Ndu3bh7bffRufOndGqVSsMGzYMcXFxSElJQbt27VCqVCmcO3cO3333HT7++GP06NEDa9aswaeffoquXbuiSpUqePDgAT7//HN4eHhoFaPTpk3DmjVrNEM7nic5OVnrImi18PBwuLi4oEmTJnjllVfQunVr+Pn54ebNm/j666/x559/YuzYsSa5vXVYWBjCwsKMXo6ariFxhUVHRyMiIgLvvvsuLl26hLCwMPz666/48ccfMXbsWM3R7/r16+P111/Hp59+iszMTDRv3hy7d+8u9uzGggULsGfPHjRt2hRDhw5F7dq1cffuXRw/fhy7du0q9kDEs8THx+PTTz9Fs2bNULp0aXz11Vdar3ft2tUsZ22bN28OLy8vxMTEYPTo0ZDJZFi3bp3BQ+LMITY2Fr/++itatGiBt956S1MI1K1bV+t231u3bsVLL70ET0/PYpdTpkwZdOnSRXMdU+HheMCTzPjhhx/QtWtXdOjQAampqVixYgVq166t89k+ulSoUAETJ05EXFwcOnbsiFdffRUnTpzAL7/8UuTvyBxZpe933ljr1q3D+vXr0bVrVzRs2BDOzs44deoUvvzyS7i4uGie9eXg4IBVq1YhKioKderUwcCBA1GxYkWkp6djz5498PDwwJYtWwD8dybo3XffRe/evVGqVClER0fr/P4PGzYMq1atwogRI3D27FkEBgZi3bp1uHz5smaZwJMh3YsXL0ZMTAxatmyJ/v3748qVK/j444/x8ssvax2kWLp0KWbNmoU9e/ZoCqEGDRpg0KBB+PLLL/H48WO0atUKe/fuxXfffYdp06Zp3ZRE7ciRI9iwYYPWgcvg4GA0atQIAwYMwODBg7Fq1So0bdrU7Gf9iDQsfFc+Ii1nz54Vhg4dKgQHBwvOzs6Cu7u70KJFC2HJkiVat+YtKCgQZs2aJYSEhAilSpUSAgIChGnTpmm1EYSit0ZWe/p21rpuKy4IgvDrr78KdevWFZydnYUaNWoIX331VZHb++7evVvo3LmzoFAoBGdnZ0GhUAivv/66cPbs2SLrePp2trt27RJatGghuLq6Ch4eHkJ0dLTw77//arXRdcvop2/Dq0vh24rrouu24hMmTBD8/f0FV1dXoUWLFsKhQ4eKfH6C8OQ2yLVr19bcpli9na1atRLq1KlT7DqLW87Dhw+Fd999V/O79fPzE3r06CFcuHBBq93KlSuFhg0bCq6uroK7u7sQGhoqTJ48Wbh27ZogCIJw/Phx4fXXXxcCAwMFuVwu+Pj4CB07dhSSk5OLfDb6fIaCIGhucVvcNGfOHCErK0v4+OOPhcjISKFSpUpCqVKlBHd3d6FZs2bC559/rnUr4ML0va34sxhyW/FnKe5v58GDB8K4ceMEhUIhlCpVSqhWrZqwePHiItv16NEjYfTo0UK5cuUENzc3ITo6WkhLSytyG2lBEIQbN24II0aMEAICAjS/79atWwsrV67UtNH3tuLq36WuSZ/fsZqu24rr+i7//vvvwosvvii4uroKCoVCmDx5srBjxw4BgLBnzx6tPhZ3W/Hisufpz0vXbcWL+24EBQVp3XZbEJ7kVIMGDQRnZ2ehSpUqwqpVq4QJEyYILi4ugiA8uW21j4+PsGjRomK3UW3r1q0CAMHf37/IrbxVKpUwf/58ISgoSJDL5UKDBg2En3/+udhHNDy9fcXlmVKpFGbNmqXJoPDwcOHvv/8usn2myKri+qjvd17M7+FpJ0+eFCZNmiS88MILgre3t+Dk5CT4+/sLr732mnD8+PEi7U+cOCF069ZNKFeunCCXy4WgoCChZ8+ewu7du7XazZkzR6hYsaLg4OCg1/f/xo0bQkxMjODt7S3I5XKhadOmwvbt24tt+/XXXwthYWGCXC4XfH19hZEjRwpZWVlabdTf18Lff0EQhPz8fCE2NlYICgoSSpUqJVStWlX46KOPil2PSqUSmjZtKowfP77Ia+fPnxdatmwplClTRmjZsmWRfyOIzEkmCDZ0SIyIiIjMpkuXLvjnn39w7tw5HDlyBE2bNsU///yD2rVrW7trREQ2i9cwERERSdCjR4+0fj537hy2bdumdd3I/PnzWSwRET0HzzARERFJkL+/PwYMGIDKlSvj8uXLWL58OfLy8nDixIkizzoiIiLdeNMHIiIiCWrfvj2+/vprZGRkQC6Xo1mzZpg/fz6LJSIikXiGiYiIiIiISAdew0RERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERml5SUhOjoaCgUCshkMmzevLlIm1OnTqFTp07w9PSEm5sbGjdujCtXrli+s0REhbBgIiK9cGeHiIyRk5ODsLAwLFu2rNjXL1y4gJdeegk1a9bE3r17cfLkSUyfPh0uLi4W7ikRkTYna3eAiOyDemdn0KBB6NatW5HX1Ts7gwcPxqxZs+Dh4YF//vmHOztEBACIiopCVFSUztffffddvPrqq1i0aJFmXpUqVSzRNSKiZ5IJgiBYuxNEZJzc3Fzk5+eLeo8gCJDJZFrz5HI55HL5c98rk8mwadMmdOnSRTOvd+/eKFWqFNatWyeqH0RkfYZkCGB4jjydISqVCp6enpg8eTIOHDiAEydOICQkBNOmTdPKGSKyXYbmiLOzs80fXOWQPCI7l5ubi5CgMvD09BQ1VapUqci8uLg4g/qgUqmwdetWVK9eHZGRkfDx8UHTpk2LHbZHRLbF0AwxZY7cvHkT2dnZWLBgAdq3b49ff/0VXbt2Rbdu3bBv3z4zbDURmZIxORISEoLc3Fxrb8IzcUgekZ3Lz89Hxk0lUo8FwcNdv2MgWQ9UCGl4GWlpafDw8NDM1+fsUnEK7+zMnTsXCxcuxPbt29GtWzfs2bMHrVq1Mmi5RGR+hmQIYNocUalUAIDOnTtj3LhxAID69evj4MGDWLFiBTOEyMYZmyP5+fk2fZaJBRORRLiVeTLpQ/n/gbgeHh5aOzqG4s4Okf0TkyGAaXOkfPnycHJyQu3atbXm16pVCwcOHDBq2URkOYbmiK3jkDwiiVBBEDWZ0rN2dniXPCL7IDZDTJkjzs7OaNy4Mc6cOaM1/+zZswgKCjLZeojIvKyZI+bEM0xEZDTu7BDR82RnZ+P8+fOan1NTU5GSkgJvb28EBgZi0qRJ6NWrF1q2bImIiAhs374dW7Zswd69e63XaSIisGAikgwVVFCJaCsWd3aIpE1Mhqjbi5GcnIyIiAjNz+PHjwcAxMTEICEhAV27dsWKFSsQFxeH0aNHo0aNGti4cSNeeuklUeshIusxd45YC28rTmTnsrKy4OnpibTTFUXd9CGgZjoyMzP1vvZg7969Wjs7auqdHQD48ssvERcXh6tXr6JGjRqYNWsWOnfurPe2EJHlGZIhgGE5QkTSJPUc4RkmIokQMxbYkDHD4eHheN7xlUGDBmHQoEGil01E1if2egJ7ufaAiCxHqjnCgolIIlQQoDRjwURE0iYmQ9TtiYgKk2qOsGAikghzn2EiImmT6pFhIrIcqeYICyYiiVAKApR6XpKobzsiKjnEZIi6PRFRYVLNERZMRBKh+v+kb1siosLEZIi6PRFRYVLNET64lkgilP8fN6zvRERUmNgMYY4Q0dPMnSNJSUmIjo6GQqGATCbD5s2btV7Pzs7GyJEjUalSJbi6uqJ27dpYsWKF0dvFgolIIpSCuImIqDCxGcIcIaKnmTtHcnJyEBYWhmXLlhX7+vjx47F9+3Z89dVXOHXqFMaOHYuRI0fip59+Mmq7OCSPSCI4JI+IjCHVoTREZDmG5khWVpbWfLlcDrlcXqR9VFQUoqKidC7v4MGDiImJQXh4OADgzTffxGeffYYjR46gU6dOInqmjWeYiCRCBRmUek4qyKzdXSKyMWIyhDlCRMUxNEcCAgLg6empmeLi4gxaf/PmzfHTTz8hPT0dgiBgz549OHv2LNq1a2fUdvEME5FEqIQnk75tiYgKE5Mh6vZERIUZmiNpaWnw8PDQzC/u7JI+lixZgjfffBOVKlWCk5MTHBwc8Pnnn6Nly5YGLU+NBRORRKiP1ujbloioMDEZom5PRFSYoTni4eGhVTAZasmSJTh8+DB++uknBAUFISkpCSNGjIBCoUCbNm0MXi4LJiKJYMFERMZgwURExrJmjjx69AjvvPMONm3ahA4dOgAA6tWrh5SUFLz//vssmIgIUAkyqAT9gkffdkRUcojJEHV7IqLCrJkjBQUFKCgogIOD9i0aHB0doVIZd5saFkxEEsEzTERkDJ5hIiJjmTtHsrOzcf78ec3PqampSElJgbe3NwIDA9GqVStMmjQJrq6uCAoKwr59+7B27Vp8+OGHotbzNBZMRERERERk85KTkxEREaH5efz48QCAmJgYJCQk4JtvvsG0adPQt29f3L17F0FBQZg3bx6GDx9u1HpZMBFJhBIOUOr5pAClmftCRPZHTIY8aU9EpM3cORIeHg5B0H0bPj8/P6xevVrkUp+PBRORRAgixg0LvPaAiJ4iJkPU7YmICpNqjvDBtRJ29OhRjBw5EnXq1IGbmxsCAwPRs2dPnD17tkjbU6dOoX379ihTpgy8vb3Rv39/3Lp1q0i7efPmoVOnTvD19YVMJkNsbGyx6/7hhx/Qq1cvVK5cGaVLl0aNGjUwYcIE3L9/38RbSWpiHhTHaw9IX9bMkU2bNiEyMhIKhQJyuRyVKlVCjx498Pfff5t6MwniM4Q5QvqyZo48rW3btpDJZBg5cqSxm0XFkGqO8AyThC1cuBC///47XnvtNdSrVw8ZGRlYunQpXnjhBRw+fBh169YFAFy9ehUtW7aEp6cn5s+fj+zsbLz//vv466+/cOTIETg7O2uW+d5778HPzw8NGjTAjh07dK77zTffhEKhQL9+/RAYGIi//voLS5cuxbZt23D8+HG4urqafftLGqXgAKWg55A8PnCS9GTNHPnrr7/g5eWFMWPGoHz58sjIyMCXX36JJk2a4NChQwgLCzP79pckYjLkSXszdoYkxZo5UtgPP/yAQ4cOmWUb6Qmp5ggLJgkbP348EhMTtQKmV69eCA0NxYIFC/DVV18BAObPn4+cnBwcO3YMgYGBAIAmTZqgbdu2SEhIwJtvvql5f2pqKoKDg3H79m1UqFBB57q///57hIeHa81r2LAhYmJisH79egwZMsSEW0oAoIIMKj1PGqtgJwlFVmfNHJkxY0aReUOGDEGlSpWwfPlyrFixwlSbSRCXIU/aM0dIP9bMEbXc3FxMmDABU6ZMKTZbyDSkmiMckidhzZs31wonAKhWrRrq1KmDU6dOaeZt3LgRHTt21IQTALRp0wbVq1fHt99+q/X+4OBgvdb9dLEEAF27dgUArXWT6UjxFDhZnzVzpDg+Pj4oXbo0h/eagVSH0pD12UKOLFq0CCqVChMnThS/AaQ3qeYIC6YSRhAE3LhxA+XLlwcApKen4+bNm2jUqFGRtk2aNMGJEydMtu6MjAwA0KybTEt9GlzfichQls6R+/fv49atW/jrr78wZMgQZGVloXXr1kYtk4oSmyHMETKGJXPkypUrWLBgARYuXMhLAsxMqjliH70kk1m/fj3S09PRq1cvAMD169cBAP7+/kXa+vv74+7du8jLyzPJuhcuXAhHR0f06NHDJMsjbU9Og+s/ERnK0jny4osvwsfHB/Xq1cO3336L9957D4MHDzZ4eVQ8sRnCHCFjWDJHJkyYgAYNGqB3796Gd5j0ItUc4TVMJcjp06cxYsQINGvWDDExMQCAR48eAQDkcnmR9i4uLpo2xb0uRmJiIr744gtMnjwZ1apVM2pZVDyViGcf2MuYYbI91siR1atXIysrCxcvXsTq1avx6NEjKJVKODjwmJ8picmQJ+2ZI2QYS+bInj17sHHjRvzxxx9G9pr0IdUcYcFUQmRkZKBDhw7w9PTE999/D0dHRwDQnJou7qhNbm6uVhtD7d+/H4MHD0ZkZCTmzZtn1LJIN3F3ybOPgCLbYq0cadasmeb/e/fujVq1agEA3n//fYOXSUWJv7sVc4TEs2SOPH78GKNHj0b//v3RuHFjI3tO+pBqjvDwXAmQmZmJqKgo3L9/H9u3b4dCodC8pj71rT4VXtj169fh7e1t1NmlP//8E506dULdunXx/fffw8mJNbq5qOAgaiISw5o5UpiXlxdeeeUVrF+/3iTLo/+IzRDmCIll6RxZu3Ytzpw5g2HDhuHSpUuaCQAePHiAS5cu4eHDh4ZvEBUh1Rzh3qvE5ebmIjo6GmfPnsWuXbtQu3ZtrdcrVqyIChUqIDk5uch7jxw5gvr16xu87gsXLqB9+/bw8fHBtm3bUKZMGYOXRc+nFGRQ6vnEbH3bEQHWzZHiPHr0CJmZmSZdJonLEHV7In1ZI0euXLmCgoICtGjRoshra9euxdq1a7Fp0yZ06dJF9LKpeFLNERZMEqZUKtGrVy8cOnQIP/74o9awlsK6d++ONWvWIC0tDQEBAQCA3bt34+zZsxg3bpxB687IyEC7du3g4OCAHTt26PWMBDKOUsS4YaWdjBkm67Nmjty8eRM+Pj5a8y5duoTdu3cXeyctMo6YDHnSnjlC+rFWjvTu3bvYQqtr16549dVXMXToUDRt2lT0ckk3qeYICyYJmzBhAn766SdER0fj7t27mgfDqfXr1w8A8M477+C7775DREQExowZg+zsbCxevBihoaEYOHCg1nvWrVuHy5cva05hJyUlYe7cuQCA/v37IygoCADQvn17XLx4EZMnT8aBAwdw4MABzTJ8fX3Rtm1bs213SaUSHKDSc9ywyk7GDJP1WTNHQkND0bp1a9SvXx9eXl44d+4cvvjiCxQUFGDBggXm3vQSR0yGPGnPHCH9WCtHatasiZo1axbbp5CQEJ5ZMgOp5ohMEOykpyRaeHg49u3bp/P1wr/6f/75B+PHj8eBAwfg7OyMDh064IMPPoCvr6/ey9yzZ4/mgbUyme5TrK1atcLevXv13xB6pqysLHh6euLz4w1R2t1Rr/c8fKDE0BeOITMzEx4eHmbuIdkza+ZIbGwstm7digsXLuDBgwfw8fFBy5Yt8c477yA0NNT4jSMAhmUIwBwh/VkzR4ojk8kwYsQILF26VNyGkE5SzxEWTER2Th1Snx1vCNcy+p00fpT9GMPsIKCIyPwMyRCAOUJE/5F6jnBIHpFEiLnbjL3clYaILEfsHauYI0T0NKnmiH30koiIiIiIyAp4holIIsQ9uJbHSohIm/gHTjJHiEibVHOEBRORRKgggwr6Pc9A33ZEVHKIyRB1eyKiwqSaI/ZR1hHRc6mP6ug7iZWUlITo6GgoFArIZDJs3rxZZ9vhw4dDJpMhPj7e8A0iIosSmyH2cmSYiCzH3Dmiz77IqVOn0KlTJ3h6esLNzQ2NGzfGlStXjNouph2RRKgfFqfvJFZOTg7CwsKwbNmyZ7bbtGkTDh8+DIVCYeimEJEViM0QQ3KEiKTN3DnyvH2RCxcu4KWXXkLNmjWxd+9enDx5EtOnT4eLi4tR22XXQ/JUKhWuXbsGd3f3Zz73h8jeCIKABw8eQKFQwMFB34fRyqAS9BySp2e7wqKiohAVFfXMNunp6Rg1ahR27NiBDh06iF6HNTBHSIrMnSHq9sQMIemyxRx53r7Iu+++i1dffRWLFi3SzKtSpYqodRTHrguma9euISAgwNrdIDKbtLQ0VKpUSa+2KhFHatS38czKytKaL5fLIZfLxXVSvUyVCv3798ekSZNQp04dg5ZhDcwRkjJzZYi6PTFDSPoskSOm2B9RqVTYunUrJk+ejMjISJw4cQIhISGYNm0aunTpImpZT7Prgsnd3R0A0LD9u3AsZdypNnq+ezX0f3IzGUeZl4uLS2ZrvuP6UAkOUOk5Fljd7ul/5GfOnInY2Fi911nYwoUL4eTkhNGjRxv0fmtRf8YNot9jjlhA6eu51u5CifD4cR4OHl1stgxRtxcjKSkJixcvxrFjx3D9+nVs2rRJ507M8OHD8dlnn+Gjjz7C2LFjRa3H0tSfcdVhM+AoZ4aQdCjzcnH+M/Pti6jbA6bZH7l58yays7OxYMECzJ07FwsXLsT27dvRrVs37NmzB61atRK1vMLsumBSn/p2LOUCJ+7omJ2jnAWTpYkZ3qGEDEo97zajbpeWlqb1ZG1Dzy4dO3YMH3/8MY4fP253Q1KYI5blZNf/6tgfc2WIur0Y6msPBg0ahG7duulsZ2/XQWoyRO7CgokkyRI5Yor9EZVKBQDo3Lkzxo0bBwCoX78+Dh48iBUrVpTcgomI/mPIGSYPDw+tgDLU/v37cfPmTQQGBmrmKZVKTJgwAfHx8bh06ZLR6yAi8zL3GSapXgdJRP8xNEdMsT9Svnx5ODk5oXbt2lrza9WqhQMHDhi1bBZMRBKhhP5HfJUmXnf//v3Rpk0brXmRkZHo378/Bg4caOK1EZE5iMkQdXvAdNdC2ut1kET0H0NzxBScnZ3RuHFjnDlzRmv+2bNnERQUZNSyWTARSYQhZ5jEyM7Oxvnz5zU/p6amIiUlBd7e3ggMDES5cuW02pcqVQp+fn6oUaOG6HURkeVZ89oDwH6vgySi/5j7TPXz9kUmTZqEXr16oWXLloiIiMD27duxZcsW7N27V9R6nsaCiUgixDwAzpAHTiYnJyMiIkLz8/jx4wEAMTExSEhIEL08IrItYh8iqW5rimsP7Pk6SCL6j6E5oq/n7Yt07doVK1asQFxcHEaPHo0aNWpg48aNeOmll0St52ksmIgkQoAMKj1PgwsiL9YGgPDwcAiCoHd7XrdEZF/EZIi6PWCaaw94HSSRNBiaI/rSZ19k0KBBGDRokKjlPg8LJiKJMPcZJiKSNnMfGX4WXgdJJA3WzBFzYsFEJBFinq4t9snaRCR9YjJE3V4MXgdJJH3mzhFrYcFEJBFKEU/XFvMUbiIqGcRkiLq9GLwOkkj6zJ0j1sKCiYiIiMyO10ESkb1iwUQkERySR0TGkOpQGiKyHKnmCAsmIolQwQEqPU9t69uOiEoOMRmibk9EVJhUc4QFE5FEKAUZlHoeqdG3HRGVHGIyRN2eiKgwqeYICyYiieCQPCIyhlSH0hCR5Ug1R1gwEUmEIDhApefzDAQ7ee4BEVmOmAxRtyciKkyqOcKCiUgilJBBqecTs/VtR0Qlh5gMUbcnIipMqjnCgolIIlSC/qe2Vfrf2ZeISggxGaJuT0RUmFRzhAUTkUSoRJwGF3O6nIhKBjEZom5PRFSYVHOEBRORRKggg0rPU9v6tiOikkNMhqjbExEVJtUcYcFEJBG8rTgRGUOqtwMmIsuRao6wYCKSCA7JIyJjSHUoDRFZjlRzhAUTkUSoIOI5THZyCpyILEdMhqjbExEVJtUcYcFEJBGCiHHDgp0EFBFZjpgMUbcnIipMqjnCgolIIsQ8XdtenqxNRJYjJkPU7YmICpNqjrBgIpIIXsNERMaQ6rUHRGQ5Us0R++glET2X+qiOvhMRUWFiM4Q5QkRPM3eOJCUlITo6GgqFAjKZDJs3b9bZdvjw4ZDJZIiPjzduo8CCiYiIiIiI7EBOTg7CwsKwbNmyZ7bbtGkTDh8+DIVCYZL1ckgekUTwwbVEZAypPnCSiCzH3DkSFRWFqKioZ7ZJT0/HqFGjsGPHDnTo0EHU8nVhwUQkEbzpAxEZQ6oXaxOR5RiaI1lZWVrz5XI55HK5+PWrVOjfvz8mTZqEOnXqiH6/LhySRyQRvPaAiIzBa5iIyFiG5khAQAA8PT01U1xcnEHrX7hwIZycnDB69GhTbhbPMBFJBc8wEZExeIaJiIxlaI6kpaXBw8NDM9+Qs0vHjh3Dxx9/jOPHj0MmM20+8QwTkUTwyDARGYNnmIjIWIbmiIeHh9ZkSMG0f/9+3Lx5E4GBgXBycoKTkxMuX76MCRMmIDg42Kjt4hkmIokQoP/Fk4J5u0JEdkhMhqjbExEVZs0c6d+/P9q0aaM1LzIyEv3798fAgQONWjYLJiKJ4JA8IjIGh+QRkbHMnSPZ2dk4f/685ufU1FSkpKTA29sbgYGBKFeunFb7UqVKwc/PDzVq1BC1nqexYCKSCBZMRGQMFkxEZCxz50hycjIiIiI0P48fPx4AEBMTg4SEBFHLEoMFE5FEsGAiImOwYCIiY5k7R8LDwyEI+g/ku3Tpkqjl68KCiUgiWDARkTFYMBGRsaSaIyyYiCRCEGQQ9AwefdsRUckhJkPU7YmICpNqjrBgspBvZyfCv1x2kfk/7KuNj759yQo9krbSpfIxuukRtK6cCu/Sj3DqVnks2P8S/r7pY+2umY0KMr3vTCPmDjZkOxxkKgxufwztGp1DOfeHuJ3lhm1HqiPh1xcA/k5Nat3S7+Hnk1Nk/k87amDJFy9aoUfmJyZD1O3JvjjIVHi7WTI61DqL8m4PcSvbDT/+UwOf/dEQzBDTK4mft1RzhAWThby5qCscHP4bcxnifxfxo7dhz4nKVuyVdM1+ZS+qed/F1F2tcSvHDR1rnMWqzlvQKbEXbuaUsXb3zIJD8qSvX+sUdGnxL+YmhiM1wxs1A27h3df3IjvXGd8nhVq7e5IyclpHrcwODryHRdN3Yt+hYOt1ysykOpSG/jOo8Qn0DPsH725/BRfueKGO7y3MidyDB/nOSDxRz9rdk5yS+HlLNUds4sG1y5YtQ3BwMFxcXNC0aVMcOXLE2l0yufvZrribVVozNa97BVdveSDlnL+1uyY5csfHaFvlIj442AzHrilwJdMTnx5pjCuZHuhd9x9rd89s1KfB9Z3ESkpKQnR0NBQKBWQyGTZv3qx5raCgAFOmTEFoaCjc3NygUCjwxhtv4Nq1aybcQt1KQoYAQN2QG9j/dxAO/RuEjLvu2PtnZRw5Uwm1A29au2uSk/nABfcyXTXTiy9cRXqGO07+62vtrpmN2Ayxl6E0+ioJOVJfcQN7LgRjf2oQrmV5YOe5Kjh4uRJC/Zgh5lASP2+p5ojVC6YNGzZg/PjxmDlzJo4fP46wsDBERkbi5k3pfpmcHJVo1+Qcth2qAamekrUmRwcVnBwE5CkdtebnPXZCA0WGlXplfoY8WVuMnJwchIWFYdmyZUVee/jwIY4fP47p06fj+PHj+OGHH3DmzBl06tTJFJv2TCUpQ/5O9UWj6ukIqHAfAFBVcQf1Kmfg8KlA63ZM4pwclWj98kXs2FMVUs5ssRliL0eG9VFSciTlmi+aBqQjqOx9AED18rfxgiIDB1KZIeZQEj9vqeaI1Yfkffjhhxg6dKjmCbwrVqzA1q1b8eWXX2Lq1KlW7p15vBx2CWVc87HtcHVrd0WSHhY448R1XwxvfAwX73nhzkNXvFrtPML8buBKpoe1u2c25r7pQ1RUFKKioop9zdPTEzt37tSat3TpUjRp0gRXrlxBYKD5/nEoSRmybncDlHYpQOK0DVAJDnCQqbByWxP8eqyatbsmac2bpKGMWz5+3VvV2l0xK6lerK2PkpIjXxx5AWWcC/DTwK+hVDnA0UGFTw40xdbT3B8xh5L4eUs1R6xaMOXn5+PYsWOYNm2aZp6DgwPatGmDQ4cOFWmfl5eHvLw8zc9ZWVkW6aepdWx2Bn/8G4A7mW7W7opkTdvZGnNa78HegWvxWCXDqVsVsO1cVdSucMvaXbMpT/8NyeVyyOVykyw7MzMTMpkMZcuWNcnyiiM2QwD7zpFX6l9Au4bnELuuNVIzvFCt4h2M6XoQtzNL45ejxj3FnHSLijiHIykVcedeaWt3hcygJO2LRNY4jw61zmLKtja4cMcbNSrcxpTw33ErpzR++remtbsnOfy8pcOqQ/Ju374NpVIJX1/tMeG+vr7IyCg6dCouLg6enp6aKSAgwFJdNRlf7wdoWDMdPx/kH4o5pWV5YsCmLmi0YghaJ/RH7++6w8lBhatZ0j7DpO/pb/URnYCAAK2/qbi4OJP0JTc3F1OmTMHrr78ODw/zfeZiMwSw7xwZ0ekwvtpdH7tPVMXF6+WwI7k6Nuyth/5tUqzdNcnyKZ+NBvWu45fd0j+LJyZDVCKPItuykrQvMqHlIXxx5AVsP1MN526Xw8+namDd8TAMaXLC2l2TpJL4eUs1R6x+DZMY06ZNQ2ZmpmZKS0uzdpdEe/XFM7j/wAWH/pbu+FVb8uhxKdx+6AYPeR5aBKZhT2qItbtkNgIAQdBz+v970tLStP6mCh9hNVRBQQF69uwJQRCwfPlyo5dnavacIy7Oj4uM91YJMshk+j/1nMSJjDiP+5ku+ON4JWt3xexEZUihHClp7DpDnB5D9dQvTqlihphLSfy8pZojVh2SV758eTg6OuLGjRta82/cuAE/P78i7U05XMgaZDIBrzY7i1/+qA6lyq5qVbvTIvAKZABS75VFYNlMTGx+CKn3ymLTKekOW1JBBpnI5zB5eHiY9AyQuli6fPkyfvvtN7OeXQLEZwhg3zny+z9BiGl7AjfulUFqhjeqV7yNXuEnsfUP6X6vrUkmExAZfh4791WBqgRktpgMUbeXgpK0L7LvYjDebHoc1x+448IdL9T0uY03Gv6Jzf9w1Is5lMTPW6o5YtWCydnZGQ0bNsTu3bvRpUsXAIBKpcLu3bsxcuRIa3bNLBrVSIefd/b/745H5lTGOR9jm/0BvzLZyMx1wc4LlfHx4SZ4rHJ8/pvtlLlv+vA86mLp3Llz2LNnD8qVK2fydTytpGXIRxtbYOirRzGxxwF4lXmE21lu+PFgLaze0dDaXZOkF0KvwbdCDrbvkfbNHtSkerH285SkHJn/20sY2eII3mudBO/Sj3Ar2w3fn6yN5YcbWbtrklQSP2+p5ojV75I3fvx4xMTEoFGjRmjSpAni4+ORk5OjuVONlBw9XQkvj3jT2t0oEXacr4od50vGTo6aSpBBpmfwGHIbz+zsbJw/f17zc2pqKlJSUuDt7Q1/f3/06NEDx48fx88//wylUqkZ++/t7Q1nZ2fR69NXScqQh3nO+HhTC3y8qYW1u1IiHDtZEW17xli7GxYjJkPU7cVISkrC4sWLcezYMVy/fh2bNm3SFCgFBQV47733sG3bNly8eBGenp5o06YNFixYAIVCIWo9higpOfKwwBmL9r6ERXtfsnZXSoSS+HmbO0esxeoFU69evXDr1i3MmDEDGRkZqF+/PrZv317k4ksiejb1eGB924qVnJyMiIgIzc/jx48HAMTExCA2NhY//fQTAKB+/fpa79uzZw/Cw8PFr1BPzBAi0xCTIer2Yqif5TZo0CB069ZN67XCz3ILCwvDvXv3MGbMGHTq1AnJycniVmQA5giRaZg7R6zF6gUTAIwcOVJyp72JLM3cQ/LCw8MhPCPZnvWauTFDiIxn7qE0tvosNzXmCJHxOCSPiGyata9hIiL7ZuiOjrme52aJZ7kRkWlJtWCS/m1/iEoIMc89sJcxw0RkOWIzRJ0j5niem6We5UZEpmVojtg6nmEikghzX8NERNJm6LUHaWlpWkWNsWeXbP1ZbkSkG69hIiKb9iSk9B2SZ+bOEJHdEZMh6vaAaZ/nZulnuRGRaRmaI7aOQ/KIJEI9bljfiYioMLEZYuocKfwst127dlnkWW5EZFrmzpGkpCRER0dDoVBAJpNh8+bNmtcKCgowZcoUhIaGws3NDQqFAm+88QauXbtm9HaxYCKSCEHkRERUmNgMEZsj2dnZSElJQUpKCoD/nuV25coVFBQUoEePHkhOTsb69es1z3LLyMhAfn6+SbaPiMzP3DmifjzBsmXLirxW+PEEx48fxw8//IAzZ86gU6dOhm/Q/3FIHpFE8C55RGQMc9/dylaf5UZEpiPVxxPoVTCpQ0wfpqjiiMgAYg7VWOEUE3OEyMaJPdwrMkeMfZYbM4TIDhiYI7b+eAK9CqYuXbrotTCZTAalUmlMf4jIUGKO6ljhDBNzhMjGib2ewMI5wgwhsgMG5khAQIDW7JkzZyI2Ntaorpjy8QR6FUwqlcqolRCR+dn6bcWZI0S2zdZvB8wMIbJ9Un08gVHXMOXm5sLFxcXoThBRycUcISJjMEOI7J+tP55A9F3ylEol5syZg4oVK6JMmTK4ePEiAGD69On44osvjO4QERnGnm4rzhwhsj3Wvq24GMwQIttk7Rwx1+MJRBdM8+bNQ0JCAhYtWgRnZ2fN/Lp162LVqlUm6RQRGUCQiZusiDlCZIPEZogVc4QZQmSjzJwj1no8geiCae3atVi5ciX69u0LR0dHzfywsDCcPn3aqM4QkeHU44b1nayJOUJke8RmiDVzhBlCZJvMnSPJyclo0KABGjRoAODJ4wkaNGiAGTNmID09HT/99BOuXr2K+vXrw9/fXzMdPHjQqO0SfQ1Teno6qlatWmS+SqVCQUGBUZ0hIiPY+G3FC2OOENkgM99W3JSYIUQ2ysYfT2Ao0WeYateujf379xeZ//3332uqPSKyPHu59gBgjhDZImtfeyAGM4TINtlTjogh+gzTjBkzEBMTg/T0dKhUKvzwww84c+YM1q5di59//tkcfSQifVn5zJG+mCNENooZQkTGspMcEUP0GabOnTtjy5Yt2LVrF9zc3DBjxgycOnUKW7ZsQdu2bc3RRyLSgz0d0WGOENkeezoyzAwhsk32lCNiGPQcppdffhk7d+40dV+IyBh2dA0TwBwhsjl2dA0TwAwhskl2liP6MvjBtcnJyTh16hSAJ2OJGzZsaLJOEZEhZP+f9G1rfcwRIlsiJkPU7a2LGUJka+wvR/QhumC6evUqXn/9dfz+++8oW7YsAOD+/fto3rw5vvnmG1SqVMnUfSQifdjRGSbmCJENsqMjw8wQIhtlRzkihuhrmIYMGYKCggKcOnUKd+/exd27d3Hq1CmoVCoMGTLEHH0kIn0IIicrYo4Q2SCxGWLFHGGGENkoO8oRMUSfYdq3bx8OHjyIGjVqaObVqFEDS5Yswcsvv2zSzhGRCGKemG3liyyZI0Q2SEyGqNtbCTOEyEbZUY6IIbpgCggIKPahcEqlEgqFwiSdIiLxxDwx20zPddMbc4TI9ojJEHV7a2GGENkme8oRMUQPyVu8eDFGjRqF5ORkzbzk5GSMGTMG77//vkk7R0Qi2NEpcOYIkQ2yo6E0zBAiG2VHOSKGXmeYvLy8IJP9d8osJycHTZs2hZPTk7c/fvwYTk5OGDRoELp06WKWjhLRc9j4kDzmCJGNs/GhNMwQIjtg4zliKL0Kpvj4eDN3g4iMJROeTPq2tTTmCJFtE5Mh6vaWxAwhsn22niOG0qtgiomJMXc/iEjimCNEZAxmCBFZi8EPrgWA3Nxc5Ofna83z8PAwqkNEZCA7eg5TYcwRIhthp89PYYYQ2RA7zZHnEX3Th5ycHIwcORI+Pj5wc3ODl5eX1kREVqIeN6zvZEXMESIbJDZDrJgjzBAiG2VHOSKG6IJp8uTJ+O2337B8+XLI5XKsWrUKs2bNgkKhwNq1a83RRyLShx3dlYY5QmSD7OjuVswQIhtlRzkihugheVu2bMHatWsRHh6OgQMH4uWXX0bVqlURFBSE9evXo2/fvuboJxE9jx0NyWOOENkgOxpKwwwhslF2lCNiiD7DdPfuXVSuXBnAkzHCd+/eBQC89NJLSEpKMm3viEh/dnREhzlCZIPs6MgwM4TIRtlRjoghumCqXLkyUlNTAQA1a9bEt99+C+DJ0Z6yZcuatHNEJIIdjRlmjhDZIDu69oAZQmSj7ChHxBBdMA0cOBB//vknAGDq1KlYtmwZXFxcMG7cOEyaNMnkHSQi/aiffaDvJFZSUhKio6OhUCggk8mwefNmrdcFQcCMGTPg7+8PV1dXtGnTBufOnSt2WcwRItsjNkOs+fwUZgiRbTJ3jphyX0QM0dcwjRs3TvP/bdq0wenTp3Hs2DFUrVoV9erVM7pDRGQgM1/DlJOTg7CwMAwaNAjdunUr8vqiRYvwySefYM2aNQgJCcH06dMRGRmJf//9Fy4uLlptmSNENsiOrj1ghhDZKDPniCn3RcQw6jlMABAUFISgoCBjF0NENi4qKgpRUVHFviYIAuLj4/Hee++hc+fOAIC1a9fC19cXmzdvRu/evZ+5bOYIERmDGUJUMphzX+RZ9CqYPvnkE70XOHr0aIM7Y6jSW5LhJCtl8fWWNPuXpVi7CyVG1gMVvN4X9x4Z9D+1rR4xnJWVpTVfLpdDLpeLWzGA1NRUZGRkoE2bNpp5np6eaNq0KQ4dOoTevXvbfI6U+eEoc8QCdlxLsXYXSoSsByp4VRf3HjEZom5vSbaeIf6f/MEMsQBmiOVkPVDBS/8/OwCG54gp9kf02RcxlF4F00cffaTXwmQymVVCiogg7uLJ/7cLCAjQmj1z5kzExsaKXnVGRgYAwNfXV2u+r6+v5jXmCJGNE3sBtoUv1maGENkBA3PEFPsj+uyLGEqvgkl9JxoismEGXMOUlpYGDw8PzWxDzi7pizlCZONs/BomZgiRHTAwRyy5P2II0XfJIyIbZcBzDzw8PLQmQwPKz88PAHDjxg2t+Tdu3NC8RkQ2TqLPTyEiCzIwR0yxP2LOfREWTEQSYc3bAYeEhMDPzw+7d+/WzMvKysIff/yBZs2amXZlRGQW9nRbcSKyTdbMEXPuixh9lzwishFmvq14dnY2zp8/r/k5NTUVKSkp8Pb2RmBgIMaOHYu5c+eiWrVqmlt5KhQKdOnSRfzKiMjybHxIHhHZATPniLX2RVgwEUmFmQum5ORkREREaH4eP348ACAmJgYJCQmYPHkycnJy8Oabb+L+/ft46aWXsH37dqOee0BEFsSCiYiMZeYcsda+CAsmItJLeHg4BEF3sslkMsyePRuzZ8+2YK+IiIiopLDWvohB1zDt378f/fr1Q7NmzZCeng4AWLduHQ4cOGDSzhGR/uzt2gPmCJFtsbdrmJghRLbH3nJEX6ILpo0bNyIyMhKurq44ceIE8vLyAACZmZmYP3++yTtIRHpSP/tA38mKmCNENkhshlgxR5ghRDbKjnJEDNEF09y5c7FixQp8/vnnKFXqvydat2jRAsePHzdp54hIBDu6HTBzhMgGGXg7YH0lJSUhOjoaCoUCMpkMmzdv1l69IGDGjBnw9/eHq6sr2rRpg3PnzhW7LGYIkY0yc45Yi+iC6cyZM2jZsmWR+Z6enrh//74p+kREBrCnU+DMESLbY+6hNDk5OQgLC8OyZcuKfX3RokX45JNPsGLFCvzxxx9wc3NDZGQkcnNzi7RlhhDZJqkOyRN90wc/Pz+cP38ewcHBWvMPHDiAypUrm6pfRCSWme+SZ0rMESIbZOa7W0VFRSEqKqr4RQkC4uPj8d5776Fz584AgLVr18LX1xebN29G7969tdozQ4hslJlzxFpEn2EaOnQoxowZgz/++AMymQzXrl3D+vXrMXHiRLz11lvm6CMR6UPM0RwrBxRzhMgGiT0q/P8cycrK0prU1xOJkZqaioyMDLRp00Yzz9PTE02bNsWhQ4eKtGeGENkoA3PE1ok+wzR16lSoVCq0bt0aDx8+RMuWLSGXyzFx4kSMGjXKHH0kIn3Y0Rkm5giRDTLwyHBAQIDW7JkzZyI2NlbUqjMyMgAAvr6+WvN9fX01rxXGDCGyURI9wyS6YJLJZHj33XcxadIknD9/HtnZ2ahduzbKlCljjv4Rkb7sqGBijhDZIAN3dNLS0uDh4aGZLZfLTdqt4jBDiGwUCyZtzs7OqF27tin7QkRGEHPxpK1cZMkcIbIdYi/AVrf18PDQKpgM4efnBwC4ceMG/P39NfNv3LiB+vXr63wfM4TIthiaI7ZOdMEUEREBmUz3PdN/++03ozpERNLHHCGiwkJCQuDn54fdu3drCqSsrCz88ccfxV6TxAwhIksSXTA9faSnoKAAKSkp+PvvvxETE2OqfhGRWHY0JI85QmSDzDyUJjs7G+fPn9f8nJqaipSUFHh7eyMwMBBjx47F3LlzUa1aNYSEhGD69OlQKBTo0qVLkWUxQ4hsFIfkPfHRRx8VOz82NhbZ2dlGd4iIDGNPQ/KYI0S2x9xDaZKTkxEREaH5efz48QCAmJgYJCQkYPLkycjJycGbb76J+/fv46WXXsL27dvh4uJSZFnMECLbJNUheaJvK65Lv3798OWXX5pqcURkCEHPyUYxR4isTN8MMSBHwsPDIQhCkSkhIQHAkxs5zJ49GxkZGcjNzcWuXbtQvXp1UetghhDZADPmiLUYfNOHpx06dKjYo0BEZCF2NCRPF+YIkRVJYCgNM4TIyiSQI8URXTB169ZN62dBEHD9+nUkJydj+vTpJusYEYljT0PymCNEtseehtIwQ4hskz3liBiiCyZPT0+tnx0cHFCjRg3Mnj0b7dq1M1nHiEgkOzrDxBwhskF2dGSYGUJko+woR8QQVTAplUoMHDgQoaGh8PLyMlefiEjCmCNEZAxmCBFZmqibPjg6OqJdu3a4f/++mbpDRIZSnwbXd7IW5giRbRKbIdbKEWYIke2ylxwRS/Rd8urWrYuLFy+aoy9EZAwxd6WxckAxR4hskNgMsWKOMEOIbJQd5YgYogumuXPnYuLEifj5559x/fp1ZGVlaU1EZCV2FFDMESIbZEc7OswQIhtlRzkiht4F0+zZs5GTk4NXX30Vf/75Jzp16oRKlSrBy8sLXl5eKFu2LMcSE1mRPZwCZ44Q2S57GErDDCGybebMEaVSienTpyMkJASurq6oUqUK5syZA0EwfxjpfdOHWbNmYfjw4dizZ485+0NEhhJzpMZKBRNzhMiGiT3aa4UcYYYQ2Tgz5sjChQuxfPlyrFmzBnXq1EFycjIGDhwIT09PjB49WmxPRdG7YFJXb61atTJbZ4jICHZQMDFHiGyYHRRMzBAiG2dgjjw9lFYul0Mul2vNO3jwIDp37owOHToAAIKDg/H111/jyJEjRnRYP6KuYZLJZObqBxEZydaH0mj6yRwhskn2MCQPYIYQ2TJDcyQgIACenp6aKS4ursiymzdvjt27d+Ps2bMAgD///BMHDhxAVFSU2bdL1HOYqlev/tygunv3rlEdIiID2cEZJoA5QmSz7OAME8AMIbJpBuZIWloaPDw8NLOfPrsEAFOnTkVWVhZq1qwJR0dHKJVKzJs3D3379jWuz3oQVTDNmjWryNO1icg2iDnia80zTMwRItsk9qyRtXKEGUJkuwzNEQ8PD62CqTjffvst1q9fj8TERNSpUwcpKSkYO3YsFAoFYmJijOj184kqmHr37g0fHx9z9YWIjGEnZ5iYI0Q2yk7OMDFDiGyYGXNk0qRJmDp1Knr37g0ACA0NxeXLlxEXF2c7BRPHDBPZODsomJgjRDbMDgomZgiRjTNjjjx8+BAODtq3X3B0dIRKpRKxQsOIvkseEdkm2f8nfdtaA3OEyHaJyRB1e0tjhhDZNnPmSHR0NObNm4fAwEDUqVMHJ06cwIcffohBgwaJ7KV4ehdMlqjeiMgIdnCGiTlCZMPs4AwTM4TIxpkxR5YsWYLp06fj7bffxs2bN6FQKDBs2DDMmDFDbC9FE3UNExHZLnu56QMR2SZ7uekDEdkuc+aIu7s74uPjER8fL7pfxmLBRCQVdnCGiYhsmB2cYSIiGyfRHGHBRCQldhI8RGSjmCFEZCwJ5ggLJivpOfIGBr+TgU2fl8eKmRWt3R2799dhN3z3qQ/O/VUad2+UwswvUtE8KlOrzZVzcnwxV4GTh8tA+RgIqp6H6Z+nwqdSgZV6TSROvwkZ6D/hhta8tPNyDGlZ00o9kg5mCJUUdZtm47W3b6Fa6EOU83uM2EHBOLSdz7UyheflyL1bTvhingLH9rkjJ9MRdV/Mxoi5V1Gxcr4Ve036YMFkBdXDHqJDv7u4+I+LtbsiGbkPHVC5ziNEvn4XsweHFHn92iVnjO9SDe1730H/iRko7a7E5TMucHaRzmEQXsNUMlw67YKpvSprflYqeZtlU2CG8BqmksKltAoX/3HBjq+9MfPLS9bujqQ8K0cEAZg1KASOTgJiV19E6TIq/LCyAqb2qorP952GS2lp3NBEqjni8Pwm5pOUlITo6GgoFArIZDJs3rzZmt2xCJfSSkxZehnxkyrhQaajtbsjGY1feYABUzLQ4qkjwmoJC/zR5JUsDJl+HVVDH0ERnI9mkVkoW/6xhXtqRoLISQSlUonp06cjJCQErq6uqFKlCubMmWMTt/gtaTmiVAL3bpXSTFl3edzLFJghEJ8h1v/zN4mSliHJezywZpE/DvKsksk9K0fSL8px6pgbRi24ihr1HyGgah5GLbiKvFwZ9mwqa/nOmotEc8SqBVNOTg7CwsKwbNkya3bDokbOT8eR3R44sd/d2l0pMVQq4MhuD1SsnId3Xq+MnqF1MLpDNRz8RVr/WKiP6ug7ibFw4UIsX74cS5cuxalTp7Bw4UIsWrQIS5YsMc/GiFDScqRiSD4Sj/+DhEOnMGXpZVSoyKEc5sYMMU2O2KqSliFkHQX5T0YDOMv/O5Pk4ACUchbwz9Ey1uqWyUk1R6x6aDIqKgpRUVHW7IJFtep8D1VDH2HUq9Ws3ZUS5f5tJzzKccSGpT4YMCUDg9+9juQ97pg9JBiLvj+Pes1yrN1F0zDgLnlZWVlas+VyOeRyeZHmBw8eROfOndGhQwcAQHBwML7++mscOXLEiA6bRknKkdPHS+P9sQG4ekEOb58C9JtwAx9sOo9hETXwKIdnrM2FGfKM9hJQkjKErCegai58Kubjyzh/jFl4FS6lnwzJu33dGXdvSGikgERzxK5+Q3l5ecjLy9P8/PTOni2roMjHW7OvYVrvyijIs+qJvRJH+P/BnGaRWej25i0AQJW6j/Bvshu2ri0vmZ0dQ65hCggI0Jo/c+ZMxMbGFmnfvHlzrFy5EmfPnkX16tXx559/4sCBA/jwww+N7LXl2XOOJO/x0Px/6ilXnD7hhnVH/kXLTvex4+tyVuyZtDFDdLcview5Q8h6nEoBM75IxYfjA9GjdigcHAU0ePkBGr+SBRsY3W4yUs0RuyqY4uLiMGvWLGt3wyBV6z2CV4XHWLbjrGaeoxMQ+mIOOg28jY7B9aBS8eJtc/DwVsLRSUBQ9Vyt+QHVcvHPETcr9coMDDjDlJaWBg+P/3bCizu7BABTp05FVlYWatasCUdHRyiVSsybNw99+/Y1rs9WYM858rScLEdcvSiHIpjD8syJGfKM9iWQlDKELKtavUdYvusMcrIcUFAgQ9lySozuUA3V6z20dtdMR6I5YlenOqZNm4bMzEzNlJaWZu0u6S1lfxm8GVEdb7X9bzqT4orffvDCW22rs1gyo1LOAqqHPcTVC9rFQPpFubRuB2zARZYeHh5ak66C6dtvv8X69euRmJiI48ePY82aNXj//fexZs0ac2+VydlzjjzNpbQSiqB83L1pV8e+7A4z5BlTCSSlDCHrcPNQoWw5JdIvOuPcn6XRLFJCZyklmiN29a+srusr7MGjHEdcPuOqNS/3oQMe3Cs6n8R7lOOAa6n/fTcy0pxx4W9XuJd9DJ9KBXjt7ZuYPzwIdV/MRljzbCTv8cDhnZ5Y/P15K/batMx5W/FJkyZh6tSp6N27NwAgNDQUly9fRlxcHGJiYkT21LrsOUeGzriGw7964OZVZ5TzK0D/iRlQqoC9m7ys3TW7xwyR7lAaU7PnDAH+f6Al5L+z0n4B+ahc5xEe3HfErXRnK/bM/j0vR5K2eMKznBI+FfOResoFK2ZUQrP2mWgY/sCKvTYtqeaIXRVMRLqc/bM0Jveoqvn5s9gnDwNu2/MuJsZfQYuoTIxecBXfLPXF8umVUKnykwdO1m0qjWsPABg0JE9fDx8+hIOD9glpR0dHqFTSeG6EvSjvX4Bpn16Gu5cSmXec8M9RN4ztWA2ZvLW40ZghkOxQGtJWPewRFm+8oPl5+KxrAIBfN3jhg3GB1uqWJDwvR+7eKIXPYivi/m0nePs8RpvX7qLP2Bu6FmefJJojVv1XNjs7G+fP/3d0LjU1FSkpKfD29kZgoPT/aAv/UZFxwppnY8e1lGe2iXz9LiJfv2uZDlmBTBAg0/PKUX3bqUVHR2PevHkIDAxEnTp1cOLECXz44YcYNGiQIV01qZKUI3FvBVm7C5LFDBGXIer2UlCSMgQATh4qg0hFmLW7IUnPy5EuQ26jy5DbluuQFUg1R6xaMCUnJyMiIkLz8/jx4wEAMTExSEhIsFKviOyUGc8wLVmyBNOnT8fbb7+NmzdvQqFQYNiwYZgxY4bYXpocc4TIRCR6ZPh5mCFEJiTRHLFqwRQeHg7BTipLIltnzmuY3N3dER8fj/j4eNH9MjfmCJFpSPXag+dhhhCZjlRzhAPfiaTCjGeYiKgEkOiRYSKyIInmCAsmIokw5xkmIpI+qR4ZJiLLkWqOsGAikgqeYSIiY0j0yDARWZBEc4QFE5FE8AwTERlDqkeGichypJojDs9vQkR2QYJP1iYiCxKbIcwRInqamXMkPT0d/fr1Q7ly5eDq6orQ0FAkJyebrv86sGAiIiIis1MqlZg+fTpCQkLg6uqKKlWqYM6cObxDHRHp5d69e2jRogVKlSqFX375Bf/++y8++OADeHl5mX3dHJJHJCH2cmqbiGyTOTNk4cKFWL58OdasWYM6deogOTkZAwcOhKenJ0aPHm2+FRORRZkrRxYuXIiAgACsXr1aMy8kJMQ8K3sKzzARSYUgiJuIiAoTmyEic+TgwYPo3LkzOnTogODgYPTo0QPt2rXDkSNHzLRBRGRxBuZIVlaW1pSXl1dk0T/99BMaNWqE1157DT4+PmjQoAE+//xzi2wWCyYiiVBfaKnvRERUmNgMUeeIPjs6ANC8eXPs3r0bZ8+eBQD8+eefOHDgAKKioiy1iURkZobmSEBAADw9PTVTXFxckWVfvHgRy5cvR7Vq1bBjxw689dZbGD16NNasWWP27eKQPCKpEHPxJAsmInqa2AuwC+3oFDZz5kzExsYWaT516lRkZWWhZs2acHR0hFKpxLx589C3b1+Du0xENsbAHElLS4OHh4dmtlwuL9JUpVKhUaNGmD9/PgCgQYMG+Pvvv7FixQrExMQY0ennY8FEJBEy1ZNJ37ZERIWJyRB1e0C/HR0A+Pbbb7F+/XokJiaiTp06SElJwdixY6FQKMy+s0NElmFojnh4eGjlSHH8/f1Ru3ZtrXm1atXCxo0bxXZTNBZMRFLBM0xEZAwDjwzrs6MDAJMmTcLUqVPRu3dvAEBoaCguX76MuLg4FkxEUmFgjuijRYsWOHPmjNa8s2fPIigoSMQKDcOCiUgi+OBaIjKGuR84+fDhQzg4aF867ejoCJWKp7yJpMKcOTJu3Dg0b94c8+fPR8+ePXHkyBGsXLkSK1euFN9RkVgwEUmFmLtW8S55RPQ0sXe+E5kj0dHRmDdvHgIDA1GnTh2cOHECH374IQYNGiSyo0Rks8yYI40bN8amTZswbdo0zJ49GyEhIYiPj7fIdZAsmIgkgmeYiMgY5j7DtGTJEkyfPh1vv/02bt68CYVCgWHDhmHGjBniFkRENsvcOdKxY0d07NhR3JtMgAUTkVTwGiYiMoYZrz0AAHd3d8THxyM+Pl7cG4nIfpg5R6yFBRORRPAMExEZw9xHholI+qSaIyyYiKSC1zARkTHMfA0TEZUAEs0RFkxEEsEzTERkDKkeGSYiy5FqjrBgIpIKXsNERMaQ6LUHRGRBEs0RFkxEEsEzTERkDKkeGSYiy5FqjrBgIpIKlfBk0rctEVFhYjJE3Z6IqDCJ5ojD85sQERERERGVTDzDRCQVvIaJiIwh0WsPiMiCJJojLJiIJEIGEdcwmbUnRGSPxGSIuj0RUWFSzREWTERSwecwEZExJPr8FCKyIInmCAsmIongXfKIyBhSvbsVEVmOVHOEBRORVPAaJiIyhkSvPSAiC5JojrBgIpIImSBApuepbX3bEVHJISZD1O2JiAqTao6wYCKSCtX/J33bEhEVJiZD1O2JiAqTaI6wYCKSCJ5hIiJjSPXIMBFZjlRzhAUTkVTwGiYiMoZErz0gIguSaI6wYCKSCt5WnIiMIdHbARORBUk0R1gwEUkEbytORMaQ6u2AichypJojDtbuABGZiPqojr6TSOnp6ejXrx/KlSsHV1dXhIaGIjk52QwbQkRWITZD7OTIMBFZkAVzZMGCBZDJZBg7dqzp+q8DzzARSYRM9WTSt60Y9+7dQ4sWLRAREYFffvkFFSpUwLlz5+Dl5SW+o0Rkk8RkiLo9EVFhlsqRo0eP4rPPPkO9evUMW4BILJiIpMKM1zAtXLgQAQEBWL16tWZeSEiIqGUQkY2T6LUHRGRBFsiR7Oxs9O3bF59//jnmzp0r+v2GsOuCSfj/h/wYBXZzlw17lvWAhxMtJSv7yWctiAodiL5LXlZWltZsuVwOuVxepPlPP/2EyMhIvPbaa9i3bx8qVqyIt99+G0OHDtW/fzaKOWJZzBHLMHuGqNsTM8TCmCGWY8kc0Xd/BABGjBiBDh06oE2bNiyY9PHgwQMAwAFss3JPSgav6tbuQcnz4MEDeHp66tXWkOcwBQQEaM2fOXMmYmNji7S/ePEili9fjvHjx+Odd97B0aNHMXr0aDg7OyMmJkavddoq5ohlMUcsy1wZom5PzBBLY4ZYniVyRN/9kW+++QbHjx/H0aNH9V6HKdh1waRQKJCWlgZ3d3fIZDJrd0dvWVlZCAgIQFpaGjw8PKzdHUmz189aEAQ8ePAACoXCrOt5+nPRdTRHpVKhUaNGmD9/PgCgQYMG+Pvvv7FixQq7L5jsMUfs9Xttj+z1s7ZUhpB9Zghgv99te2Svn7Ulc0Sf/ZG0tDSMGTMGO3fuhIuLi9n7VJhdF0wODg6oVKmStbthMA8PD7v6w7Fn9vhZ63s0R8OAa5j0/Vz8/f1Ru3ZtrXm1atXCxo0bxfXRBtlzjtjj99pe2eNnbdYMUbcnu84QwD6/2/bKHj9rS+WIPp/NsWPHcPPmTbzwwguaeUqlEklJSVi6dCny8vLg6Ogorr96suuCiYgKEQDoO7Rb5H5OixYtcObMGa15Z8+eRVBQkLgFEZHtEpMh6vZERIWZMUdat26Nv/76S2vewIEDUbNmTUyZMsVsxRLAgolIMgy5hklf48aNQ/PmzTF//nz07NkTR44cwcqVK7Fy5UpDukpENojXMBGRscyZI+7u7qhbt67WPDc3N5QrV67IfFPjg2utQC6XY+bMmTqvFyHTKVGftQARD4oTt+jGjRtj06ZN+Prrr1G3bl3MmTMH8fHx6Nu3r1k2hZ6tRH2vraxEfdaiMkR8jpBtKVHfbSsrUZ+1RHNEJoi6VyAR2ZqsrCx4enrilbApcHLUL4wfK/Pw258LkZmZaXfjqYnItAzJEIA5QkT/kXqOcEgekVSoAOh7gyY+xoKIniYmQ9TtiYgKk2iOsGAikghzXsNERNLHa5iIyFhSzREWTERSYcBtxYmINHhbcSIylkRzhAUTkVSwYCIiY0h0R4eILEiiOcKCiUgqWDARkTEkuqNDRBYk0RzhbcUtbNmyZQgODoaLiwuaNm2KI0eOWLtLkpSUlITo6GgoFArIZDJs3rzZ2l0yP5XIiewWc8QySlyOiM0Q5ojdYoZYRonLEECyOcKCyYI2bNiA8ePHY+bMmTh+/DjCwsIQGRmJmzdvWrtrkpOTk4OwsDAsW7bM2l2xGPWFlvpOZJ+YI5ZT0nJEbIYwR+wTM8RySlqGANLNET6HyYKaNm2Kxo0bY+nSpQAAlUqFgIAAjBo1ClOnTrVy76RLJpNh06ZN6NKli7W7YhbqZx+0qTZO1HOYdp37yOafe0BFMUesQ8o5YkiGAMwRe8UMsQ4pZwgg/RzhGSYLyc/Px7Fjx9CmTRvNPAcHB7Rp0waHDh2yYs9IMlSCuInsDnOEzEpshjBH7A4zhMxOojnCgslCbt++DaVSCV9fX635vr6+yMjIsFKvSFLUF1rqO5HdYY6QWYnNEOaI3WGGkNlJNEdYMBFJhphwso+AIiJLEruTIz5H0tPT0a9fP5QrVw6urq4IDQ1FcnKy6TeFiKzE/DliDbytuIWUL18ejo6OuHHjhtb8GzduwM/Pz0q9IiJ7whwhe3bv3j20aNECERER+OWXX1ChQgWcO3cOXl5e1u5aicEMITIMzzBZiLOzMxo2bIjdu3dr5qlUKuzevRvNmjWzYs9IMiR4Cpy0MUfIrAwcSpOVlaU15eXlFbv4hQsXIiAgAKtXr0aTJk0QEhKCdu3aoUqVKpbcyhKNGUJmJ9EheTzDZEHjx49HTEwMGjVqhCZNmiA+Ph45OTkYOHCgtbsmOdnZ2Th//rzm59TUVKSkpMDb2xuBgYFW7JkZqUSc2raTiyypKOaI5ZS4HBGTIZr2QEBAgNbsmTNnIjY2tkjzn376CZGRkXjttdewb98+VKxYEW+//TaGDh1qRKdJLGaI5ZS4DAEMzhFbx4LJgnr16oVbt25hxowZyMjIQP369bF9+/YiF1+S8ZKTkxEREaH5efz48QCAmJgYJCQkWKlXZiaonkz6tiW7xByxnBKXI2IyRN0eQFpamtbtgOXy4m8pfPHiRSxfvhzjx4/HO++8g6NHj2L06NFwdnZGTEyMUV0n/TFDLKfEZQhgcI7YOj6HicjOaZ59EPAWnBz0fA6TKg+70pbb/HMPiMj8DMkQQHyOODs7o1GjRjh48KBm3ujRo3H06FHe0prIzlkqR6yF1zARSYUEn3tARBZk5uen+Pv7o3bt2lrzatWqhStXrphyK4jImiT6HCYOySOSCjEXT/LEMhE9TewF2CJzpEWLFjhz5ozWvLNnzyIoKEjUcojIhpk5R6yFBRORVAgQUTCZtSdEZI/EZIi6vQjjxo1D8+bNMX/+fPTs2RNHjhzBypUrsXLlSnELIiLbZeYcsRYOySOSCgnexpOILMjMtwNu3LgxNm3ahK+//hp169bFnDlzEB8fj759+5ppg4jI4syYI3FxcWjcuDHc3d3h4+ODLl26FDlrbS48w0QkFSoVAD3vNqOyj7vSEJEFickQTXtxOnbsiI4dO4p+HxHZCTPmyL59+zBixAg0btwYjx8/xjvvvIN27drh33//hZubm/i+isCCiUgqeA0TERlDotceEJEFmTFHtm/frvVzQkICfHx8cOzYMbRs2VL/dRqABRORVLBgIiJjsGAiImMZmCNZWVlas+Vyuc5nuqllZmYCALy9vcX10QC8hkliBgwYgC5dumh+Dg8Px9ixYy3ej71790Imk+H+/fs628hkMmzevFnvZcbGxqJ+/fpG9evSpUuQyWRISUkxajk2SYK38STLY4Y8GzOEOULPxxx5NuZI0RwJCAiAp6enZoqLi3v2alQqjB07Fi1atEDdunXNvlksmCxgwIABkMlkkMlkcHZ2RtWqVTF79mw8fvzY7Ov+4YcfMGfOHL3a6hMsZLsEQSVqIvvBDCFLEJshzBH7whwhSzA0R9LS0pCZmamZpk2b9sz1jBgxAn///Te++eYbS2wWh+RZSvv27bF69Wrk5eVh27ZtGDFiBEqVKlXsFyI/Px/Ozs4mWa8lTlOSjRBEHPHlUBq7wwwhsxOTIer2ZFeYI2R2BuaIh4cHPDw89HrLyJEj8fPPPyMpKQmVKlUypJei8QyThcjlcvj5+SEoKAhvvfUW2rRpg59++gnAf6eu582bB4VCgRo1agB4Um337NkTZcuWhbe3Nzp37oxLly5plqlUKjF+/HiULVsW5cqVw+TJkyE89Q/Y06fB8/LyMGXKFAQEBEAul6Nq1ar44osvcOnSJURERAAAvLy8IJPJMGDAAABPTnvGxcUhJCQErq6uCAsLw/fff6+1nm3btqF69epwdXVFRESEVj/1NWXKFFSvXh2lS5dG5cqVMX36dBQUFBRp99lnnyEgIAClS5dGz549NWNY1VatWoVatWrBxcUFNWvWxKeffiq6L3aJtxWXNGbI8zFDjGTm24qT9TFHno85YiQz5oggCBg5ciQ2bdqE3377DSEhIWbcEG08w2Qlrq6uuHPnjubn3bt3w8PDAzt37gQAFBQUIDIyEs2aNcP+/fvh5OSEuXPnon379jh58iScnZ3xwQcfICEhAV9++SVq1aqFDz74AJs2bcIrr7yic71vvPEGDh06hE8++QRhYWFITU3F7du3ERAQgI0bN6J79+44c+YMPDw84OrqCuDJfe+/+uorrFixAtWqVUNSUhL69euHChUqoFWrVkhLS0O3bt0wYsQIvPnmm0hOTsaECRNEfybu7u5ISEiAQqHAX3/9haFDh8Ld3R2TJ0/WtDl//jy+/fZbbNmyBVlZWRg8eDDefvttrF+/HgCwfv16zJgxA0uXLkWDBg1w4sQJDB06FG5uboiJiRHdJ7uiUgEyPYfIcCiN3WOGFMUMMZKYDAGYIxLAHCmKOWIkM+bIiBEjkJiYiB9//BHu7u7IyMgAAHh6emq+J2YjkNnFxMQInTt3FgRBEFQqlbBz505BLpcLEydO1Lzu6+sr5OXlad6zbt06oUaNGoJKpdLMy8vLE1xdXYUdO3YIgiAI/v7+wqJFizSvFxQUCJUqVdKsSxAEoVWrVsKYMWMEQRCEM2fOCACEnTt3FtvPPXv2CACEe/fuaebl5uYKpUuXFg4ePKjVdvDgwcLrr78uCIIgTJs2Tahdu7bW61OmTCmyrKcBEDZt2qTz9cWLFwsNGzbU/Dxz5kzB0dFRuHr1qmbeL7/8Ijg4OAjXr18XBEEQqlSpIiQmJmotZ86cOUKzZs0EQRCE1NRUAYBw4sQJneu1N5mZmQIAoXWZPkKk+wC9ptZl+ggAhMzMTGt3n/TADCkeM8Q0DMkQ5oj9YY4UjzliGpbIEQDFTqtXrzb79vEMk4X8/PPPKFOmDAoKCqBSqdCnTx/ExsZqXg8NDdUaK/znn3/i/PnzcHd311pObm4uLly4gMzMTFy/fh1NmzbVvObk5IRGjRoVORWulpKSAkdHR7Rq1Urvfp8/fx4PHz5E27Zttebn5+ejQYMGAIBTp05p9QMAmjVrpvc61DZs2IBPPvkEFy5cQHZ2Nh4/flxkPGtgYCAqVqyotR6VSoUzZ87A3d0dFy5cwODBgzF06FBNm8ePH8PT01N0f4hsCTPk+ZghRM/GHHk+5ojt0vWdsgQWTBYSERGB5cuXw9nZGQqFAk5O2h/9008ozs7ORsOGDTWndwurUKGCQX0w5HRldnY2AGDr1q1a4QDguffHF+PQoUPo27cvZs2ahcjISHh6euKbb77BBx98ILqvn3/+eZHQdHR0NFlfbZWgUkHQ8zQ4725lf5ghz8YMMZ6YDAGYI/aIOfJszBHjSTVHWDBZiJubG6pWrap3+xdeeAEbNmyAj4+PzruG+Pv7448//tA83fjx48c4duwYXnjhhWLbh4aGQqVSYd++fWjTpk2R19VHlZRKpWZe7dq1IZfLceXKFZ1Hg2rVqqW5aFTt8OHDz9/IQg4ePIigoCC8++67mnmXL18u0u7KlSu4du0aFAqFZj0ODg6oUaMGfH19oVAocPHiRfTt21fU+iVBc7Za37ZkT5ghz8YMMQExGaJpT/aEOfJszBETkGiO8C55Nqpv374oX748OnfujP379yM1NRV79+7F6NGjcfXqVQDAmDFjsGDBAmzevBmnT5/G22+//cznFgQHByMmJgaDBg3C5s2bNcv89ttvAQBBQUGQyWT4+eefcevWLWRnZ8Pd3R0TJ07EuHHjsGbNGly4cAHHjx/HkiVLsGbNGgDA8OHDce7cOUyaNAlnzpxBYmIiEhISRG1vtWrVcOXKFXzzzTe4cOECPvnkE2zatKlIOxcXF8TExODPP//E/v37MXr0aPTs2RN+fn4AgFmzZiEuLg6ffPIJzp49i7/++gurV6/Ghx9+KKo/dokPnKRCmCHMENH44Fp6CnOEOSKaRHOEBZONKl26NJKSkhAYGIhu3bqhVq1aGDx4MHJzczVHeSZMmID+/fsjJiYGzZo1g7u7O7p27frM5S5fvhw9evTA22+/jZo1a2Lo0KHIyckBAFSsWBGzZs3C1KlT4evri5EjRwIA5syZg+nTpyMuLg61atVC+/btsXXrVs3tHAMDA7Fx40Zs3rwZYWFhWLFiBebPny9qezt16oRx48Zh5MiRqF+/Pg4ePIjp06cXaVe1alV069YNr776Ktq1a4d69epp3apzyJAhWLVqFVavXo3Q0FC0atUKCQkJFr31pNUIwpO7zeg12UdAkeGYIcwQ0URlCHOkJGCOMEdEk2iOyARrXkFFREbLysqCp6cnIpx6wElWSq/3PBYKsOfx98jMzNT7QXGFLViwANOmTcOYMWMQHx8v+v1EZDsMyRDA+BwhIumQeo7wGiYiqRBUAMz/HKajR4/is88+Q7169QxeBhHZIDEZomlPRFSIRHOEQ/KIJEJQCaImQ2RnZ6Nv3774/PPP4eXlZeItICJrEpshhuYIEUmXVHOEZ5iIJOKxkKf3kZrHKADw5BR6YXK5/Jm3aB0xYgQ6dOiANm3aYO7cuYZ3lohsjpgMAf7LESIiNanmCAsmIjvn7OwMPz8/HMjYJup9ZcqUQUBAgNa8mTNnaj3EsLBvvvkGx48fx9GjRw3tKhHZIEMzBAD8/Py0HnRKRCWT1HOEBRORnXNxcUFqairy8/NFvU8QBMhkMq15us4upaWlYcyYMdi5cydcXFwM7isR2R5DMwR4spPETCAiqecI75JHRM+1efNmdO3aVesp5UqlEjKZDA4ODsjLyysRTzAnIiKikocFExE914MHD4o87XzgwIGoWbMmpkyZgrp161qpZ0RERETmxSF5RPRc7u7uRYoiNzc3lCtXjsUSERERSRpvK05ERERERKQDh+QRERERERHpwDNMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwURERERERKQDCyYiIiIiIiIdWDARERERERHpwIKJiIiIiIhIBxZMREREREREOrBgIiIiIiIi0oEFExERERERkQ4smIiIiIiIiHRgwUREeklKSkJ0dDQUCgVkMhk2b96s9fqAAQMgk8m0pvbt21uns0Rkc56XIYUNHz4cMpkM8fHxFusfEdm2uLg4NG7cGO7u7vDx8UGXLl1w5swZrTbh4eFF9kWGDx9u9LpZMBGRXnJychAWFoZly5bpbNO+fXtcv35dM3399dcW7CER2TJ9MgQANm3ahMOHD0OhUFioZ0RkD/bt24cRI0bg8OHD2LlzJwoKCtCuXTvk5ORotRs6dKjWvsiiRYuMXreT0UsgIqvLzc1Ffn6+qPcIggCZTKY1Ty6XQy6XF9s+KioKUVFRz1ymXC6Hn5+fqH4QkfUZkiGAuBzRJ0PS09MxatQo7NixAx06dBDdHyKyHnPnyPbt27V+TkhIgI+PD44dO4aWLVtq5pcuXdrk+yIsmIjsXG5uLkKCyiDjplLU+8qUKYPs7GyteTNnzkRsbKzBfdm7dy98fHzg5eWFV155BXPnzkW5cuUMXh4RmZ+hGQKYNkdUKhX69++PSZMmoU6dOqLfT0TWY40cyczMBAB4e3trzV+/fj2++uor+Pn5ITo6GtOnT0fp0qVF96swFkxEdi4/Px8ZN5VIPRYED3f9RtlmPVAhpOFlpKWlwcPDQzNf19klfbRv3x7dunVDSEgILly4gHfeeQdRUVE4dOgQHB0dDV4uEZmXIRkCmD5HFi5cCCcnJ4wePdqg9xOR9Vg6R1QqFcaOHYsWLVqgbt26mvl9+vRBUFAQFAoFTp48iSlTpuDMmTP44YcfxG9UISyYiCTCw91BVEgBgIeHh1ZAGaN3796a/w8NDUW9evVQpUoV7N27F61btzbJOojIfAzJEMA0OXLs2DF8/PHHOH78eJGhOURkPyyVIyNGjMDff/+NAwcOaM1/8803Nf8fGhoKf39/tG7dGhcuXECVKlVE90uNN30gkgiloBI1mVvlypVRvnx5nD9/3uzrIiLjic0QU+bI/v37cfPmTQQGBsLJyQlOTk64fPkyJkyYgODgYJOth4jMyxI5MnLkSPz888/Ys2cPKlWq9My2TZs2BQCj90V4holIIlQQoIKgd1tzu3r1Ku7cuQN/f3+zr4uIjCcmQ9TtTaV///5o06aN1rzIyEj0798fAwcONNl6iMi8zJkjgiBg1KhR2LRpE/bu3YuQkJDnviclJQUAjN4XYcFEJBEqqKDvcRr9W/4nOztb6whNamoqUlJS4O3tDW9vb8yaNQvdu3eHn58fLly4gMmTJ6Nq1aqIjIwUvS4isjwxGaJuL8azMiQwMLDIDWJKlSoFPz8/1KhRQ9R6iMh6zJkjI0aMQGJiIn788Ue4u7sjIyMDAODp6QlXV1dcuHABiYmJePXVV1GuXDmcPHkS48aNQ8uWLVGvXj2RW6KNBRORRCgFAUpBvyM1+rYrLDk5GREREZqfx48fDwCIiYnB8uXLcfLkSaxZswb379+HQqFAu3btMGfOHKNuJEFEliMmQ9TtxXhWhiQkJIhaFhHZJnPmyPLlywE8eThtYatXr8aAAQPg7OyMXbt2IT4+Hjk5OQgICED37t3x3nvv6b0OXVgwEUmEuYfkhYeHQ3hGsO3YsUP0MonIdph7SN7zMuRply5dErV8IrI+cw/Je5aAgADs27dP7+WJwYKJSCJUEKC0oWuYiMi+iMkQdXsiosKkmiMsmIgkwtZu+kBE9sWaN30gImmQao6wYCKSCHNfw0RE0mbua5iISPqkmiMsmIgkQvX/Sd+2RESFickQdXsiosKkmiMsmIgkQili3LCY8cVEVDKIyRB1eyKiwqSaIyyYiCRCKTyZ9G1LRFSYmAxRtyciKkyqOcKCiUgiOCSPiIwh1aE0RGQ5Us0RFkxEEqGCDErI9G5LRFSYmAxRtyciKkyqOcKCiUgiVMKTSd+2RESFickQdXsiosKkmiMsmIgkQiniqI6Yoz9EVDKIyRB1eyKiwqSaIyyYiCSCBRMRGUOqOzpEZDlSzREHa3eAiIiIiIjIVvEME5FEqAQZVIKeN33Qsx0RlRxiMkTdnoioMKnmCAsmIongkDwiMoZUh9IQkeVINUdYMBFJhBIOUOo5ylZp5r4Qkf0RkyFP2hMRaZNqjrBgIpIIQcRpcMFOToETkeWIyRB1eyKiwqSaI7zpg4QdPXoUI0eORJ06deDm5obAwED07NkTZ8+eLdL21KlTaN++PcqUKQNvb2/0798ft27dKtJu3rx56NSpE3x9fSGTyRAbG1vsumNjYyGTyYpMLi4upt5M+j/1aXB9JyJ9WDNH1DZs2IBmzZrBzc0NZcuWRfPmzfHbb7+ZahPp/8RmCHOE9GXNHAkODi52f0Qmk6FatWqm3tQST6o5wjNMErZw4UL8/vvveO2111CvXj1kZGRg6dKleOGFF3D48GHUrVsXAHD16lW0bNkSnp6emD9/PrKzs/H+++/jr7/+wpEjR+Ds7KxZ5nvvvQc/Pz80aNAAO3bseG4fli9fjjJlymh+dnR0NP2GEgBAKThAKeg5JM9OHhRH1mftHImNjcXs2bPRo0cPDBgwAAUFBfj777+Rnp5u1u0uicRkyJP2ZuwMSYo1cyQ+Ph7Z2dla8y5fvoz33nsP7dq1M88Gl2BSzREWTBI2fvx4JCYmagVMr169EBoaigULFuCrr74CAMyfPx85OTk4duwYAgMDAQBNmjRB27ZtkZCQgDfffFPz/tTUVAQHB+P27duoUKHCc/vQo0cPlC9f3sRbRsVRQQaVnieNVbCThCKrs2aOHD58GLNnz8YHH3yAcePGmWkLSU1Mhjxpzxwh/VgzR7p06VJk3ty5cwEAffv2NcXmUSFSzREOyZOw5s2ba4UTAFSrVg116tTBqVOnNPM2btyIjh07asIJANq0aYPq1avj22+/1Xp/cHCwqD4IgoCsrCwIgn38Qdgzc58CT0pKQnR0NBQKBWQyGTZv3qyz7fDhwyGTyRAfH2/4BpFNsGaOxMfHw8/PD2PGjIEgCEWOEpNpSXUoDVmfLeyPFJaYmIiQkBA0b97c4GVQ8aSaIyyYShhBEHDjxg3NWZ/09HTcvHkTjRo1KtK2SZMmOHHihFHrq1y5Mjw9PeHu7o5+/frhxo0bRi2PdFOfBtd3EisnJwdhYWFYtmzZM9tt2rQJhw8fhkKhMHRTyMZZKkd2796Nxo0b45NPPkGFChXg7u4Of39/LF261Kj+U/HEZoghOUKkZun9EbUTJ07g1KlT6NOnj0mWR9qkmiMcklfCrF+/Hunp6Zg9ezYA4Pr16wAAf3//Im39/f1x9+5d5OXlQS6Xi1qPl5cXRo4ciWbNmkEul2P//v1YtmwZjhw5guTkZHh4eBi/MaTlyWlwPR9ca8ARnaioKERFRT2zTXp6OkaNGoUdO3agQ4cOotdB9sESOXLv3j3cvn0bv//+O3777TfMnDkTgYGBWL16NUaNGoVSpUph2LBhptkgAiAuQ9TtiQxlqf2R4tYLcDieuUg1R1gwlSCnT5/GiBEj0KxZM8TExAAAHj16BADFBpD6jnaPHj0SHVBjxozR+rl79+5o0qQJ+vbti08//RRTp041ZBPoGVQinn2gHjOclZWlNV8ulxv8j5FKpUL//v0xadIk1KlTx6BlkO2zVI6oh9/duXMH33zzDXr16gXgyXWRoaGhmDt3LgsmExOTIU/ac6g1GcaS+yOFqVQqfPPNN2jQoAFq1apl8HJIN6nmiH2cByOjZWRkoEOHDvD09MT333+vuVudq6srACAvL6/Ie3Jzc7XaGKtPnz7w8/PDrl27TLI80mbIKfCAgAB4enpqpri4OIPXv3DhQjg5OWH06NGm2iSyMZbMEXX7UqVKoUePHpr5Dg4O6NWrF65evYorV64YtB1UPKkOpSHbYs39kX379iE9PZ1nl8xIqjnCM0wlQGZmJqKionD//n3s379f69oS9alv9anwwq5fvw5vb2+jT38XFhAQgLt375psefQfFRxE3yUvLS1Na3ikob/rY8eO4eOPP8bx48chk9nH6XUSx9I54u3tDRcXF5QtW7bI4wh8fHwAPBm2V/jicDKOmAx50t4+jgyT7bD2/sj69evh4OCA119/3ajlkG5SzRH7KOvIYLm5uYiOjsbZs2fx888/o3bt2lqvV6xYERUqVEBycnKR9x45cgT169c3WV8EQcClS5f0uh05iacUZKImAPDw8NCaDP3HaP/+/bh58yYCAwPh5OQEJycnXL58GRMmTDDqTkZkG6yRIw4ODqhfvz5u3bqF/Px8rdeuXbsGAMwSExObIeocIdKHtfdH8vLysHHjRoSHh/OmRGYk1RxhwSRhSqUSvXr1wqFDh/Ddd9+hWbNmxbbr3r07fv75Z6SlpWnm7d69G2fPnsVrr71m0LqLeyr38uXLcevWLbRv396gZdKzKf8/bljfyZT69++PkydPIiUlRTMpFApMmjRJrwcck+2yZo706tULSqUSa9as0czLzc3F+vXrUbt2be70mJjYDDF1jpB0WTNH1LZt24b79+9zOJ6ZSTVHOCRPwiZMmICffvoJ0dHRuHv3rubBcGr9+vUDALzzzjv47rvvEBERgTFjxiA7OxuLFy9GaGgoBg4cqPWedevW4fLly3j48CGAJ8/mUT8Arn///ggKCgIABAUFaR5K5+LiggMHDuCbb75B/fr1eaG2magEB6j0HAusMuC5WNnZ2Th//rzm59TUVKSkpMDb2xuBgYEoV66cVvtSpUrBz88PNWrUEL0ush3WzJFhw4Zh1apVGDFiBM6ePYvAwEDNe7ds2WLuTS9xxGTIk/b2MZSGrM+aOaK2fv16yOVydO/e3VybSZBujsgEPlFUssLDw7Fv3z6drxf+1f/zzz8YP348Dhw4AGdnZ3To0AEffPABfH199V7mnj17EB4eDgAYOnQoDh48iLS0NOTm5iIoKAjdu3fHu+++C3d3d+M3jjSysrLg6emJz483RGl3x+e/AcDDB0oMfeEYMjMz9b7F+969exEREVFkfkxMDBISEorMDw4OxtixYzF27Fi9lk+2yZo5AgA3b97E5MmTsWXLFuTk5KB+/fqYNWsWIiMjjdsw0jAkQwDDcoRKJmvnSFZWFnx9ffHqq69i48aNxm0MFUvqOcKCicjOWapgIiJpkvqODhGZn9RzhEPyiCRCBeh98aTKvF0hIjskJkPU7YmICpNqjrBgIpIIcbcVt4+LLInIcsTfDpg5QkTapJojLJiIJELMA+Ds5UFxRGQ5Yh8iyRwhoqdJNUdYMBFJhAoyqKDvkDz7eO4BEVmOmAxRtyciKkyqOcKCiUgieIaJiIwh1SPDRGQ5Us0RFkxEEiHmAXD28qA4IrIcsQ+RZI4Q0dOkmiN2XTCpVCpcu3YN7u7ukMns45QekT4EQcCDBw+gUCjg4KDvw2hlUOl7lzwRd7CROuYISZG5M0TdnpghJF3Mkf/YdcF07do1BAQEWLsbRGaTlpaGSpUq6dVWJeKojr3clcYSmCMkZebKEHV7YoaQ9DFH7Lxgcnd3BwC0qvwWnBzkVu6N9D0K9rJ2F0qMx49zcWRvnOY7rg+V4ACVnmOB9W1XEqg/4wbR78GxlIuVeyN9c2JXWbsLJUJOtgo9ml8xW4ao24uRlJSExYsX49ixY7h+/To2bdqELl26AAAKCgrw3nvvYdu2bbh48SI8PT3Rpk0bLFiwAAqFQtR6LE39Gb+EV+GEUlbujfSlTWtq7S6UGKq8XKR+ONumcsRa7LpgUp/6dnKQw8mRBZO5OXFn0uLEDO9QQgalnneb0bddSaD+jB1LufA7bgFu7vbxj6NUmCtD1O3FyMnJQVhYGAYNGoRu3bppvfbw4UMcP34c06dPR1hYGO7du4cxY8agU6dOSE5OFrUeS9Psi6AUnGQsmMzN0YU5bWm2lCPWYtcFExH9h2eYiMgY5j4yHBUVhaioqGJf8/T0xM6dO7XmLV26FE2aNMGVK1cQGBgoal1EZB08w0RENk0J/Y/UKM3bFSKyQ2IyRN0eALKysrTmy+VyyOXGj/rIzMyETCZD2bJljV4WEVmGoTli6+yjrCOi51If1dF3IiIqTGyGqHMkICAAnp6emikuLs7ovuTm5mLKlCl4/fXX4eHhYfTyiMgyDM0RW2cfvSSi51I/LE7fiYioMLEZos6RtLQ0ZGZmaqZp06YZ1Y+CggL07NkTgiBg+fLlptg0IrIQQ3NEH3FxcWjcuDHc3d3h4+ODLl264MyZM1ptcnNzMWLECJQrVw5lypRB9+7dcePGDaO3i3tNRBIhQAaVnpNgJxdZEpHliMmQwjni4eGhNRkzHE9dLF2+fBk7d+7k2SUiO2Nojuhj3759GDFiBA4fPoydO3eioKAA7dq1Q05OjqbNuHHjsGXLFnz33XfYt28frl27VuQmM4bgNUxEEiHmSA3PMBHR08Qe7TV1jqiLpXPnzmHPnj0oV66cSZdPROZnzhzZvn271s8JCQnw8fHBsWPH0LJlS2RmZuKLL75A4v/Yu/OwqOr9D+DvAWRAhRFENgXF3Dc0TUOt5EYSGWlWLlkhlt1MK+W6USm40nKvkWWaZi7dTP2Vel1Kr5FL5hYYlTdFUVRcwAUBQWWZOb8/aCZHBp0z25lz5v16nvPcO2e+M/MZH3033/NdzqpV+Nvf/gYAWLZsGdq3b4/9+/fj/vvvN/uzbscOExEREdldWVkZcnNzDY/z8vKQnZ0Nf39/hISE4Omnn8ahQ4ewefNmaLVaFBQUAAD8/f3h6ekpVdlE5ACWbB5TUlICoCYjACArKwtVVVWIiYkxtGnXrh3Cw8Oxb98+qzpMvMxMpBA6QSXqICK6ldgMEZsjmZmZ6NatG7p16wYASEpKQrdu3TB9+nScO3cOGzduxNmzZ9G1a1eEhIQYjr1799rj6xKRHViaI2I3j9HpdBg/fjz69OmDTp06AQAKCgrg6elZa2fNoKAgwwUYS3GEiUghtHCD1sxrIOa2IyLXISZD9O3F6NevHwRBqPP5Oz1HRPJgaY7k5+cbrVm82+jS2LFjcfjwYezZs8eyQkXiryYihbD3CNPu3bsRHx+P0NBQqFQqbNiwwej51NRUtGvXDg0aNICfnx9iYmJw4MABG307IrI3e48wEZHyWZojYjaPGTduHDZv3owdO3agWbNmhvPBwcGorKxEcXGxUfvCwkIEBwdb9b3YYSJSCB3cRB1ilZeXIzIyEgsWLDD5fJs2bfDxxx/j999/x549e9CiRQv0798fly5dsvarEZEDiM0QS3KEiJTNnjkiCALGjRuH9evX44cffkBERITR8927d0e9evWQkZFhOJeTk4MzZ84gKirKqu/FKXlECqEVVNCaecXX3Ha3iouLQ1xcXJ3PP/vss0aP582bh6VLl+K3337Dww8/LPrziMixxGSIvj0R0a3smSNjx47FqlWr8J///Ac+Pj6GdUkajQbe3t7QaDR48cUXkZSUBH9/f/j6+uK1115DVFSUVRs+AOwwESmGmCky+naW7EpjjsrKSixevBgajQaRkZFWvx8R2Z/YaXackkdEt7NnjuhvZN2vXz+j88uWLcPIkSMBAB988AHc3Nzw1FNPoaKiArGxsfjkk0/M/oy6sMNEpBCC4AadmfczEP5sFxYWZnQ+JSUFqampFtewefNmDBs2DNevX0dISAi2b9+OgIAAi9+PiBxHTIbo2xMR3cqeOWLOxjBeXl5YsGBBncsHLMUOE5FCaKGC1sw7Zuvbid2V5m6io6ORnZ2Ny5cvY8mSJRgyZAgOHDiAwMBAq96XiOxPTIbo2xMR3UqpOcLLQ0QKoRPE7E5T8xoxu9KYo0GDBmjVqhXuv/9+LF26FB4eHli6dKkNvh0R2Zu4DPkrR4iI9JSaIxxhIlIInYhhcDHD5dbQ6XSoqKhwyGcRkXXEZIi+PRHRrZSaI+wwESmEDirozBzaNrfdrcrKypCbm2t4nJeXh+zsbPj7+6Nx48aYM2cOnnjiCYSEhODy5ctYsGABzp07h2eeeUb0ZxGR44nJEH17IqJbKTVH2GEiUgh7byuemZmJ6Ohow+OkpCQAQEJCAhYtWoSjR49ixYoVuHz5Mho3boz77rsPP/74Izp27Cj6s4jI8bitOBFZS6k5wg4TkULYe0pev3797rhDzbp160S/JxE5D6VOpSEix1FqjrDDRKQQOoi4D5NMhsCJyHHEZIi+PRHRrZSaI+wwESmEIGLesCCTgCIixxGTIfr2RES3UmqOsMNEpBBi7q4t5uoPEbkGMRmib09EdCul5og8Jg4SERERERFJgCNMRArhjPdhIiL5UOpibSJyHKXmCDtMRArBKXlEZA2lTqUhIsdRao6ww0SkEPa+cS0RKZtSbzhJRI6j1Bxhh4lIITjCRETWUOqVYSJyHKXmCDtMRArBDhMRWUOpP3SIyHGUmiPsMBEpBDtMRGQNpf7QISLHUWqOsMNEpBDsMBGRNZT6Q4eIHEepOcIOE5FCCDB/8aRg31KISIbEZIi+PRHRrZSaI+wwESkER5iIyBpKvTJMRI6j1Bxhh4lIIdhhIiJrKPWHDhE5jlJzhB0mIoVgh4mIrKHUHzpE5DhKzRF2mIgUgh0mIrKGUn/oEJHjKDVH2GEiUghBUEEwM3jMbUdErkNMhujbExHdSqk5wg6TgyxbvRVBwddrnd+8viU++bCr4wtSMDeVDgmDDuGR+3Phr7mBy8X1se2nNvhiU1dAxM4tcqODyuydacTsYEPOJUBTjlfj9+P+9vnwqleNs5c1mPtVPxzNbyJ1abJ2+mBD7F0chAuHvVF20RNDFp1Au/4lhud3pofgf5v9UHqhHtzrCQjpdB3RE8+jWdfauS5XYjJE357kKX7kZTw95iL8m1Tj5B/e+OTtpsjJri91WbLXI/g8RkVmo2PAJQQ2uI5x2x5FxukIw/OPtDiJoR3+h44Bl9DIqwJPfvMMjl4JkLBi21NqjrDD5CBv/D0a7u5/bZ7YPKIUc/+1Bz/uaiphVco0/LHfMLDfEbyz9CHknfND2xaXMeXF3Si/UQ/rvu8kdXl2wyl5yufjXYFFb2zAoeOh+Menj6G4zAthTUpw7bqn1KXJXuV1NwS1v45uz1zG2jH31Hq+ccRNxKXmwy+8AlU33XDg80B8+UJrjNvxPzRoXC1Bxban1Kk0ZOyhJ67i5ZTz+GhqMxw9VB9Pjr6EOatO4sUH2qLkSj2py5M173pVyLnSGOty2uGj/ttMPn+oIARbT9yDWQ/tkqBC+1NqjrhJXQAALFiwAC1atICXlxd69eqFgwcPSl2SzZWWqHG1yMtw9Iy6gPPnGuD3bGVdWXAGHVsV4qfs5tj/WzgKr/hgd1YEMg83RbuIS1KXZlf6YXBzD7F2796N+Ph4hIaGQqVSYcOGDYbnqqqqMGXKFHTu3BkNGjRAaGgoXnjhBZw/f96G37BurpAhADDi4WxcvNoQc7+KxpEzgbhQ5IuDOWE4d0UjdWmy17pfKf72jwtoF1ti8vnOA6+iZd9r8AuvRGCbm+j/1llUlLmj8Ki3gyu1H7EZIpepNOZylRwZ/PJlbF3lj/+u8ceZ416YP6UZKm6oEDu8SOrSZO/H/Ob4MLMXvj/V0uTzG4+3xSeHemDvuWYOrsxxlJojkneY1qxZg6SkJKSkpODQoUOIjIxEbGwsLl68KHVpduPhoUP0I/n477fNoeQpYlL5X24Q7m1/Hs2Can743BN2BZ1aF+Dg72ESVyZv5eXliIyMxIIFC2o9d/36dRw6dAjTpk3DoUOHsG7dOuTk5OCJJ56we12ulCF9O53C0fwmmDVyOzbPWoFlE79G/P1HpC7L5WgrVchaHQC1TzWC2ytnSp4rc5Uc8ainQ+su13HoRx/DOUFQ4ZcffdChO/8uE9VF8il58+bNw+jRo5GYmAgAWLRoEbZs2YLPP/8cU6dOlbg6+4jqex4NG1bh+63NpS5FkVZ9G4n63pVYMef/oNOp4OYmYOm6Hvh+fyupS7Mre0/Ji4uLQ1xcnMnnNBoNtm/fbnTu448/Rs+ePXHmzBmEh4eL/jxzuVKGhDa+hkF9/sCanZ2xcns3tA+/iAmDf0K11g3f/dxW6vIU71iGL755IwJVN9zgE1iF51bmor6/VuqybEapU2nM4So54uuvhbsHUHzJ+Off1cseCGtVIVFVpCRKzRFJO0yVlZXIyspCcnKy4ZybmxtiYmKwb9++Wu0rKipQUfHXP+jS0lKH1Glr/R87hcwDQSi6opypHM6k330nEXP/CcxeHI1T5/zQKvwKxg7fjyvF9bFtbxupy7MbS3bJu/3fkFqthlqttkk9JSUlUKlUaNSokU3ezxSxGQLIO0fcVAKO5jfBp1t6AQCOnwtAy5CrGNTnD3aYHKBFVBn+vvkorl91x6HVAfjmtQi8uC4HDQKUsYZJqbtb3Y2r/hYhsgel5oikU/IuX74MrVaLoKAgo/NBQUEoKCio1T4tLQ0ajcZwhIXJb4pVYNB1dO1+Edu2tJC6FMV6ZchBfPVtJHYcvAd55/yxfV9rfP3fTnh2wK9Sl2ZXwp9Xdcw59AEVFhZm9G8qLS3NJrXcvHkTU6ZMwfDhw+Hr62uT9zRFbIYA8s6RK6X1carAz+jcqcJGCGpUJlFFrsWzvg7+LSrQrNt1PPHuGbi5C/hlbWOpy7IZMRmiE/mjyJm50m+R0iJ3aKuBRk2MO/l+AdW4eknySUekAErNEcnXMImRnJyMkpISw5Gfny91SaI9EncKJcVqHNwfLHUpiqX2rIZOZ3xOp1NBpRJMv0AhBACCYObx52vy8/ON/k3deoXVUlVVVRgyZAgEQcDChQutfj9bk3OO/JYXjPDAYqNz4U1KUHDVx/QLyK4EQYXqSln9Z/SORGXILTniauScIdVVbjj+W31063vNcE6lEtC1bxn+yOK24mQ9peaIpJcTAgIC4O7ujsLCQqPzhYWFCA6u3aGw5XQhKahUAh559DS+39YcOq1y/iPrbPZlh+O5x7Nxsagh8s75oXXzK3gm9jC++1G50/GAmnsZqETeh8nX19emI0D6ztLp06fxww8/2HV0CRCfIYC8c2TNzs74dPx/8ELMIWRk34MO4RfxRNQRvLf2QalLk73KcjcUnf7r70VxvhoFf3jDW1MNbz8tflwQjLYxxWgYWI3rRe7I/KIJSgvqocNjVyWs2rbEZIi+vRK42m+RdYsDMDE9H8d+rY+cX2q2Ffeqr8N/V/tLXZrs1feoQrjmr502m/mWol3jyyi5qcaFch9o1DcR0rAMgfXLAQARmmIAwOXr9XH5hjI6rErNEUk7TJ6enujevTsyMjIwaNAgAIBOp0NGRgbGjRsnZWl20bX7RQQG38D2b7nZgz3NXxWFUU9m4Y3n9sLPt+bGtZt2tsPKjd2kLs2uLFnDZEv6ztLx48exY8cONG5s/6lKrpYhR/MDkby0P155/CBGxh7ChSIffLi+N/6b1Vrq0mTv/O/1sfLZvy6q/HdOzba/kU9dwYDZZ3DlhBf+b11LXL/qAe9G1Qjtch0j1xxDYJubUpVsc0pde3A3rpYjuzb6QdNYixcmFcCvSTVO/s8bb42IQPFl3oPJWh2bXMTK+I2Gx1Oj9gIA1ue0xZu7/obo5qeQ1m+H4fl5MTWbJX2c1QMLsu5zbLF2otQckXzCalJSEhISEtCjRw/07NkT6enpKC8vN+xUoyS/ZAbhsX6DpS5D8W7c9MSCr6Kw4KsoqUtxKJ2ggsqOu+SVlZUhNzfX8DgvLw/Z2dnw9/dHSEgInn76aRw6dAibN2+GVqs1zP339/eHp6f9bqzqShkCAHv/aI69f/Cii621uL8M008eqvP5IYtOOrAaaYjJEH17MXbv3o33338fWVlZuHDhAtavX2/ooACAIAhISUnBkiVLUFxcjD59+mDhwoVo3dr+FwRcLUc2LgvAxmW8D6St/XyhKdovHlPn8xuOtcOGY+0cWJHj2TtHpCJ5h2no0KG4dOkSpk+fjoKCAnTt2hVbt26ttfiSiO5MPx/Y3LZiZWZmIjo62vA4KSkJAJCQkIDU1FRs3FhzVa1r165Gr9uxYwf69esn/gPNxAwhsg0xGaJvL4b+Xm6jRo3C4MG1Lx6+9957mD9/PlasWIGIiAhMmzYNsbGx+OOPP+Dl5SXuw0RijhDZhr1zRCqSd5gAYNy4cYoc9iZyJHtPyevXrx+EOyTbnZ6zN2YIkfXsPZXmTvdyEwQB6enpePvttzFw4EAAwMqVKxEUFIQNGzZg2LBhoj7LEswRIuspdUoedx4gUgh9SJl7EBHdSmyG3Ho/t1uPW+9RZK68vDwUFBQgJibGcE6j0aBXr1513lONiJyPpTni7NhhIlIIMfc9kMucYSJyHLEZos8RW9zPTb/mUcw91YjI+ViaI87OKabkEZH17L2GiYiUzdK1B/n5+Ua3EJDzlttEZB2uYSIip1YTUuauYbJzMUQkO2IyRN8esM393PT3OyosLERISIjhfGFhYa2NZIjIeVmaI86OU/KIFEKJc4aJyHGkXHsQERGB4OBgZGRkGM6VlpbiwIEDiIpyrVtEEMmZUtcwcYSJSCGEPw9z2xIR3UpMhujbi3Gne7mFh4dj/PjxmD17Nlq3bm3YVjw0NNToXk1E5NzsnSNSYYeJSCHsva04ESmbvbcDvtO93JYvX47JkyejvLwcL7/8MoqLi9G3b19s3brV7vdgIiLbUeq24mZ1mPQ3pDTHE088YXExRGQFJx9iYo4QOTk7Xxq+273cVCoVZs6ciZkzZ5p8nhlCJAN2zpHdu3fj/fffR1ZWFi5cuID169cbjUKPHDkSK1asMHpNbGwstm7dKu6DbmNWh8nc4XCVSgWtVmtNPUSkUMwRIrIGM4SIysvLERkZiVGjRmHw4MEm2zz66KNYtmyZ4bEtdu40q8Ok0+ms/iAisjMxw+ASDIEzR4icnNgF2A7OEWYIkQzYOUfi4uIQFxd3xzZqtdqw86atWLVL3s2bN21VBxFZSX/vA3MPZ8EcIXIOYjPEWXKEGULkPCzNkdLSUqOjoqLC4hp27tyJwMBAtG3bFmPGjMGVK1es/l6iO0xarRazZs1C06ZN0bBhQ5w8eRIAMG3aNCxdutTqgojIMnLaxpM5QuR85LQdMDOEyDlZmiNhYWHQaDSGIy0tzaLPf/TRR7Fy5UpkZGTg3Xffxa5duxAXF2f1NF3RHaY5c+Zg+fLleO+99+Dp6Wk436lTJ3z22WdWFUNEVhBU4g4JMUeInJDYDJEwR5ghRE7KwhzJz89HSUmJ4UhOTrbo44cNG4YnnngCnTt3xqBBg7B582b8/PPP2Llzp1VfS3SHaeXKlVi8eDFGjBgBd3d3w/nIyEgcPXrUqmKIyHJymkrDHCFyPnKakscMIXJOluaIr6+v0WGLjRoAoGXLlggICDC6B5wlRN+H6dy5c2jVqlWt8zqdDlVVVVYVQ0RWcPJtxW/FHCFyQjK64yQzhMhJOVmOnD17FleuXEFISIhV7yN6hKlDhw748ccfa53/+uuv0a1bN6uKISLLyWXtAcAcIXJGclrDxAwhck72zpGysjJkZ2cjOzsbAJCXl4fs7GycOXMGZWVlmDRpEvbv349Tp04hIyMDAwcORKtWrRAbG2vV9xI9wjR9+nQkJCTg3Llz0Ol0WLduHXJycrBy5Ups3rzZqmKIyEpOsmvV3TBHiJwUM4SIrGXHHMnMzER0dLThcVJSEgAgISEBCxcuxG+//YYVK1aguLgYoaGh6N+/P2bNmmX1FD/RHaaBAwdi06ZNmDlzJho0aIDp06fj3nvvxaZNm/DII49YVQwRWU7MlRqpR5iYI0TOR+zVXilzhBlC5JzsnSP9+vWDcIcFlNu2bRP1fuYS3WECgAceeADbt2+3dS1EZA0ZrWECmCNETsfJ1h7cDTOEyAnJLEfMZVGHCagZEjty5AiAmrnE3bt3t1lRRGQJ1Z+HuW3F2b17N95//31kZWXhwoULWL9+PQYNGmR4ft26dVi0aBGysrJQVFSEX375BV27dr3jezJHiJyJmAzRt5cWM4TI2cgvR8whusN09uxZDB8+HD/99BMaNWoEACguLkbv3r2xevVqNGvWzNY1EpE57DzCVF5ejsjISIwaNQqDBw82+Xzfvn0xZMgQjB49+o7vxRwhckIyujLMDCFyUjLKETFE75L30ksvoaqqCkeOHEFRURGKiopw5MgR6HQ6vPTSS/aokYjMIYg8RIqLi8Ps2bPx5JNPmnz++eefx/Tp0xETE3PX92KOEDkhsRki4Q8dZgiRk5JRjogheoRp165d2Lt3L9q2bWs417ZtW3z00Ud44IEHbFocEYlwyx2zzWoLoLS01Oi0Wq222c3i7oQ5QuSExGSIvr1EmCFETkpGOSKG6BGmsLAwkzeF02q1CA0NtUlRRCSeJXfWDgsLg0ajMRxpaWkOqZU5QuR8xGbIHTaqsjtmCJFzklOOiCG6w/T+++/jtddeQ2ZmpuFcZmYm3njjDfzzn/+0aXFEJIIFQ+D5+fkoKSkxHMnJyQ4plTlC5IRkNJWGGULkpGSUI2KYNSXPz88PKtVfQ2bl5eXo1asXPDxqXl5dXQ0PDw+MGjXKaNcsInJuvr6+8PX1dchnMUeIyBrMECKSilkdpvT0dDuXQURWs2ANkyMxR4icnJOvPWCGEMmAk+eIpczqMCUkJNi7DiKykkqoOcxtK1ZZWRlyc3MNj/Py8pCdnQ1/f3+Eh4ejqKgIZ86cwfnz5wEAOTk5AIDg4GAEBwczR4icnJgM0bd3JGYIkfNz9hyxlMU3rgWAmzdvorKy0uico6b3ENFtxMwFtiCgMjMzER0dbXiclJQEoOZHzPLly7Fx40YkJiYanh82bBgAICUlBampqXW+L3OEyEmIXU/gJD90mCFETkSmOXI3ojtM5eXlmDJlCtauXYsrV67Uel6r1dqkMCISyc5T8vr16wfhDtvZjBw5EiNHjjTrvZgjRE5IRlNpmCFETkpGOSKG6F3yJk+ejB9++AELFy6EWq3GZ599hhkzZiA0NBQrV660R41EZA4Z7UrDHCFyQjLa3YoZQuSkZJQjYogeYdq0aRNWrlyJfv36ITExEQ888ABatWqF5s2b48svv8SIESPsUScR3Y2dp+TZEnOEyAnJaCoNM4TISckoR8QQPcJUVFSEli1bAqiZI1xUVAQA6Nu3L3bv3m3b6ojIfDK6osMcIXJCMroyzAwhclIyyhExRHeYWrZsiby8PABAu3btsHbtWgA1V3saNWpk0+KISAT9vGFzDwkxR4ickNgMkTBHmCFETkpGOSKG6A5TYmIifv31VwDA1KlTsWDBAnh5eWHChAmYNGmSzQskIvPot/I095ASc4TI+YjNEClzhBlC5JzklCNiiF7DNGHCBMP/j4mJwdGjR5GVlYVWrVqhS5cuNi2OiESQ0Rom5giRE5LR2gNmCJGTklGOiGHVfZgAoHnz5mjevLktaiEiF8UcISJrMEOIyJ7M6jDNnz/f7Dd8/fXXLS7GUtrcPKhU9Rz+ua5mx85vpC7BZZRe08GvjbjXqGD+0LYUM4adPUcarvsZHswRu+uTLnomOFmgtEr8a8RkiL69Izl7hpBjHHn5E6lLcBml13TwSxP3GmfPEUuZ1WH64IMPzHozlUrFkCKSip1vXGst5giRk3PyG04yQ4hkwMlzxFJmdZj0O9EQkRNz8jVMzBEiJ+fkaw+YIUQy4OQ5Yimr1zARkZNw8g4TETk5hf7QISIHUmiOsMNEpBBitueUyzaeROQ4Yrf4ZY4Q0e2UmiNcfUtERERERFQHjjARKQWn5BGRNRQ6lYaIHEihOcIOE5FSsMNERNZQ6A8dInIgheaIRVPyfvzxRzz33HOIiorCuXPnAABffPEF9uzZY9PiiMh8+nnD5h5SY44QORexGSJ1jjBDiJyP3HLEXKI7TN988w1iY2Ph7e2NX375BRUVFQCAkpISzJ071+YFEpGZ9Pc+MPeQEHOEyAmJzRAJc4QZQuSkZJQjYojuMM2ePRuLFi3CkiVLUK9ePcP5Pn364NChQzYtjohEEEQeEmKOEDkhsRkiMke0Wi2mTZuGiIgIeHt745577sGsWbMgCOIDiRlC5KTsnCNSEb2GKScnBw8++GCt8xqNBsXFxbaoiYgsIKdtxZkjRM7H3tsBv/vuu1i4cCFWrFiBjh07IjMzE4mJidBoNHj99ddFvRczhMg5cVvxPwUHByM3N7fW+T179qBly5Y2KYqILCCjKzrMESInZOcrw3v37sXAgQMxYMAAtGjRAk8//TT69++PgwcPii6VGULkpBQ6wiS6wzR69Gi88cYbOHDgAFQqFc6fP48vv/wSEydOxJgxY+xRIxGZQ8wCSwsCavfu3YiPj0doaChUKhU2bNhg/PGCgOnTpyMkJATe3t6IiYnB8ePHTb4Xc4TICYldqP1njpSWlhod+vVEt+vduzcyMjJw7NgxAMCvv/6KPXv2IC4uTnSpzBAiJ2Vhjjg70VPypk6dCp1Oh4cffhjXr1/Hgw8+CLVajYkTJ+K1116zR41EZA4xwWNBQJWXlyMyMhKjRo3C4MGDaz3/3nvvYf78+VixYgUiIiIwbdo0xMbG4o8//oCXl5dRW+YIkRMS++Plz7ZhYWFGp1NSUpCamlqr+dSpU1FaWop27drB3d0dWq0Wc+bMwYgRI0SXygwhclIW5oizE91hUqlUeOuttzBp0iTk5uairKwMHTp0QMOGDe1RHxGZy4IOU2lpqdFptVoNtVpt8iVxcXF1XgkWBAHp6el4++23MXDgQADAypUrERQUhA0bNmDYsGFG7ZkjRE7Iwh86+fn58PX1NZyuK0PWrl2LL7/8EqtWrULHjh2RnZ2N8ePHIzQ0FAkJCaJKZYYQOSl2mIx5enqiQ4cOtqyFiKxgyaYP5l4Zvpu8vDwUFBQgJibGcE6j0aBXr17Yt29frQ6THnOEyHlYuljb19fXqMNUl0mTJmHq1KmGPOjcuTNOnz6NtLQ00R0mPWYIkXNR6qYPojtM0dHRUKnq3jP9hx9+sKogInIcc68M301BQQEAICgoyOh8UFCQ4blbMUeIXM/169fh5ma8dNrd3R06nU70ezFDiMiRRHeYunbtavS4qqoK2dnZOHz4sMVXiIjIBiyYkmfulWFbY44QOSE7T6WJj4/HnDlzEB4ejo4dO+KXX37BvHnzMGrUKHFvBGYIkdPilLwaH3zwgcnzqampKCsrs7ogIrKMlPdhCg4OBgAUFhYiJCTEcL6wsLDWDxuAOULkjOw9leajjz7CtGnT8Oqrr+LixYsIDQ3F3//+d0yfPl3cG4EZQuSslDolT/S24nV57rnn8Pnnn9vq7YjIEhLd8yAiIgLBwcHIyMgwnCstLcWBAwcQFRVl9vswR4gkZsd7p/j4+CA9PR2nT5/GjRs3cOLECcyePRuenp62qp4ZQuQMFHYPJsCKTR9ut2/fvlpbBxORA9l5W/GysjKjG0Xm5eUhOzsb/v7+CA8Px/jx4zF79my0bt3asK14aGgoBg0aZPZnMEeIJKSAqTTMECKJKSBHTBHdYbr9/iuCIODChQvIzMzEtGnTbFYYETmXzMxMREdHGx4nJSUBABISErB8+XJMnjwZ5eXlePnll1FcXIy+ffti69atJn+8MEeIyBrMECJyJNEdJo1GY/TYzc0Nbdu2xcyZM9G/f3+bFUZE4th7DVO/fv0gCHW/UKVSYebMmZg5c+Zd34s5QuR85LT2gBlC5JzklCNiiOowabVaJCYmonPnzvDz87NXTURkCTtPybMV5giRk5LJVBpmCJETk0mOiCVq0wd3d3f0798fxcXFdiqHiCylv6pj7iEV5giRcxKbIVLlCDOEyHnZO0d2796N+Ph4hIaGQqVSYcOGDUbPC4KA6dOnIyQkBN7e3oiJicHx48et/l6id8nr1KkTTp48afUHE5GNidmVRuIrOswRIickNkMkzBFmCJGTsnOOlJeXIzIyEgsWLDD5/HvvvYf58+dj0aJFOHDgABo0aIDY2FjcvHnTwi9UQ/QaptmzZ2PixImYNWsWunfvjgYNGhg9L8VNMIkIspmSBzBHiJySjKbSMEOInJSFOVJaWmp0Wq1WQ61W12oeFxeHuLg4028lCEhPT8fbb7+NgQMHAgBWrlyJoKAgbNiwAcOGDRNRmDGzR5hmzpyJ8vJyPPbYY/j111/xxBNPoFmzZvDz84Ofnx8aNWrEucREEpLDVBrmCJHzksOUPGYIkXOzNEfCwsKg0WgMR1pamujPzsvLQ0FBAWJiYgznNBoNevXqhX379ln1vcweYZoxYwZeeeUV7Nixw6oPJCI7kcEIE3OEyInJYISJGULk5CzMkfz8fKORYVOjS3dTUFAAAAgKCjI6HxQUZHjOUmZ3mPTbCT/00ENWfSAR2YkMOkzMESInJoMOEzOEyMlZmCO+vr5OPZVW1KYPKpXKXnUQkZWcfSqNoU7mCJFTksOUPIAZQuTMpMyR4OBgAEBhYaHR+cLCQsNzlhK16UObNm3uGlRFRUVWFUREFpLBCBPAHCFyWjIYYQKYIUROTcIciYiIQHBwMDIyMtC1a1cANZtJHDhwAGPGjLHqvUV1mGbMmFHr7tpE5BzEXKmRcoSJOULknMRe7ZUqR5ghRM7L3jlSVlaG3Nxcw+O8vDxkZ2fD398f4eHhGD9+PGbPno3WrVsjIiIC06ZNQ2hoKAYNGiTug24jqsM0bNgwBAYGWvWBRGQnMhlhYo4QOSmZjDAxQ4icmJ1zJDMzE9HR0YbHSUlJAICEhAQsX74ckydPRnl5OV5++WUUFxejb9++2Lp1K7y8vMR90G3M7jBxzjCRk5NBh4k5QuTEZNBhYoYQOTk750i/fv0Mm7+YolKpMHPmTMycOVPcG9+F6F3yiMg5qf48zG0rBeYIkfMSkyH69o7GDCFybnLIEUuY3WHS6XT2rIOIrCWDESbmCJETk8EIEzOEyMnJIEcsIWoNExE5L7ls+kBEzkkumz4QkfNSao6ww0SkFDIYYSIiJ6bQK8NE5EAKzRFRN64lIiIiIiJyJRxhIlISmVypISInxQwhImspMEfYYXKgxsFVePGt87gv+hrU3jqcP6XGvyaE4fhv9aUuTfZ+398A//dJII7/Xh9FhfWQsjQPveNKDM//c3w4tq/1N3pN936lmLvqpKNLtRuuYVK+x1+4jAEvXEFQWCUA4HSOF778IAiZO3wlrkz+7pYht/pwSjN8+0UA/j7jHAaPvuTgSu1HqWsPqLb4kZfx9JiL8G9SjZN/eOOTt5siJ5u/Rayx+qNA/PRtI+TnquHppUOHHtfx4lvnEdaqwtBm0lOt8Nu+hkave+z5y3jj3bOOLtdulJojkk7J2717N+Lj4xEaGgqVSoUNGzZIWY5dNdRUY95/jkNbrcLbz7XE6H5tsXhmKMpK3KUuTRFuXndDy443MG5u3aHTI7oUX2UfNhzJn5x2YIUOIIg8RLp27RrGjx+P5s2bw9vbG71798bPP/9so+It50o5culCPXw+NwTjHm2D1+La4NefGiJ12Sk0b3NT6tJkz5wMAYCfvtPgaFYDNA6udFBlDiQ2Q2TyQ+duXClDAOChJ67i5ZTz+HJeMMbGtsHJP7wwZ9VJaBpXSV2arP22ryHiR15G+ubjSFt9Atpq4M3h9+DmdeOf2nEjLhv9Fnnp7fMSVWwnCs0RSUeYysvLERkZiVGjRmHw4MFSlmJ3Q8ZexOXznvjXhHDDucJ8tYQVKct9f7uG+/527Y5t6nkK8A+sdlBFjmfvEaaXXnoJhw8fxhdffIHQ0FD8+9//RkxMDP744w80bdpU/BvaiCvlyIHtGqPHy98NweMvXEG77uU4fcy6u5i7OnMy5PKFevjk7aaYs+okpj/f0kGVOY5SrwzfjStlCAAMfvkytq7yx3/X1My6mD+lGXo+XIrY4UVY+3GQxNXJ1+0zVv6RfgZDO3fG8d+80fn+csN5tTd/i9zeXg4k7TDFxcUhLi5OyhIc5v7+pcja6YO3Pj2FLlHluFzggc3LA/DdqsZSl+YyftvXEEM6d4SPRovIvmUYOfkCfP21UpdlO3bcJe/GjRv45ptv8J///AcPPvggACA1NRWbNm3CwoULMXv2bHFvaEOulCO3cnMT8EB8MdT1dTiS2UDqchRPpwPeez0cT4+5iBZtFTqip9Ddre7GlTLEo54Orbtcx+qPAw3nBEGFX370QYfu1yWsTHnKS2tmEPk0Mv6dsWOdH374xg9+gVW4/5FSPDu+AF71FfKPCVBsjshqDVNFRQUqKv6aC1paWiphNeKEhFfi8ReuYN3iJlj9USDaRN7AmFnnUFWlwvf/53/3NyCr9OhXij5xxQgOr8SFU2oseycEbz3XEumbjsNdIbMiLRlhuv3fkFqthlpde+SzuroaWq0WXl7Goxje3t7Ys2ePRfVKRc45AgAt2t1A+qZceKp1uFHuhpkvtsCZ4xxdsre1CwLh7i5g0IuXpS7FbpR6ZdjW5Jwhvv5auHsAxZeMf/5dvexhtNaGrKPTAYtSmqLjfWVo0e6vCyzRT15FYLNKNA6qQt4RbyydE4KzJ9SYvvSUdMXamFJzRFbbiqelpUGj0RiOsLAwqUsym8oNyD3sjWXvhODE4fr47svG+G5VYwx4/orUpbmEfoOKERVbioj2N9E7rgQzV57EsewG+G1vw7u/WC4smDMcFhZm9G8qLS3N5Fv7+PggKioKs2bNwvnz56HVavHvf/8b+/btw4ULF+z9zWxKzjkCAGdPqPHqI23w+oDW2LwyABM/PIPw1god8XASx3/zxobPmmBi+hmoVFJXY0cKXXtga3LPELK/j99shtNHvZG80Hit9GPPXUGPftcQ0f4m/jb4KiZ9eAY/fdcI5095SlSpHSg0R2TVYUpOTkZJSYnhyM/Pl7oksxVd9Ki1xiD/uBqBTRW4cFgGQppXQuNfjfOnFLSOzIKAys/PN/o3lZycXOfbf/HFFxAEAU2bNoVarcb8+fMxfPhwuLnJKkZknSMAUF3lhvOn1Mj9vT6WpYUg7w9vDHpJOTu1OaPfDzRE8WUPPHdfR8SFRSIuLBKFZz2xZEYoXujZQerybEehP3RsTc4ZUlrkDm010KiJ8Roav4BqXL0kq0lHTuvjN5viwHZfvPd1LpqE3nkjjXb31kyDdOnfIjLJEVn966hrupAc/PFzA4TdYzzc3bRlBS6eU9BVBRm5dL4eSq+6wz9QObsCWTIlz9fXF76+5m1Jfc8992DXrl0oLy9HaWkpQkJCMHToULRsKa/F73LOEVNUqpoNTch+Yp4qwr0PGG8I8eazLfHwU1fRf2iRRFXZnlKn0tianDOkusoNx3+rj259r2Hf1ppNZFQqAV37lmHjcq6ptoYgAAveaoq9WzV4/+tcBIff/YL4icPeAOCyv0X07eVAVh0mOVu3uAk+2Hgcw14rxO5NjdC223U89lwR0ic1k7o0RbhR7obzeX/9B6wg3xMnDnvDp1E1fPy0+Pe/gtF3QDH8Aqtx4ZQnPpsditCICnTvd+ddsWTFjps+3KpBgwZo0KABrl69im3btuG9996z/M1IlMTkC/j5Bx9cOucJ74ZaRD9ZjC69y/DWs/LqtDqjO2VIYLOqWhvEeHgAfoHVylr3odDF2mRs3eIATEzPx7Ff6yPnl/p4cvQleNXX4b+ruZ7aGh+/2Qw71vshddlJeDfUoehizU/sBj5aqL0FnD/liR3r/dDz4VL4+GmR94cXPk1tis73l6FlBwVNq1ZojkjaYSorK0Nubq7hcV5eHrKzs+Hv74/w8PA7vFJ+jv1aHzNfjEBi8gWMmFCIgnxPLJoeih3r/aQuTRGO/Vofk59uZXj8aWrNNtePDCnCa2n5yDvihe3/F4HyUnc0DqrGvQ+VImFyATzVMvmXagaVIEAlmPd9zG13q23btkEQBLRt2xa5ubmYNGkS2rVrh8TERNHvZUuulCONAqoxaf4Z+AdW4/o1d+Qd8cJbz7bEod0+Upcme3fKkInpZ6Qqy6HEZIi+vRK4UoYAwK6NftA01uKFSQXwa1KNk//zxlsjIlB8uZ7Upcna5hUBAIBJT7U2Ov+PD86g/9AieNQT8MuPPlj/WRPcvO6GJqFV6PtYMYaPL5SiXLtRao5I2mHKzMxEdHS04XFSUhIAICEhAcuXL5eoKvs58L0vDnxv3vQnEieydxm2nc+u8/m5X52s8znFsPMIk36N09mzZ+Hv74+nnnoKc+bMQb160v5H1pVy5IN/cHG5vdwtQ2638uAf9itGKgq9Mnw3rpQhehuXBWDjsgCpy1CUu+VHYNMq/HNd7h3bKIJCc0TSDlO/fv0gyKRnSeTs7H3j2iFDhmDIkCHiX2hnzBEi21Dq2oO7YYYQ2Y5Sc4RrmIiUwkFrmIhIoRR6ZZiIHEihOcIOE5FC2HuEiYiUTalXhonIcZSaI+wwESkFR5iIyBoKvTJMRA6k0ByR1x0niYiIiIiIHIgjTEQKwSl5RGQNpU6lISLHUWqOcISJSCkEkQcR0a3EZogFOXLu3Dk899xzaNy4Mby9vdG5c2dkZmbapn4ikp4DckQKHGEiUhC5XKkhIudkzwy5evUq+vTpg+joaHz33Xdo0qQJjh8/Dj8/3sCdSEmU+FuEHSYipRCEmsPctkREtxKTIfr2Irz77rsICwvDsmXLDOciIiJEvQcROTk754hUOCWPSCH084bNPYiIbiU2Q/Q5UlpaanRUVFSYfP+NGzeiR48eeOaZZxAYGIhu3bphyZIlDvyGRGRvluaIs2OHiUgpFDhnmIgcyMK1B2FhYdBoNIYjLS3N5NufPHkSCxcuROvWrbFt2zaMGTMGr7/+OlasWGHnL0ZEDsM1TETkzFS6msPctkREtxKTIfr2AJCfnw9fX1/DebVabbK9TqdDjx49MHfuXABAt27dcPjwYSxatAgJCQkW101EzsPSHHF2HGEiUgoFXtEhIgey8Mqwr6+v0VFXhykkJAQdOnQwOte+fXucOXPGHt+GiKTAESYicma8DxMRWcPe90/p06cPcnJyjM4dO3YMzZs3F/dGROS0lHofJnaYiJSCu+QRkTXsvLvVhAkT0Lt3b8ydOxdDhgzBwYMHsXjxYixevFhkoUTktLhLHhE5MyXuSkNEjmPv3a3uu+8+rF+/Hl999RU6deqEWbNmIT09HSNGjLDPFyIih1PqLnkcYSJSCjFzgWUSUETkQGLXE1iQI48//jgef/xx8S8kInlwQI5IgR0mIoXgGiYisoZS1x4QkeMoNUfYYSJSCq5hIiJrKHTtARE5kEJzhB0mIoXgCBMRWUOpV4aJyHGUmiPc9IFIKex43wOtVotp06YhIiIC3t7euOeeezBr1iwIMrkyRERmUOj9U4jIgRSaIxxhIqK7evfdd7Fw4UKsWLECHTt2RGZmJhITE6HRaPD6669LXR4RERGR3bDDRKQQ9pySt3fvXgwcOBADBgwAALRo0QJfffUVDh48KLJKInJWSp1KQ0SOo9Qc4ZQ8IqXQCeIOAKWlpUZHRUWFybfu3bs3MjIycOzYMQDAr7/+ij179iAuLs5hX4+I7Exshuhk8kuHiBxHoTnCESYipbDgPkxhYWFGp1NSUpCamlqr+dSpU1FaWop27drB3d0dWq0Wc+bM4Q0niZREofdPISIHUmiOsMNEpBAqiJiS9+f/5ufnw9fX13BerVabbL927Vp8+eWXWLVqFTp27Ijs7GyMHz8eoaGhSEhIsK5wInIKYjJE356I6FZKzRFOySNSCv29D8w9APj6+hoddXWYJk2ahKlTp2LYsGHo3Lkznn/+eUyYMAFpaWmO/IZEZE9iM4S7ZBLR7eyYI6mpqVCpVEZHu3bt7Phl/sIRJiKFsOemD9evX4ebm/H1FXd3d+h0OnFvREROS6mLtYnIceydIx07dsT3339veOzh4ZiuDDtMREphwRomc8XHx2POnDkIDw9Hx44d8csvv2DevHkYNWqU2CqJyFkpdO0BETmQnXPEw8MDwcHB4l5kA+wwESmEShCgMnNo29x2eh999BGmTZuGV199FRcvXkRoaCj+/ve/Y/r06ZaUSkROSEyG6NsTEd3K0hwpLS01Oq9Wq00uEzh+/DhCQ0Ph5eWFqKgopKWlITw83LqizcA1TERKoRN5iODj44P09HScPn0aN27cwIkTJzB79mx4enra8AsQkaTEZghn5BLR7SzMkbCwMGg0GsNhao10r169sHz5cmzduhULFy5EXl4eHnjgAVy7ds3uX4sjTEQKYc8RJiJSPo4wEZG1LM0Rc3btvfXej126dEGvXr3QvHlzrF27Fi+++KIVVd8dO0xESmHHNUxE5AK4homIrGVhjuh36xWjUaNGaNOmDXJzc0W9zhKckkekFNwOmIiswW3FichaDsyRsrIynDhxAiEhITb8Aqaxw0SkEPqtPM09iIhuJTZDmCNEdDt75sjEiROxa9cunDp1Cnv37sWTTz4Jd3d3DB8+3H5f6E+ckkekFGKu1PDKMBHdTuzVXuYIEd3Ojjly9uxZDB8+HFeuXEGTJk3Qt29f7N+/H02aNLGgUHHYYSJSCJWu5jC3LRHRrcRkiL49EdGt7Jkjq1evFl+QjbDDRKQUHGEiImtwhImIrKXQHJF1h0n48w+5GlXcrccBSq/xcqKjlJbV/FkLMgkSOWOOOBZzxDGYIY7DDHEsZojjMEf+IusOk/5GVXvwrcSVuAa/NlJX4HquXbsGjUZjXmNuK24R5ohjMUccy24Zom9PzBAHY4Y4HnNE5h2m0NBQ5Ofnw8fHByqVSupyzFZaWoqwsLBaN+ki25Prn7UgCLh27RpCQ0PNfg1vXGsZOeaIXP9ey5Fc/6ztnSH69iTPDAHk+3dbjuT6Z80c+YusO0xubm5o1qyZ1GVYzJKbdJFl5PhnbfbVHD2uYbKInHNEjn+v5UqOf9Z2zRB9e5J1hgDy/LstV3L8s2aO1JB1h4mIbiEAMHdqtzzyiYgcSUyG6NsTEd1KoTnCDhORQnBKHhFZQ6lTaYjIcZSaI+wwSUCtViMlJQVqtVrqUhTPpf6sBYiYkmfXSsjOXOrvtcRc6s9aTIbo25NsudTfbYm51J+1QnNEJXCvQCJZKy0thUajwd8ip8DD3bwwrtZW4Idf30VJSYns5lMTkW1ZkiEAc4SI/qL0HOEIE5FS6ACYu0ETb2NBRLcTkyH69kREt1JojrDDRKQQXMNERNZQ6toDInIcpeYIO0xESsFtxYnIGgrdDpiIHEihOcIOE5FSsMNERNZQ6A8dInIgheaIm9QFEJGN6EPK3EOEFi1aQKVS1TrGjh1rpy9DRA4nNkNk8kOHiBxIoTnCDpODLViwAC1atICXlxd69eqFgwcPSl2SIu3evRvx8fEIDQ2FSqXChg0bpC7J/nQiDxF+/vlnXLhwwXBs374dAPDMM8/YqnoSgTniGC6XI2IzRCaLtak2ZohjuFyGAIrNEXaYHGjNmjVISkpCSkoKDh06hMjISMTGxuLixYtSl6Y45eXliIyMxIIFC6QuxWH0Cy3NPcRo0qQJgoODDcfmzZtxzz334KGHHrLTt6G6MEccx9VyRGyGyGWxNhljhjiOq2UIoNwc4RomB5o3bx5Gjx6NxMREAMCiRYuwZcsWfP7555g6darE1SlLXFwc4uLipC7DsSxYw1RaWmp0Wq1W3/XGepWVlfj3v/+NpKQkqFRi9g4lW2COOI7L5YhC1x6QMWaI47hchgCKzRGOMDlIZWUlsrKyEBMTYzjn5uaGmJgY7Nu3T8LKSDF0grgDQFhYGDQajeFIS0u768ds2LABxcXFGDlypJ2/EN2OOUJ2JTZDdPL4oUN/YYaQ3Sk0RzjC5CCXL1+GVqtFUFCQ0fmgoCAcPXpUoqpIUSwYYcrPzze6s/bdRpcAYOnSpYiLi0NoaKhFZZLlmCNkVwq9Mkx/YYaQ3Sk0RzjCROTCfH19jY67dZhOnz6N77//Hi+99JKDKiQiJXrnnXegUqkwfvx4qUshIrorjjA5SEBAANzd3VFYWGh0vrCwEMHBwRJVRcoi5qqOZVd0li1bhsDAQAwYMMCi15N1mCNkX2K3+LUsR37++Wd8+umn6NKli0WvJ8sxQ8j+HJMjjsYRJgfx9PRE9+7dkZGRYTin0+mQkZGBqKgoCSsjxbDzfQ90Oh2WLVuGhIQEeHjwWosUmCNkVxbeP6W0tNToqKioqPMjysrKMGLECCxZsgR+fn6O+mb0J2YI2Z1C78PEXz0OlJSUhISEBPTo0QM9e/ZEeno6ysvLDTvVkO2UlZUhNzfX8DgvLw/Z2dnw9/dHeHi4hJXZkU6A2VdqLFhk+f333+PMmTMYNWqU6NeS7TBHHMflckRMhhja12wec6uUlBSkpqaafMnYsWMxYMAAxMTEYPbs2RYWStZghjiOy2UIYHGOODt2mBxo6NChuHTpEqZPn46CggJ07doVW7durbX4kqyXmZmJ6Ohow+OkpCQAQEJCApYvXy5RVXYm6GoOc9uK1L9/fwgyuRKkZMwRx3G5HBGTIfr2MH/zmNWrV+PQoUP4+eefrSqTrMMMcRyXyxDA4hxxdiqBv4CIZK20tBQajQYxYWPg4Xb3Xe4AoFpXge/zF6KkpMTohw4RuR5LMgQQlyP5+fno0aMHtm/fbli71K9fP3Tt2hXp6enWlE9ETsAROSIljjARKYWdp+QRkcLZcSpNVlYWLl68iHvvvddwTqvVYvfu3fj4449RUVEBd3d3EcUSkVPilDwicmoW3IeJiMjAjvdPefjhh/H7778bnUtMTES7du0wZcoUdpaIlEKh92Fih4lIKQSI6DDZtRIikiMxGaJvbyYfHx906tTJ6FyDBg3QuHHjWueJSMbsmCNSYoeJSCk4wkRE1lDolWEiciCF5gg7TERKodMBMHO3GZ08dqUhIgcSkyGG9pbbuXOnVa8nIifk4BxxFHaYiJSCI0xEZA2FXhkmIgdSaI6ww0SkFOwwEZE1FPpDh4gcSKE54iZ1AWRbI0eOxKBBgwyP+/Xrh/Hjxzu8jp07d0KlUqG4uLjONiqVChs2bDD7PVNTU9G1a1er6jp16hRUKhWys7Oteh+npBPEHUQmMEPujBnCHKG7Y47cGXNEfjnCDpMDjBw5EiqVCiqVCp6enmjVqhVmzpyJ6upqu3/2unXrMGvWLLPamhMs5LwEQSfqIPlghpAjiM0Q5oi8MEfIEZSaI5yS5yCPPvooli1bhoqKCnz77bcYO3Ys6tWrh+Tk5FptKysr4enpaZPP9ff3t8n7kAwIIq7UyGQInP7CDCG7E5Mh+vYkK8wRsjuF5ghHmBxErVYjODgYzZs3x5gxYxATE4ONGzcC+Gvoes6cOQgNDUXbtm0BAPn5+RgyZAgaNWoEf39/DBw4EKdOnTK8p1arRVJSEho1aoTGjRtj8uTJEG77i3f7MHhFRQWmTJmCsLAwqNVqtGrVCkuXLsWpU6cQHR0NAPDz84NKpcLIkSMBADqdDmlpaYiIiIC3tzciIyPx9ddfG33Ot99+izZt2sDb2xvR0dFGdZprypQpaNOmDerXr4+WLVti2rRpqKqqqtXu008/RVhYGOrXr48hQ4agpKTE6PnPPvsM7du3h5eXF9q1a4dPPvlEdC2ypJ83bO5BssIMuTtmiJXEZghzRHaYI3fHHLGSQnOEHSaJeHt7o7Ky0vA4IyMDOTk52L59OzZv3oyqqirExsbCx8cHP/74I3766Sc0bNgQjz76qOF1//rXv7B8+XJ8/vnn2LNnD4qKirB+/fo7fu4LL7yAr776CvPnz8eRI0fw6aefomHDhggLC8M333wDAMjJycGFCxfw4YcfAgDS0tKwcuVKLFq0CP/73/8wYcIEPPfcc9i1axeAmjAdPHgw4uPjkZ2djZdeeglTp04V/Wfi4+OD5cuX448//sCHH36IJUuW4IMPPjBqk5ubi7Vr12LTpk3YunUrfvnlF7z66quG57/88ktMnz4dc+bMwZEjRzB37lxMmzYNK1asEF0PkTNjhtTGDCEShzlSG3OETBLI7hISEoSBAwcKgiAIOp1O2L59u6BWq4WJEycang8KChIqKioMr/niiy+Etm3bCjqdznCuoqJC8Pb2FrZt2yYIgiCEhIQI7733nuH5qqoqoVmzZobPEgRBeOihh4Q33nhDEARByMnJEQAI27dvN1nnjh07BADC1atXDedu3rwp1K9fX9i7d69R2xdffFEYPny4IAiCkJycLHTo0MHo+SlTptR6r9sBENavX1/n8++//77QvXt3w+OUlBTB3d1dOHv2rOHcd999J7i5uQkXLlwQBEEQ7rnnHmHVqlVG7zNr1iwhKipKEARByMvLEwAIv/zyS52fKzclJSUCAOFhnxFCrG+iWcfDPiMEAEJJSYnU5ZMZmCGmMUNsw5IMYY7ID3PENOaIbSg9R7iGyUE2b96Mhg0boqqqCjqdDs8++yxSU1MNz3fu3NlorvCvv/6K3Nxc+Pj4GL3PzZs3ceLECZSUlODChQvo1auX4TkPDw/06NGj1lC4XnZ2Ntzd3fHQQw+ZXXdubi6uX7+ORx55xOh8ZWUlunXrBgA4cuSIUR0AEBUVZfZn6K1Zswbz58/HiRMnUFZWhurqavj6+hq1CQ8PR9OmTY0+R6fTIScnBz4+Pjhx4gRefPFFjB492tCmuroaGo1GdD2yU5P7ItqSnDBD7o4ZYiUxGWJoT3LCHLk75oiVFJoj7DA5SHR0NBYuXAhPT0+EhobCw8P4j75BgwZGj8vKytC9e3d8+eWXtd6rSZMmFtXg7e0t+jVlZWUAgC1bthiFA1AzF9pW9u3bhxEjRmDGjBmIjY2FRqPB6tWr8a9//Ut0rUuWLKkVmu7u7jar1VkJOh0ElXm7zchlVxr6CzPkzpgh1hOTIQBzRI6YI3fGHLGeUnOEHSYHadCgAVq1amV2+3vvvRdr1qxBYGBgrSsbeiEhIThw4AAefPBBADVXL7KysnDvvfeabN+5c2fodDrs2rULMTExtZ7XX1XSarWGcx06dIBarcaZM2fqvBrUvn17w6JRvf3799/9S95i7969aN68Od566y3DudOnT9dqd+bMGZw/fx6hoaGGz3Fzc0Pbtm0RFBSE0NBQnDx5EiNGjBD1+YrAESZFY4bcGTPEBhR6ZZj+why5M+aIDSg0R7jpg5MaMWIEAgICMHDgQPz444/Iy8vDzp078frrr+Ps2bMAgDfeeAPvvPMONmzYgKNHj+LVV1+9430LWrRogYSEBIwaNQobNmwwvOfatWsBAM2bN4dKpcLmzZtx6dIllJWVwcfHBxMnTsSECROwYsUKnDhxAocOHcJHH31kWLz4yiuv4Pjx45g0aRJycnKwatUqLF++XNT3bd26Nc6cOYPVq1fjxIkTmD9/vslFo15eXkhISMCvv/6KH3/8Ea+//jqGDBmC4OBgAMCMGTOQlpaG+fPn49ixY/j999+xbNkyzJs3T1Q9sqTAG8WR5ZghzBDRFHrDSbIcc4Q5IppCc4QdJidVv3597N69G+Hh4Rg8eDDat2+PF198ETdv3jRc5fnHP/6B559/HgkJCYiKioKPjw+efPLJO77vwoUL8fTTT+PVV19Fu3btMHr0aJSXlwMAmjZtihkzZmDq1KkICgrCuHHjAACzZs3CtGnTkJaWhvbt2+PRRx/Fli1bEBERAaBmLu8333yDDRs2IDIyEosWLcLcuXNFfd8nnngCEyZMwLhx49C1a1fs3bsX06ZNq9WuVatWGDx4MB577DH0798fXbp0Mdqq86WXXsJnn32GZcuWoXPnznjooYewfPlyQ62KJgiAoDPzkEdAkeWYIcwQ0URlCHPEFTBHmCOiKTRHVEJdq/KISBZKS0uh0WgQ7fE0PFT1zHpNtVCFHdVfo6SkpM5pFrc7d+4cpkyZgu+++w7Xr19Hq1atsGzZMvTo0cOa8olIYpZkCGBZjhCRMjkyRxYsWID3338fBQUFiIyMxEcffYSePXtaWrpZOMJEpBSiruiIW2R59epV9OnTB/Xq1cN3332HP/74A//617/g5+dnpy9DRA4nNkNkslibiBzIzjmyZs0aJCUlISUlBYcOHUJkZCRiY2Nx8eJFO32hGtz0gUghBJ0AQWXegLHYgeV3330XYWFhWLZsmeGcS0wtIHIhYjIEEJ8jRKR89s6RefPmYfTo0UhMTAQALFq0CFu2bMHnn39u0Y2KzcUOE5FCVAsVZl+pqUYVgJoh9Fup1WqTW7Ru3LgRsbGxeOaZZ7Br1y40bdoUr776qtE9JohI3sRkCPBXjhAR6VmaI+b8HqmsrERWVhaSk5MN59zc3BATE4N9+/ZZUfXdscNEJHOenp4IDg7GnoJvRb2uYcOGCAsLMzqXkpJidBNDvZMnT2LhwoVISkrCm2++iZ9//hmvv/46PD09kZCQYE35RCQxSzMEAIKDg41udEpErsmaHDH398jly5eh1WoRFBRkdD4oKAhHjx4V/blisMNEJHNeXl7Iy8tDZWWlqNcJggCVSmV0rq4bAOp0OvTo0cOw41C3bt1w+PBhLFq0iB0mIpmzNEOAmh9JXl5edqiKiOTEmhwR83tEKuwwESmAl5eXXX+0hISEoEOHDkbn2rdvj2+++cZun0lEjmPvDCEi5bN3jgQEBMDd3R2FhYVG5wsLCw33wLIX7pJHRHfVp08f5OTkGJ07duwYmjdvLlFFRERE5Eo8PT3RvXt3ZGRkGM7pdDpkZGQgKirKrp/NESYiuqsJEyagd+/emDt3LoYMGYKDBw9i8eLFWLx4sdSlERERkYtISkpCQkICevTogZ49eyI9PR3l5eWGXfPshTeuJSKzbN68GcnJyTh+/DgiIiKQlJTEXfKIiIjIoT7++GPDjWu7du2K+fPno1evXnb9THaYiIiIiIiI6sA1TERERERERHVgh4mIiIiIiKgO7DARERERERHVgR0mIiIiIiKiOrDDREREREREVAd2mIiIiIiIiOrADhMREREREVEd2GEiIiIiIiKqAztMREREREREdWCHiYiIiIiIqA7sMBEREREREdWBHSYiIiIiIqI6sMNERERERERUB3aYiIiIiIiI6sAOExERERERUR3YYSIiIiIiIqoDO0xERERERER1YIeJiIiIiIioDuwwERERERER1YEdJiIiIiIiojqww0RERERERFQHdpiIiIiIiIjqwA4TERERERFRHdhhIiIiIiIiqgM7TERERERERHVgh4mIiIiIiKgO7DARERERERHVgR0mIiIiIiKiOrDDREREREREVAd2mIiIiIiIiOrADhMREREREVEd2GEiIiIiIiKqAztMREREREREdWCHiYiIiIiIqA7sMBEREREREdWBHSYiIiIiIqI6sMNERERERERUB3aYiIiIiIiI6sAOExERERERUR3YYSIiIiIiIqoDO0xERERERER1YIeJiIiIiIioDuwwERERERER1YEdJiIiIiIiojqww0REZtm9ezfi4+MRGhoKlUqFDRs21Gpz5MgRPPHEE9BoNGjQoAHuu+8+nDlzxvHFEpFLMienbrdz507ce++9UKvVaNWqFZYvX273OolIXthhIiKzlJeXIzIyEgsWLDD5/IkTJ9C3b1+0a9cOO3fuxG+//YZp06bBy8vLwZUSkau6W07dLi8vDwMGDEB0dDSys7Mxfvx4vPTSS9i2bZudKyUiOVEJgiBIXQQRyYtKpcL69esxaNAgw7lhw4ahXr16+OKLL6QrjIjoT6Zy6nZTpkzBli1bcPjwYcO5YcOGobi4GFu3bnVAlUQkBx5SF0BE1rt58yYqKytFvUYQBKhUKqNzarUaarVa9OfrdDps2bIFkydPRmxsLH755RdEREQgOTn5jj9WiMg5WJIhAODp6SnrUeR9+/YhJibG6FxsbCzGjx9f52sqKipQUVFheKzT6VBUVITGjRvXylQicixBEHDt2jWEhobCzc12E+nYYSKSuZs3byKieUMUXNSKel3Dhg1RVlZmdC4lJQWpqamia7h48SLKysrwzjvvYPbs2Xj33XexdetWDB48GDt27MBDDz0k+j2JyDEszRAACA4ORl5enmw7TQUFBQgKCjI6FxQUhNLSUty4cQPe3t61XpOWloYZM2Y4qkQiskB+fj6aNWtms/djh4lI5iorK1FwUYu8rObw9THvakrpNR0iup9Gfn4+fH19DectGV0Caq6wAsDAgQMxYcIEAEDXrl2xd+9eLFq0iB0mIidmSYYAf+VIZWWlbDtMlkhOTkZSUpLhcUlJCcLDw2vlKRE5XmlpKcLCwuDj42PT92WHiUghGjSsOcyh/XPloq+vr03+Ax8QEAAPDw906NDB6Hz79u2xZ88eq9+fiOxPTIYAf+WInAUHB6OwsNDoXGFhIXx9fU2OLgF1T122VZ4SkfVsPT2WHSYihdBBgA7m/YIxt525PD09cd999yEnJ8fo/LFjx9C8eXObfhYR2YeYDNG3l7uoqCh8++23Rue2b9+OqKgoiSoiImfEDhORQuigg05EW7HKysqQm5treJyXl4fs7Gz4+/sjPDwckyZNwtChQ/Hggw8iOjoaW7duxaZNm7Bz507Rn0VEjicmQ/Ttnc3dcio5ORnnzp3DypUrAQCvvPIKPv74Y0yePBmjRo3CDz/8gLVr12LLli1SfQUickLsMBEphFYQoDXzLgHmtrtVZmYmoqOjDY/1c/gTEhKwfPlyPPnkk1i0aBHS0tLw+uuvo23btvjmm2/Qt29f0Z9FRI4nJkP07Z3N3XLqwoULRjfTjoiIwJYtWzBhwgR8+OGHaNasGT777DPExsY6vHYicl68DxORzJWWlkKj0eD00VBRmz40b3ceJSUlnHNP5OIsyRCAOaKn//Nz9T8HImdgr3+PHGEiUggdBGglWsNERPInJkP07YmIXAE7TEQKIeWmD0Qkf6646QMRkTnYYSJSCHuvYSIiZVPCGiYiIntgh4lIIXR/Hua2JSK6lZgM0bcnInIF7DARKYRWxPoDMesUiMg1iMkQfXsiIlfADhORQmiFmsPctkREtxKTIfr2RESugB0mIoXglDwisgan5BERmcYOE5FC6KCCFiqz2xIR3UpMhujbExG5AnaYiBRCJ9Qc5rYlIrqVmAzRtycicgXsMBEphFbE1WExV5GJyDWIyRB9eyIiV+AmdQFERERERETOiiNMRArBESYisgZHmIiITGOHiUghdIIKOsHMTR/MbEdErkNMhujbExG5AnaYiBSCI0xEZA2OMBERmcYOE5FCaOEGrZnLErV2roWI5EdMhtS0JyJyDewwESmEIGI6jcCpNER0GzEZom9PROQK2GEiUghOySMia3BKHhGRadxWXMF+/vlnjBs3Dh07dkSDBg0QHh6OIUOG4NixY7XaHjlyBI8++igaNmwIf39/PP/887h06VKtdnPmzMETTzyBoKAgqFQqpKam1vn533//PaKjoxEQEIBGjRqhZ8+e+OKLL2z5FekWWsFN1EFkDqlzZPXq1bj33nvh5eWFJk2a4MUXX8Tly5dt+RXpT2IzhDlCRK6CI0wK9u677+Knn37CM888gy5duqCgoAAff/wx7r33Xuzfvx+dOnUCAJw9exYPPvggNBoN5s6di7KyMvzzn//E77//joMHD8LT09Pwnm+//TaCg4PRrVs3bNu2rc7P3rhxIwYNGoSoqCikpqZCpVJh7dq1eOGFF3D58mVMmDDB7t/f1eiggs7MayA6CHauhpRCyhxZuHAhXn31VTz88MOYN28ezp49iw8//BCZmZk4cOAAvLy87P79XYmYDKlpzxwhItfADpOCJSUlYdWqVUY/VIYOHYrOnTvjnXfewb///W8AwNy5c1FeXo6srCyEh4cDAHr27IlHHnkEy5cvx8svv2x4fV5eHlq0aIHLly+jSZMmdX72xx9/jJCQEPzwww9Qq9UAgL///e9o164dli9fzg6THXBKHtmDVDlSWVmJN998Ew8++CC2b98Olarm72zv3r0RHx+PJUuW4LXXXrPX13ZJnJJHRGQax9MVrHfv3kY/cgCgdevW6NixI44cOWI498033+Dxxx83/MgBgJiYGLRp0wZr1641en2LFi3M+uzS0lL4+fkZOksA4OHhgYCAAHh7e1vwbehuOJWG7EGqHDl8+DCKi4sxdOhQQ2cJAB5//HE0bNgQq1evtvAbUV04JY+IyDSmnYsRBAGFhYUICAgAAJw7dw4XL15Ejx49arXt2bMnfvnlF4s+p1+/fvjf//6HadOmITc3FydOnMCsWbOQmZmJyZMnW/UdyLSa6TTmH0SWckSOVFRUAIDJCyze3t745ZdfoNPpRL8v1U1shjBHiMhVsMPkYr788kucO3cOQ4cOBQBcuHABABASElKrbUhICIqKigw/XMSYNm0ahgwZgjlz5qB169Zo1aoV3nnnHXzzzTcYPHiwdV+CTNL9eQ8Vcw4x6xSIbueIHGndujVUKhV++ukno/M5OTm4dOkSbty4gatXr1r4DcgUMRnCHCEiV8I1TC7k6NGjGDt2LKKiopCQkAAAuHHjBgAYTZ3T0y+ovnHjhsnn70StVqNNmzZ4+umnMXjwYGi1WixevBjPPfcctm/fjvvvv9/Kb0O3EzNFRitwsTZZxlE5EhAQgCFDhmDFihVo3749nnzySZw7dw6vvfYa6tWrh6qqKsPnkm2InWbHHCEiV8HLQy6ioKAAAwYMgEajwddffw13d3cAf013MXX19+bNm0ZtxBg3bhw2bdqE1atXY9iwYRgxYgS+//57hISE4I033rDim1BddH9e8TX3IBLL0Tny6aef4rHHHsPEiRNxzz334MEHH0Tnzp0RHx8PAGjYsKGlX4VMEJshYnMkLS0N9913H3x8fBAYGIhBgwYhJyfHqM3NmzcxduxYNG7cGA0bNsRTTz2FwsJCW35NIiLR+KvJBZSUlCAuLg7FxcXYunUrQkNDDc/pp9Dop9Tc6sKFC/D39xc9ulRZWYmlS5diwIABcHP7669YvXr1EBcXh8zMTFRWVlr4baguWkEl6iASw9E5AgAajQb/+c9/cPr0aezatQunTp3CF198gQsXLqBJkyZo1KiRxd+HahObIWJzZNeuXRg7diz279+P7du3o6qqCv3790d5ebmhzYQJE7Bp0yb83//9H3bt2oXz589zGjcRSY5T8hTu5s2biI+Px7Fjx/D999+jQ4cORs83bdoUTZo0QWZmZq3XHjx4EF27dhX9mVeuXEF1dTW0Wm2t56qqqqDT6Uw+R9bRryswry2n0pD5pMiRW4WHhxt23ysuLkZWVhaeeuopq96TahOTITXtxeXI1q1bjR4vX74cgYGByMrKwoMPPoiSkhIsXboUq1atwt/+9jcAwLJly9C+fXvs37+fU7mJSDIcYVIwrVaLoUOHYt++ffi///s/REVFmWz31FNPYfPmzcjPzzecy8jIwLFjx/DMM8+I/tzAwEA0atQI69evNxpJKisrw6ZNm9CuXTtuLU4kE1LlSF2Sk5NRXV3Ne7k5kdLSUqPD3A0+SkpKAAD+/v4AgKysLFRVVSEmJsbQpl27dggPD8e+fftsXzgRkZk4wqRg//jHP7Bx40bEx8ejqKjIcINJveeeew4A8Oabb+L//u//EB0djTfeeANlZWV4//330blzZyQmJhq95osvvsDp06dx/fp1AMDu3bsxe/ZsAMDzzz+P5s2bw93dHRMnTsTbb7+N+++/Hy+88AK0Wi2WLl2Ks2fP1qqDbEMnuEFn5oJtnQWLtXfv3o33338fWVlZuHDhAtavX49BgwaZbPvKK6/g008/xQcffIDx48eL/ixyHlLlCAC88847OHz4MHr16gUPDw9s2LAB//3vfzF79mzcd9999v7qLkdMhtS0r8mRsLAwo/MpKSlITU2982t1OowfPx59+vRBp06dANSskfP09Kw11TIoKAgFBQVm10VEZGvsMClYdnY2AGDTpk3YtGlTref1P3TCwsKwa9cuJCUlYerUqfD09MSAAQPwr3/9q9a6g6VLl2LXrl2Gxzt27MCOHTsAAH379jX80HnrrbcQERGBDz/8EDNmzEBFRQW6dOmCr7/+mlNp7MTeU/LKy8sRGRmJUaNG3XFNwfr167F//36jNS4kX1LmSOfOnbF+/Xps3LgRWq0WXbp0wdq1a206YkV/sXRKXn5+Pnx9fQ3nzVmvNnbsWBw+fBh79uwRXygRkYOxw6RgO3fuNLttx44dsW3bNpu+57PPPotnn33W7PZkHR1g9iJs/e0+S0tLjc6r1eo6f+zExcUhLi7uju+r3/Z527ZtGDBggFm1kHOTMkcGDBjAv0cOJCZD9O0BwNfX16jDdDfjxo3D5s2bsXv3bjRr1sxwPjg4GJWVlSguLjYaZSosLERwcLDZ709EZGtcw0SkEJZsBxwWFgaNRmM40tLSLP98nQ7PP/88Jk2ahI4dO9rqaxGRg9h7W3FBEDBu3DisX78eP/zwAyIiIoye7969O+rVq4eMjAzDuZycHJw5c6bOtXNERI7AESYihRB349qadpZMpanLu+++Cw8PD7z++usWvwcRSUf8jWvFdZjGjh2LVatW4T//+Q98fHwM65I0Gg28vb2h0Wjw4osvIikpCf7+/vD19cVrr72GqKgo7pBHRJJih4lIIXRQQQdzp+TVtBM7laYuWVlZ+PDDD3Ho0CGoVLzHE5EcickQfXsxFi5cCADo16+f0flly5Zh5MiRAIAPPvgAbm5ueOqpp1BRUYHY2Fh88sknoj6HiMjW2GEiUghLRphs5ccff8TFixcN98oBaraj/sc//oH09HScOnXKpp9HRLZn7xEmwYzdOb28vLBgwQIsWLBA1HsTEdkTO0xECiFulzzbdpief/55o3unAEBsbCyef/75WltKE5FzEr9LHpdBE5FrkHWHSafT4fz58/Dx8eE0IFIUQRBw7do1hIaGws3N3HsrqaAzd5c8ETth6ZWVlSE3N9fwOC8vD9nZ2fD390d4eDgaN25s1L5evXoIDg5G27ZtRX+WIzFHSInsnSH69kRErkDWHabz58/XumEekZLk5+cbbbt7JzoRV4fF7m4FAJmZmYiOjjY8TkpKAgAkJCRg+fLlot/PWTBHSMnslSH69kRErkDWHSYfHx8AQNMPpsLN2/Ldvcg86jz+GTuKruImTqbPNPwdN+s1ght0Zq4pMLfdrfr162fWGgQ9uaxb0v8Z92v2EjzcPCWuRvlyX2oqdQkuQXfzJs7MnWW3DNG3JyJyBbLuMOmnz7h5q+Hm7SVxNcrnbsWW02QZMVPEtFBBa+auVea2cwX6P2MPN094uPHvuL25eTGrHcleGaJvT0TkCmTdYSKiv9h7hImIlI0jTEREprHDRKQQWph/xVdr31KISIbEZIi+PRGRK2CHiUghOMJERNbgCBMRkWlMOyKF0N900tyDiOhWYjPEWXNkwYIFaNGiBby8vNCrVy8cPHjwju3T09PRtm1beHt7IywsDBMmTMDNmzcdVC0RyYFzph0RERGRSGvWrEFSUhJSUlJw6NAhREZGIjY2FhcvXjTZftWqVZg6dSpSUlJw5MgRLF26FGvWrMGbb77p4MqJyJmxw0SkEAJU0Jl5CNzdiohuIyZDnDVH5s2bh9GjRyMxMREdOnTAokWLUL9+fXz++ecm2+/duxd9+vTBs88+ixYtWqB///4YPnz4XUeliMi1sMNEpBBKmEpDRNKR+5S8yspKZGVlISYmxnDOzc0NMTEx2Ldvn8nX9O7dG1lZWYYO0smTJ/Htt9/iscceq/NzKioqUFpaanQQkbJx0wcihdAJKugE8674mtuOiFyHmAzRt3cmly9fhlarRVBQkNH5oKAgHD161ORrnn32WVy+fBl9+/aFIAiorq7GK6+8cscpeWlpaZgxY4ZNayci5+Zcl4eIyGJauIk6iIhuJTZDlJAjO3fuxNy5c/HJJ5/g0KFDWLduHbZs2YJZs2bV+Zrk5GSUlJQYjvz8fAdWTERS4AgTkUJwhImIrCH3EaaAgAC4u7ujsLDQ6HxhYSGCg4NNvmbatGl4/vnn8dJLLwEAOnfujPLycrz88st466234OZWu1OoVquhVqtt/wWIyGnJ//IQEQEAdHATdRAR3Upshjhbjnh6eqJ79+7IyMgwnNPpdMjIyEBUVJTJ11y/fr1Wp8jd3R0AIAiC/YolIlnhCBORQmgFFbRmXvE1tx0RuQ4xGaJv72ySkpKQkJCAHj16oGfPnkhPT0d5eTkSExMBAC+88AKaNm2KtLQ0AEB8fDzmzZuHbt26oVevXsjNzcW0adMQHx9v6DgREbHDRKQQnJJHRNaQ+5Q8ABg6dCguXbqE6dOno6CgAF27dsXWrVsNG0GcOXPGaETp7bffhkqlwttvv41z586hSZMmiI+Px5w5c6T6CkTkhNhhIlIIQXCDzsxtfgUn2w6YiKQnJkP07Z3RuHHjMG7cOJPP7dy50+ixh4cHUlJSkJKS4oDKiEiu2GEiUggtVNCaeSNJc9sRkesQkyH69kREroAdJiKF0AnmT5HRcS0zEd1GTIbo2xMRuQJ2mIgUQidiOo2YaTdE5BrEZIi+PRGRK2CHiUghdFBBZ+YUGXPbEZHrEJMh+vZERK6AHSYiheC24kRkDSVsK05EZA/sMBEpBKfkEZE1OCWPiMg0dpiIFEIHEfdh4lQaIrqNmAzRtycicgW8PERERERERFQHjjARKYQgYsG2wCvDRHQbMRmib09E5ArYYSJSCJ0gYkoeF2sT0W3EZIi+PRGRK2CHiUghuOkDEVmDmz4QEZnGDhORQnCEiYiswREmIiLTeHmISCH0N5009xBr9+7diI+PR2hoKFQqFTZs2GB4rqqqClOmTEHnzp3RoEEDhIaG4oUXXsD58+dt+A2JyJ7EZgh3ySMiV8EOE5FC6K8Om3uIVV5ejsjISCxYsKDWc9evX8ehQ4cwbdo0HDp0COvWrUNOTg6eeOIJW3w1InIAsRnCESYichWckkekEPaekhcXF4e4uDiTz2k0Gmzfvt3o3Mcff4yePXvizJkzCA8PF/15RORYnJJHRGQaO0xECmFJh6m0tNTovFqthlqttkk9JSUlUKlUaNSokU3ej4jsix0mIiLTOCWPSCEsmUoTFhYGjUZjONLS0mxSy82bNzFlyhQMHz4cvr6+NnlPIrIvTskjIjKNI0xECiEAIm5cWyM/P9+oQ2OL0aWqqioMGTIEgiBg4cKFVr8fETmGmAzRtycicgXsMBEphCVT8nx9fW06AqTvLJ0+fRo//PADR5eIZIRT8oiITGOHiUghpL4Pk76zdPz4cezYsQONGze2+WcQkf2ww0REZBo7TEQKYe8OU1lZGXJzcw2P8/LykJ2dDX9/f4SEhODpp5/GoUOHsHnzZmi1WhQUFAAA/P394enpKfrziMix2GEiIjKNHSYihbB3hykzMxPR0dGGx0lJSQCAhIQEpKamYuPGjQCArl27Gr1ux44d6Nevn+jPIyLHYoeJiMg0dpiIFEIQVBDM/AFjbrtb9evXD4JQ9zLvOz1HRM5PTIbo2xMRuQJ2mIgUQgeV2TtcidkJi4hcg5gM0bcnInIF7DDZiVfONfh9Wwiv09fhUVyF86/dg/Lujf5qIAjwX38Bml2X4HZdi5utG+LiC+GoCvaSrGalcFPpMLZHJuLbHENA/eu4WN4AG3LaYlFWd4D/gScZe+aFXPR+6AKaNS9DZYU7jvzuh2WftMe5Mw2lLk327gs8j5c6/oqO/pcQVP86xuyMxff5EYbn+4edxPA2f6Bj40vwU1fgic1P48jVAAkrJiIiR3GKG9cuWLAALVq0gJeXF3r16oWDBw9KXZLV3Cp0qAz3xsXnw0w+7/dtIRptv4iLCc2RP70ddGo3NP3XcagqdQ6uVHle6vYLhnX8H2b/+AAeXz0M8/bfjxe7ZuO5zr9LXZpdufINJ5WYIaZ07nYFW75pgX+M7ou337gfHh4CZqcfgNqrWurSZM/boxpHrzbGjIMP1Pl81sVgvH/ofgdX5ji8cS0RkWmSjzCtWbMGSUlJWLRoEXr16oX09HTExsYiJycHgYGBUpdnsetdNLjeRWP6SUFAo/8WouiJYJTf2wgAUDg6AhGv/4oGh4pRdr+/4wpVoK5BhfjhVAvsPtMcAHD+mi8ea30cnQMvSlyZfdl7DZOzUmqGmDJ9Qi+jx/NmR+Kr77ajVbsS/C+b27hbY/f5cOw+H17n8//JawMAaNqg1FElORzXMBERmSb5CNO8efMwevRoJCYmokOHDli0aBHq16+Pzz//XOrS7MbjUiU8SqpxvcNfN/XU1XfHzXsawOtEuYSVKUN2YRDub3oOzTXFAIC2jS/j3uAC/Him7h9DSuCqV4ZdMUP0GjSsGVkqK60ncSWkBBxhIiIyTdIRpsrKSmRlZSE5Odlwzs3NDTExMdi3b1+t9hUVFaioqDA8Li2V55U+j5IqAIBWY/wjR+tbz/AcWW7JoXvRoF4Vtgz/ClqdG9zddPjwQC9sPt5G6tLsyhVHmMRmCKCcHFGpBLw8/n/4369+OH3S9+4vILoLjjAREZkm6QjT5cuXodVqERQUZHQ+KCjIcNPLW6WlpUGj0RiOsDDT64PItT3aKhePtzmGSd/H4Omvn0byD39DYtdsDGx7VOrS7EoQcVVYKT90xGYIoJwcGTPxMJq3vIZ3p90rdSmkEGIyxJIc2b17N+Lj4xEaGgqVSoUNGzYYPT9y5EioVCqj49FHH7XhNyQisozkU/LESE5ORklJieHIz8+XuiSLVP85suR+22iSe2mV4Tmy3MSoffjs0L34Lrc1jhc1xqZjbbHi10iM7vaL1KXZlQBAEMw8pC5WQkrIkVf+8Tt69ilE8tgoXLnkLXU5pBCiMsSCHCkvL0dkZCQWLFhQZ5tHH30UFy5cMBxfffWVVd+JiMgWJJ2SFxAQAHd3dxQWFhqdLywsRHBwcK32arUaarXaUeXZTXUTT1RrPFD/j2uobF4fAOB2QwuvE+UoiW4icXXy5+1Rjdv3GtQJKriplN1N0EEFlYvdh0lshgByzxEBr/zjMKIeKkDyq1EovFBf6oJIQcRkiL69GHFxcYiLi7tjG7VaXee/XSIiqUg6wuTp6Ynu3bsjIyPDcE6n0yEjIwNRUVESVmY91U0tPE9fh+fp6wCAepcr4Hn6OjyuVAIqFYr7B8F/0wU0+KUYnvk3ELQ4D1q/eoZd88hyO061wN/vPYQHw08j1KcUD0ecRELkr/g+L+LuL5Yx/foDcw8lUHKGmPLqxMOIjj2H91PuxY3rHvDzvwk//5vwVGulLk326ntUob3fZbT3uwwAaNawFO39LiOk/jUAgMbzJtr7XUYrzVUAQIRvMdr7XUaA13XJarY1sRmiz5HS0lKj49Y1gmLt3LkTgYGBaNu2LcaMGYMrV67Y6usREVlM8m3Fk5KSkJCQgB49eqBnz55IT09HeXk5EhMTpS7NKl5519Hs3WOGx02+OgsAKO3TGIWjW+DqY0FQVegQuOx0zY1r2zTEuX+0huApq1mSTmnOnr54vedBTH9wN/y9b+BieQOs/aMDFmb2kLo0u9IJKqjM7AgpaXcrpWaIKQOeOg0AePcT4w0tPpgVie+/ledaLGfRqfFFfNl/k+HxWz1q/ozXnWiDKXv/hoebncK7fXYanv/wwe8BAPN/7Y6PfrvPobXai5gM0bcHUGsdYEpKClJTU0V//qOPPorBgwcjIiICJ06cwJtvvom4uDjs27cP7u7uot+PiMhWJO8wDR06FJcuXcL06dNRUFCArl27YuvWrbUWccvNjfY+OL68e90NVCoUDQ5F0eBQxxXlIq5XeeKdn/rinZ/6Sl2KQ+nXFZjbVimUmiGmDIh6XOoSFOtgYVO0/uKVOp9fd7Id1p1s58CKHE9MhujbA0B+fj58ff/aqdHSKa/Dhg0z/P/OnTujS5cuuOeee7Bz5048/PDDFr0nEZEtSN5hAoBx48Zh3LhxUpdBJGuuuK24HjOEyHqWbivu6+tr1GGylZYtWyIgIAC5ubnsMBGRpJyiw0RE1nPlDhMRWc/Z7sN09uxZXLlyBSEhIXb9HCKiu2GHiUghXHUNExHZhqVrmMxVVlaG3Nxcw+O8vDxkZ2fD398f/v7+mDFjBp566ikEBwfjxIkTmDx5Mlq1aoXY2FhRn0NEZGvsMBEphKuuYSIi27B0DZO5MjMzER0dbXiclJQEAEhISMDChQvx22+/YcWKFSguLkZoaCj69++PWbNmyfg2AESkFOwwESlEzY8dc6fk2bkYIpIdMRmiby9Gv379INzhRdu2bRP3hkREDsIOE5FCcA0TEVnD2dYwERE5C3aYiBRC+PMwty0R0a3EZIi+PRGRK+BdUomIiIiIiOpg1gjTxo0bzX7DJ554wuJiiMhyzj4ljzlC5NyUMiVvwYIFeP/991FQUIDIyEh89NFH6NmzZ53ti4uL8dZbb2HdunUoKipC8+bNkZ6ejscee8yBVRORMzOrwzRo0CCz3kylUkGr1VpTDxFZysnn5DFHiJycAubkrVmzBklJSVi0aBF69eqF9PR0xMbGIicnB4GBgbXaV1ZW4pFHHkFgYCC+/vprNG3aFKdPn0ajRo0cXzwROS2zOkw6nc7edRCRtcRcHZbgyjBzhMjJiRxhkiJH7mbevHkYPXo0EhMTAQCLFi3Cli1b8Pnnn2Pq1Km12n/++ecoKirC3r17Ua9ePQBAixYtHFkyEcmAVWuYbt68aas6iMhK+nuomHs4C+YIkXMQmyHOlCNAzWhRVlYWYmJiDOfc3NwQExODffv2mXzNxo0bERUVhbFjxyIoKAidOnXC3Llz7zjKXVFRgdLSUqODiJRNdIdJq9Vi1qxZaNq0KRo2bIiTJ08CAKZNm4alS5favEAiMo9+/YG5h5SYI0TOR2yGSJ0jt7t8+TK0Wi2CgoKMzgcFBaGgoMDka06ePImvv/4aWq0W3377LaZNm4Z//etfmD17dp2fk5aWBo1GYzjCwsJs+j2IyPmI7jDNmTMHy5cvx3vvvQdPT0/D+U6dOuGzzz6zaXFEJIKgEndIiDlC5ITEZoiTdZgsodPpEBgYiMWLF6N79+4YOnQo3nrrLSxatKjO1yQnJ6OkpMRw5OfnO7BiIpKC6A7TypUrsXjxYowYMQLu7u6G85GRkTh69KhNiyMi88lpKg1zhMj5yH1KXkBAANzd3VFYWGh0vrCwEMHBwSZfExISgjZt2hjlUPv27VFQUIDKykqTr1Gr1fD19TU6iEjZRHeYzp07h1atWtU6r9PpUFVVZZOiiMgCgshDQswRIickNkOcrMPk6emJ7t27IyMjw3BOp9MhIyMDUVFRJl/Tp08f5ObmGm1Kc+zYMYSEhBiNfhORaxPdYerQoQN+/PHHWue//vprdOvWzSZFEZF49l57sHv3bsTHxyM0NBQqlQobNmy47fMFTJ8+HSEhIfD29kZMTAyOHz9u8r2YI0TOR+5rmAAgKSkJS5YswYoVK3DkyBGMGTMG5eXlhl3zXnjhBSQnJxvajxkzBkVFRXjjjTdw7NgxbNmyBXPnzsXYsWOl+gpE5ITM2lb8VtOnT0dCQgLOnTsHnU6HdevWIScnBytXrsTmzZvtUSMRmcuOV3zLy8sRGRmJUaNGYfDgwbWef++99zB//nysWLECERERmDZtGmJjY/HHH3/Ay8vLqC1zhMhJOdmokVhDhw7FpUuXMH36dBQUFKBr167YunWrYSOIM2fOwM3tr2vFYWFh2LZtGyZMmIAuXbqgadOmeOONNzBlyhSpvgIROSHRHaaBAwdi06ZNmDlzJho0aIDp06fj3nvvxaZNm/DII4/Yo0YiMoOYK76WXBmOi4tDXFxcHe8nID09HW+//TYGDhwIoGadUlBQEDZs2IBhw4YZtWeOEDkfsaNGzjjCBADjxo3DuHHjTD63c+fOWueioqKwf/9+O1dFRHImusMEAA888AC2b99u61qIyBpi1hT82e72+4eo1Wqo1WrRH52Xl4eCggKj+59oNBr06tUL+/btq9VhApgjRE5H7LokmY9GERGZy6IOEwBkZmbiyJEjAGrWI3Tv3t1mRRGRJVR/Hua2Ra37h6SkpCA1NVX0J+vvcSLm/icAc4TIuYjJEH17IiLlE91hOnv2LIYPH46ffvoJjRo1AgAUFxejd+/eWL16NZo1a2brGonIHBaMMOXn5xttiWvJ6JIlmCNETogjTEREJoneJe+ll15CVVUVjhw5gqKiIhQVFeHIkSPQ6XR46aWX7FEjEZnDgu2Ab7+XiKUdJv09Tsy9/wlzhMgJyXxbcSIiexE9wrRr1y7s3bsXbdu2NZxr27YtPvroIzzwwAM2LY6IRBBUNYe5bW0oIiICwcHByMjIQNeuXQHUrI86cOAAxowZU6s9c4TICYnJEH17IiIXILrDFBYWZvLGklqtFqGhoTYpioicT1lZGXJzcw2P8/LykJ2dDX9/f4SHh2P8+PGYPXs2WrdubdhWPDQ0FIMGDar1XswRIiIikgvRU/Lef/99vPbaa8jMzDScy8zMxBtvvIF//vOfNi2OiMwnCOIOsTIzM9GtWzfDjWWTkpLQrVs3TJ8+HQAwefJkvPbaa3j55Zdx3333oaysDFu3bq11DyaAOULkjMRmiCU5QkQkR2aNMPn5+UGl+mvovby8HL169YKHR83Lq6ur4eHhgVGjRpm8mkxEDmDBpg9i9OvXD8IdfiGpVCrMnDkTM2fONPk8c4TIyXHTByIik8zqMKWnp9u5DCKymoRrmMzBHCFyclzDRERkklkdpoSEBHvXQURWUgk1h7ltHY05QuTcxGSIvj0RkSuw+Ma1AHDz5k1UVlYanbv1ni5E5EB2npJnL8wRIifBKXlERCaJ3vShvLwc48aNQ2BgIBo0aAA/Pz+jg4gkop9OY+4hIeYIkRMSmyGckkdELkJ0h2ny5Mn44YcfsHDhQqjVanz22WeYsgL4CQAAMZRJREFUMWMGQkNDsXLlSnvUSETmkNENJ5kjRE6IN64lIjJJ9JS8TZs2YeXKlejXrx8SExPxwAMPoFWrVmjevDm+/PJLjBgxwh51EtHdyGhKHnOEyAlxSh4RkUmiR5iKiorQsmVLADXrDIqKigAAffv2xe7du21bHRGZT0ZXhpkjRE6II0xERCaJ7jC1bNkSeXl5AIB27dph7dq1AGquGDdq1MimxRGRCDJae8AcIXJCXMNERGSS6A5TYmIifv31VwDA1KlTsWDBAnh5eWHChAmYNGmSzQskIvPotwQ295ASc4TI+YjNEKlzhIjIUUSvYZowYYLh/8fExODo0aPIyspCq1at0KVLF5sWR0QiyGgNE3OEyAlxDRMRkUlW3YcJAJo3b47mzZvbohYiclHMESIiInJWZnWY5s+fb/Ybvv766xYXQ0SWU8H8KTJSrDxgjhA5NzEZom9PROQKzOowffDBB2a9mUqlkuSHzj2vZMNDVc/hn+tqtp3PlroEl1F6TQe/d0W+SMwibAkWazt7jlSfOQcwR+zu+PObpC7BJZRe08FvusgXid3IgZs+EJGLMKvDpN/NioicmJOvYWKOEDk5rmEiIjJJ9C55RERERERErsLqTR+IyEk4+QgTETk5jjAREZnEDhORQoi5Lwrvn0JEtxN7byXmCBG5CnaYiJSCI0xEZA2OMBERmcQOE5FSsMNERNZgh4mIyCSLNn348ccf8dxzzyEqKgrnzp0DAHzxxRfYs2ePTYsjIvPpp9OYe0iNOULkXMRmiDPkCBGRI4juMH3zzTeIjY2Ft7c3fvnlF1RUVAAASkpKMHfuXJsXSERm0t9DxdxDQswRIickNkN4HyYichGiO0yzZ8/GokWLsGTJEtSr99dNHvv06YNDhw7ZtDgiEkEQeUiIOULkhMRmCEeYiMhFiF7DlJOTgwcffLDWeY1Gg+LiYlvUREQWkNMuecwRIufDXfKIiEwTPcIUHByM3NzcWuf37NmDli1b2qQoIrKAjK4MM0eInBBHmIiITBLdYRo9ejTeeOMNHDhwACqVCufPn8eXX36JiRMnYsyYMfaokYjMIWahtsQ/dJgjRE5I7IYP7DARkYsQPSVv6tSp0Ol0ePjhh3H9+nU8+OCDUKvVmDhxIl577TV71EhE5pDRtuLMESInxG3FiYhMEj3CpFKp8NZbb6GoqAiHDx/G/v37cenSJcyaNcse9RGRuWQ0lYY5QuSE7Dwlb/fu3YiPj0doaChUKhU2bNhg/PGCgOnTpyMkJATe3t6IiYnB8ePHrftOREQ2YNF9mADA09MTHTp0QM+ePdGwYUNb1kREFpDj/VOYI0TOw973YSovL0dkZCQWLFhg8vn33nsP8+fPx6JFi3DgwAE0aNAAsbGxuHnzpg2+HRGR5URPyYuOjoZKVfe9F3744QerCiIi56PVapGamop///vfKCgoQGhoKEaOHIm33377jnlQF+YIkeuJi4tDXFycyecEQUB6ejrefvttDBw4EACwcuVKBAUFYcOGDRg2bJgjSyUiMiK6w9S1a1ejx1VVVcjOzsbhw4eRkJBgq7qISCw7rmF69913sXDhQqxYsQIdO3ZEZmYmEhMTodFo8Prrr4utlDlC5IwsXMNUWlpqdFqtVkOtVov66Ly8PBQUFCAmJsZwTqPRoFevXti3bx87TEQkKdEdpg8++MDk+dTUVJSVlVldEBFZxp73Ydq7dy8GDhyIAQMGAABatGiBr776CgcPHhRZZQ3mCJHzsfQ+TGFhYUbnU1JSkJqaKuqzCwoKAABBQUFG54OCggzPERFJxeI1TLd77rnn8Pnnn9vq7YjIAUpLS42OiooKk+169+6NjIwMHDt2DADw66+/Ys+ePXVOr7EUc4RIfvLz81FSUmI4kpOTpS6JiMimRI8w1WXfvn3w8vKy1dsRkSVEjhyZe2V46tSpKC0tRbt27eDu7g6tVos5c+ZgxIgRVhRbG3OESGIWbAjj6+sLX19fqz42ODgYAFBYWIiQkBDD+cLCwlpTeImIHE10h2nw4MFGjwVBwIULF5CZmYlp06bZrDAiEsmCNUz5+flGP3TqWnewdu1afPnll1i1ahU6duyI7OxsjB8/HqGhoRatOWKOEDkhCe/DFBERgeDgYGRkZBg6SKWlpThw4ABvZk1EkhPdYdJoNEaP3dzc0LZtW8ycORP9+/e3WWFEJI4la5jMvTI8adIkTJ061bDwunPnzjh9+jTS0tIs6jAxR4icj6VrmMxVVlaG3Nxcw+O8vDxkZ2fD398f4eHhGD9+PGbPno3WrVsjIiIC06ZNQ2hoKAYNGiTug4iIbExUh0mr1SIxMRGdO3eGn5+fvWoiIkvYcZe869evw83NeMmju7s7dDqduDcCc4TIadl5hCkzMxPR0dGGx0lJSQCAhIQELF++HJMnT0Z5eTlefvllFBcXo2/fvti6dSun6RKR5ERt+uDu7o7+/fujuLjYTuUQkaXsecPJ+Ph4zJkzB1u2bMGpU6ewfv16zJs3D08++aToOpkjRM7J3jeu7devHwRBqHUsX7685vNVKsycORMFBQW4efMmvv/+e7Rp00b091iwYAFatGgBLy8v9OrVy+zdPFevXg2VSsURLSKqRfQueZ06dcLJkyftUQsRWUMQeYjw0Ucf4emnn8arr76K9u3bY+LEifj73/+OWbNmWVQqc4TICYnNEBuuYbKVNWvWICkpCSkpKTh06BAiIyMRGxuLixcv3vF1p06dwsSJE/HAAw84qFIikhPRHabZs2dj4sSJ2Lx5My5cuFBrW2Iikogdf+j4+PggPT0dp0+fxo0bN3DixAnMnj0bnp6eFpXKHCFyQgroMM2bNw+jR49GYmIiOnTogEWLFqF+/fp3vF2BVqvFiBEjMGPGDLRs2dKB1RKRXJjdYZo5cybKy8vx2GOP4ddff8UTTzyBZs2awc/PD35+fmjUqBHXIxBJyJ5TaWyFOULkvOw9Jc/eKisrkZWVhZiYGMM5Nzc3xMTEYN++fXW+bubMmQgMDMSLL75o1udUVFTwIg+RizF704cZM2bglVdewY4dO+xZDxFZyo6bPtgKc4TIiUm4rbgtXL58GVqtFkFBQUbng4KCcPToUZOv2bNnD5YuXYrs7GyzPyctLQ0zZsywplQikhmzO0yCUJOMDz30kN2KISIryKDDxBwhcmIy7zCJde3aNTz//PNYsmQJAgICzH5dcnKyYYc/oOZ+UbffBJyIlEXUtuIqlcpedRCRlSy5D5MUmCNEzsne92Gyt4CAALi7u6OwsNDofGFhIYKDg2u1P3HiBE6dOoX4+HjDOf2tEjw8PJCTk4N77rmn1uvUanWdN/kmImUS1WFq06bNXX/sFBUVWVUQEVlIBiNMAHOEyGnJfITJ09MT3bt3R0ZGhmFrcJ1Oh4yMDIwbN65W+3bt2uH33383Ovf222/j2rVr+PDDDzlqREQGojpMM2bMgEajsVctRGQFuYwwMUeInJPcR5iAmpvhJiQkoEePHujZsyfS09NRXl6OxMREAMALL7yApk2bIi0tDV5eXujUqZPR6xs1agQAtc4TkWsT1WEaNmwYAgMD7VULEVlDJiNMzBEiJyXzESYAGDp0KC5duoTp06ejoKAAXbt2xdatWw0bQZw5cwZubqLvqEJELs7sDhPXHRA5ORl0mJgjRE5MAR0mABg3bpzJKXgAsHPnzju+dvny5bYviIhkT/QueUTknFR/Hua2lQJzhMh5ickQfXsiIldgdodJv3MMETkpGYwwMUeInJhCRpiIiGyNE3mJiIiIiIjqIGrTByJyXnLZJY+InJMSdskjIrIHdpiIlEIGU/KIyIlxSh4RkUnsMBEpCX/AEJE1mCFERLWww+QgQ8cVos9jJQhrVYHKm274I7M+ls4JwdkTXlKXpgi/72+A//skEMd/r4+iwnpIWZqH3nElRm3OHFdj6exQ/La/IbTVQPM2FZi2JA+Bzaokqtq2OCXPdcSPvIynx1yEf5NqnPzDG5+83RQ52fWlLkvWVn8UiJ++bYT8XDU8vXTo0OM6XnzrPMJaVRjafDi5GX750QdXCuvBu74O7XuU48W3ziO8dcUd3lk+OCWPiMg0STd92L17N+Lj4xEaGgqVSoUNGzZIWY5ddYkqx6blARj/eGskD2sJdw8Bc786CbW3VurSFOHmdTe07HgD4+aeNfn8+VOeSBrUGmGtbuL9r3OxKCMHz44vgKeXgv6LL4g8FMKVcgQAHnriKl5OOY8v5wVjbGwbnPzDC3NWnYSmsTI6/lL5bV9DxI+8jPTNx5G2+gS01cCbw+/Bzet//WeydZcb+McHZ7Bk11HMWXUCEGraaJUS42IzREE5QkR0J5KOMJWXlyMyMhKjRo3C4MGDpSzF7t4a0dLo8b/Gh2Pt4f+hdZcbOHygoURVKcd9f7uG+/52rc7nl78Tgp5/K8VL0y4YzoW2qHREaQ7jqiNMrpQjADD45cvYusof/13jDwCYP6UZej5citjhRVj7cZDE1cnX3FUnjR7/I/0MhnbujOO/eaPz/eUAgMeeu2J4PjgMSJhyAWNi2qEw31MRecIRJiIi0yTtMMXFxSEuLk7KEiTTwLfmkuS1YneJK1E+nQ44mOGLZ169iDeHt0TuYW8Eh1di2LiLtabtyZqLbvrgSjniUU+H1l2uY/XHgYZzgqDCLz/6oEP36xJWpjzlpTXZ7NPI9PDRzetu+O8afwSHV6BJqEJG97jpAxGRSbK6D1NFRQVKS0uNDjlSqQS8MuMcDh+sj9M53lKXo3jFlz1wo9wdaz4ORI/oa0j76iT6PFqCmS+1wG/7Gkhdns3orw6be7gqOeeIr78W7h5A8SXja11XL3vAr0m1RFUpj04HLEppio73laFFu5tGz21a3hgDW3XGwFZd8PMPvkhbfQL1PJXxD0pshrhyjhCRa5FVhyktLQ0ajcZwhIWFSV2SRcbNPYfm7W4ibUxzqUtxCYKu5n+jYksx+OVLuKfTDQx97SJ6xZRiy8oAaYuzJa49MItScoTs5+M3m+H0UW8kLzxd67m/Db6KT/6bg3+uO45mLSsw5+8tUHlTJUGVdsA1TEREJsmqw5ScnIySkhLDkZ+fL3VJoo2dcxa9HinF5KfvweULnlKX4xJqrsoLaN7G+EpxWOubuHiunkRV2QF/6JhFzjlSWuQObTXQ6LbRJL+Aaly9xE1PbeHjN5viwHZfvPd1rsmpdg18dWjashKd7y/H20tOIT9XjZ++00hQqR2ww0REZJKs/gurVquhVqulLsNCAsbOOYfej5Zg0tOtUJgv1+8hP/U8BbSJvI6zJ4z/zM+dVCtmS3HAdTd9EEvOOVJd5Ybjv9VHt77XsG9rzY90lUpA175l2Li8scTVyZsgAAveaoq9WzV4/+tcBIfffRMHQQAgqFBVKatrj3Xipg9ERKbJqsMkZ+PmnkP0k1eRmhiBG2Vu8GtS80O9/Jo7Km8q4z+2UrpR7obzeX/9CC7I98SJw97waVSNwGZVeObVi5j7SnN0ur8Mkb3LkLnDF/u31/wwUgwX3fTB1axbHICJ6fk49mt95PxSH0+OvgSv+jr8d7W/1KXJ2sdvNsOO9X5IXXYS3g11KLpY85/HBj5aqL0FXDjtiV0bG6H7Q9eg8a/GpQv1sPbjIHh669DzYfmsg7sjbvpARGSSpB2msrIy5Ob+9YM1Ly8P2dnZ8Pf3R3h4uISV2V78yJrtaP+57oTR+X+OD8P2tfyhY61jv9bH5KdbGR5/mtoUAPDIkCJMTD+DPnEleP2ds1j9cRAWTmuGZi1rblrbqVe5VCXbnEoQoBLM+wVjbjs5cKUcAYBdG/2gaazFC5MK4NekGif/5423RkSg+LKCppdKYPOKmvWMk55qbXT+Hx+cQf+hRfBU63D4QEOsX9IEZSXuaBRQjc73l+GD/xxHowBlbLghJkP07YmIXIGkHabMzExER0cbHiclJQEAEhISsHz5comqso/Y0EipS1C0yN5l2HY++45tYocXIXZ4kWMKkoKLjjC5Uo7obVwWgI3LFLRhiRO4W340Dq7G7H+fvGMb2eMIExGRSZJ2mPr16weBV6iIbMJV1zAxR4hsg2uYiIhM4xomIqVw0REmIrIRjjAREZnE3QaIiIiIiIjqwA4TkULop9OYe4h17tw5PPfcc2jcuDG8vb3RuXNnZGZm2v6LEJEkxGYIp+QRkavglDwipbDjlLyrV6+iT58+iI6OxnfffYcmTZrg+PHj8PPzE1slETkrTskjIjKJHSYihbDnpg/vvvsuwsLCsGzZMsO5iIgIcW9CRE6Nmz4QEZnGKXlESiGIPACUlpYaHRUVFSbfeuPGjejRoweeeeYZBAYGolu3bliyZIm9vxEROZLYDGGHiYhcBDtMRAoidt1BWFgYNBqN4UhLSzP5vidPnsTChQvRunVrbNu2DWPGjMHrr7+OFStWOOibEZEjcP0SEVFtnJJHpBSCUHOY2xZAfn4+fH19DafVarXJ5jqdDj169MDcuXMBAN26dcPhw4exaNEiJCQkWFc3ETkHMRmib09E5AI4wkSkEJbsbuXr62t01NVhCgkJQYcOHYzOtW/fHmfOnLH31yIiB+EueUREpnGEiUgp7LhLXp8+fZCTk2N07tixY2jevLm4NyIi58Vd8oiITGKHiUghVLqaw9y2YkyYMAG9e/fG3LlzMWTIEBw8eBCLFy/G4sWLxRdKRE5JTIbo2xMRuQJOySNSCjvubnXfffdh/fr1+Oqrr9CpUyfMmjUL6enpGDFihA2/ABFJirvkERGZxBEmIoWw532YAODxxx/H448/Lv6FRCQLvA8TEZFp7DARKYUFu+QRERlwlzwiIpPYYSJSCHuPMBGRsnGEiYjINHaYiJTCjrvkEZEL4C55REQmscNEpBAcYSIia3CEiYjINHaYiJSCa5iIyBpcw0REZBK3FSciIiIiIqoDR5iIFIJT8ojIGpySR0RkGkeYiJSCN5wkImvY+ca1qampUKlURke7du1sVz8RkZ1whIlIITjCRETWcMQIU8eOHfH9998bHnt48GcIETk/JhWRUuiEmsPctkREtxKTIfr2Inl4eCA4OFj064iIpMQpeURKwSl5RGQNC6fklZaWGh0VFRV1fsTx48cRGhqKli1bYsSIEThz5owdvxARkW2ww0SkECr8NaXmrofUxRKR0xGVIbfkSFhYGDQajeFIS0sz+f69evXC8uXLsXXrVixcuBB5eXl44IEHcO3aNYd9RyIiS7DDRKQU+nuomHsQEd1KbIb8mSP5+fkoKSkxHMnJySbfPi4uDs888wy6dOmC2NhYfPvttyguLsbatWtt+jUWLFiAFi1awMvLC7169cLBgwfrbLtkyRI88MAD8PPzg5+fH2JiYu7YnohcEztMRAoh6sow+0tEdBuxGaLPEV9fX6NDrVab9XmNGjVCmzZtkJuba7PvsGbNGiQlJSElJQWHDh1CZGQkYmNjcfHiRZPtd+7cieHDh2PHjh3Yt28fwsLC0L9/f5w7d85mNRGR/LHDRKQUXMNERNawcA2TpcrKynDixAmEhIRY90a3mDdvHkaPHo3ExER06NABixYtQv369fH555+bbP/ll1/i1VdfRdeuXdGuXTt89tln0Ol0yMjIsFlNRCR/7DARKYRKEEQdRES3EpshYnNk4sSJ2LVrF06dOoW9e/fiySefhLu7O4YPH26T+isrK5GVlYWYmBjDOTc3N8TExGDfvn1mvcf169dRVVUFf3//OttUVFTU2uiCiJSNHSYipdCJPIiIbiU2Q0TmyNmzZzF8+HC0bdsWQ4YMQePGjbF//340adLEJuVfvnwZWq0WQUFBRueDgoJQUFBg1ntMmTIFoaGhRp2u26WlpRltchEWFmZV3UTk/HgfJiKFEHPFlyNMRHQ7saNGYnNk9erVYktyqHfeeQerV6/Gzp074eXlVWe75ORkJCUlGR6Xlpay00SkcOwwESmFmDUF7C8R0e3ErktyshwJCAiAu7s7CgsLjc4XFhbe9Wa5//znP/HOO+/g+++/R5cuXe7YVq1Wm72xBREpA6fkESkFtxUnImtYuK24s/D09ET37t2NNmzQb+AQFRVV5+vee+89zJo1C1u3bkWPHj0cUSoRyQxHmIgUQsx24dxWnIhuJ/aWA86YI0lJSUhISECPHj3Qs2dPpKeno7y8HImJiQCAF154AU2bNjXcXPfdd9/F9OnTsWrVKrRo0cKw1qlhw4Zo2LChZN+DiJwLO0xESiHmiq+TXRkmIicgdtTICXNk6NChuHTpEqZPn46CggJ07doVW7duNWwEcebMGbi5/TW5ZuHChaisrMTTTz9t9D4pKSlITU11ZOlE5MTYYSIiIiLFGDduHMaNG2fyuZ07dxo9PnXqlP0LIiLZY4eJSCFUuprD3LZERLcSkyH69kREroAdJiKl4JQ8IrKGAqbkERHZg6w7TMKfYV2NKqfb3lSJSq/xcqKjlJbV/FkLon68gNuKW4A54ljMEcewe4bo2xMRuQBZd5iuXbsGANiDbyWuxDX4tZG6Atdz7do1aDQas9ryxrWWYY44FnPEseyVIfr2RESuQNYdptDQUOTn58PHxwcqlUrqcsymvyt4fn4+fH19pS5H0eT6Zy0IAq5du4bQ0FAxL+KUPAvIMUfk+vdajuT6Z233DNG3JyJyAbLuMLm5uaFZs2ZSl2ExX19fWf0HWM7k+Gdt7lVhAwGAubOdrPyd88477yA5ORlvvPEG0tPTrXszick5R+T491qu5PhnbdcM0bcnInIBsu4wEdFfHDUl7+eff8ann36KLl26WPweROR8OCWPiMg0t7s3ISJZEPDXlJq7HjUvKS0tNToqKiru+BFlZWUYMWIElixZAj8/P/t/JyJyHFEZInCEiYhcBjtMElCr1UhJSYFarZa6FMVzqT9rUT90an7phIWFQaPRGI60tLQ7fsTYsWMxYMAAxMTEOOIbUR1c6u+1xFzqz1pshnCEiYhcBKfkSUCtViM1NVXqMlyCS/1Z6wCYu2fBn+sUbl/IfqcfhatXr8ahQ4fw888/W14j2YRL/b2WmEv9WYvJEH17IiIXwA4TkUJYsobJ3IXs+fn5eOONN7B9+3Z4eXlZVScROSeuYSIiMo0dJiKlsOO24llZWbh48SLuvfdewzmtVovdu3fj448/RkVFBdzd3UW9JxE5GW4rTkRkEjtMREphxw7Tww8/jN9//93oXGJiItq1a4cpU6aws0SkBOwwERGZxA4TkVLYscPk4+ODTp06GZ1r0KABGjduXOs8EckUO0xERCZxlzwHW7BgAVq0aAEvLy/06tULBw8elLokRdq9ezfi4+MRGhoKlUqFDRs2SF2S/elEHiRbzBHHcLkcEZshzBEichHsMDnQmjVrkJSUhJSUFBw6dAiRkZGIjY3FxYsXpS5NccrLyxEZGYkFCxZIXYrD6Bdsm3tYa+fOnUhPT7e+cBKFOeI4rpYjYjOEmz4Qkatgh8mB5s2bh9GjRyMxMREdOnTAokWLUL9+fXz++edSl6Y4cXFxmD17Np588kmpS3Ec3j/FJTBHHMflcoT3YSIiMokdJgeprKxEVlaW0Q0/3dzcEBMTg3379klYGRHJBXOEiIjI8dhhcpDLly9Dq9UiKCjI6HxQUBAKCgokqooURSeIO0h2mCNkV2IzhDlCRC6Cu+QRKYUdd8kjIhfAXfKIiExih8lBAgIC4O7ujsLCQqPzhYWFCA4OlqgqUhYxP3b4Q0eOmCNkX2LXJTFHiMg1cEqeg3h6eqJ79+7IyMgwnNPpdMjIyEBUVJSElZFicLG24jFHyK646QMRkUkcYXKgpKQkJCQkoEePHujZsyfS09NRXl6OxMREqUtTnLKyMuTm5hoe5+XlITs7G/7+/ggPD5ewMjvSCTD7ii/XHsgWc8RxXC5HxGSIoT0RkfKxw+RAQ4cOxaVLlzB9+nQUFBSga9eu2Lp1a60F3GS9zMxMREdHGx4nJSUBABISErB8+XKJqrIzQVdzmNuWZIk54jgulyNiMkTfnojIBagEgWPqRHJWWloKjUaDmLAx8HBTm/Waal0Fvs9fiJKSEvj6+tq5QiJyZpZkCMAc0dP/+bn6nwORM7DXv0eOMBEpBafkEZE1OCWPiMgkdpiIlILbihORNbitOBGRSewwESmFABEdJrtWQkRyJCZD9O2JiFwAO0xESsERJiKyBkeYiIhMYoeJSCl0OgBm7lql4+5WRHQbMRliaE9EpHzsMBEpBUeYiMgaHGEiIjKJHSYipWCHiYiswQ4TEZFJ7DARKQW3FScia3BbcSIik9ykLoBsa+TIkRg0aJDhcb9+/TB+/HiH17Fz506oVCoUFxfX2UalUmHDhg1mv2dqaiq6du1qVV2nTp2CSqVCdna2Ve/jjARBJ+ogMoUZcmfMEOYIEbkedpgcYOTIkVCpVFCpVPD09ESrVq0wc+ZMVFdX2/2z161bh1mzZpnV1pwfKETkeMwQIiIi6XBKnoM8+uijWLZsGSoqKvDtt99i7NixqFevHpKTk2u1rayshKenp00+19/f3ybvQzIgCOZPkeHaA9lhhpDdickQfXsiIhfAESYHUavVCA4ORvPmzTFmzBjExMRg48aNAP6aAjNnzhyEhoaibdu2AID8/HwMGTIEjRo1gr+/PwYOHIhTp04Z3lOr1SIpKQmNGjVC48aNMXnyZAi3/Qfs9uk0FRUVmDJlCsLCwqBWq9GqVSssXboUp06dQnR0NADAz88PKpUKI0eOBADodLr/b+/Og5o4+ziAfzkMCRqojnJpvC9UBMVKo7VUXxRHR6W2o6MW0xaxDlAPvLCWRl9bwXMcPOtRcVoteEFbpFqKd8F2VLQ6VSyHoq14jaJilUCe9w+HfRshylIIBL+fmfzBs8/u880O+U2e3ewuYmJi0K5dO6hUKnh7e2P37t0m46SmpqJz585QqVQYOHCgSc6qmjt3Ljp37gxHR0e0b98e0dHRMBgMFfp98cUX0Gg0cHR0xJgxY1BUVGSyfPPmzfD09IRSqUTXrl2xbt062VmsUvkF21V9kVVhDXkx1pB/SW4NYR0hopcEzzDVEZVKhTt37kh/p6enw8nJCWlpaQAAg8GAwMBAaLVaHDt2DPb29vjss88wdOhQ/Pbbb1AoFFixYgXi4+Px5ZdfwtPTEytWrEBSUhIGDRpkdtyJEyciMzMTcXFx8Pb2Rn5+Pm7fvg2NRoM9e/bg7bffRnZ2NpycnKBSqQAAMTEx+Prrr7FhwwZ06tQJR48exbvvvosWLVrA398fV69exejRoxEeHo7Jkyfj5MmTmDlzpux9olarER8fDw8PD5w7dw6hoaFQq9WYM2eO1CcnJwc7d+7E999/j/v37yMkJARhYWHYvn07AGD79u349NNPsWbNGvTq1QtZWVkIDQ1F48aNodPpZGeyKkYjYFPFawp47YHVYw2piDXkX5JTQwDWESJ6eQiqdTqdTowaNUoIIYTRaBRpaWnCwcFBzJo1S1ru6uoqnjx5Iq3z1VdfiS5dugij0Si1PXnyRKhUKnHgwAEhhBDu7u5i6dKl0nKDwSBatWoljSWEEP7+/mLatGlCCCGys7MFAJGWllZpzkOHDgkA4u7du1Lb48ePhaOjo8jIyDDpGxISIsaNGyeEEGLevHmiW7duJsvnzp1bYVvPAiCSkpLMLl+2bJnw9fWV/tbr9cLOzk5cu3ZNavvhhx+Era2tuH79uhBCiA4dOogdO3aYbGfRokVCq9UKIYTIz88XAERWVpbZca1NUVGRACD+02S8CFS/V6XXf5qMFwBEUVFRXcenKmANqRxrSM2oTg1hHfm/8v33su8Hovqgtj6PPMNkISkpKWjSpAkMBgOMRiPGjx+PBQsWSMu9vLxMrjk4e/YscnJyoFarTbbz+PFj5ObmoqioCNevX4efn5+0zN7eHn369Knwk5pyZ86cgZ2dHfz9/aucOycnB48ePcLgwYNN2ktKStCrVy8AwIULF0xyAIBWq63yGOUSExMRFxeH3NxcPHz4EKWlpXBycjLp07p1a7Rs2dJkHKPRiOzsbKjVauTm5iIkJAShoaFSn9LSUjg7O8vOY22E0QhRxaPDvLuV9WENeTHWkH9HTg0BWEeI6OXBCZOFDBw4EOvXr4dCoYCHhwfs7U13fePGjU3+fvjwIXx9faWfifxTixYtqpWh/Ocxcjx8+BAAsG/fPpMvGcDTaypqSmZmJiZMmICFCxciMDAQzs7OSEhIwIoVK2Rn3bRpU4UvX3Z2djWWtd4SMp6hwmsPrA5ryPOxhtQAOTVE6k9E1PBxwmQhjRs3RseOHavcv3fv3khMTISLi0uFI6Tl3N3d8csvv+CNN94A8PQo6KlTp9C7d+9K+3t5ecFoNOLIkSMICAiosLz86HRZWZnU1q1bNzg4OKCgoMDsUWVPT0/p4vNyJ06cePGb/IeMjAy0adMG8+fPl9quXLlSoV9BQQH++usveHh4SOPY2tqiS5cucHV1hYeHB/Ly8jBhwgRZ4zcIRgHYcMLUULGGPB9rSA2QU0MA1hEiemnwLnn11IQJE9C8eXOMGjUKx44dQ35+Pg4fPoypU6fi2rVrAIBp06YhNjYWycnJuHjxIsLCwp77/JO2bdtCp9Phgw8+QHJysrTNnTt3AgDatGkDGxsbpKSk4NatW3j48CHUajVmzZqFGTNmYNu2bcjNzcXp06exevVqbNu2DQAwZcoU/PHHH5g9ezays7OxY8cOxMfHy3q/nTp1QkFBARISEpCbm4u4uDgkJSVV6KdUKqHT6XD27FkcO3YMU6dOxZgxY+Dm5gYAWLhwIWJiYhAXF4dLly7h3Llz2Lp1K1auXCkrj1US4ulF2FV68YtOQ8cawhoim6wawjpCRC8PTpjqKUdHRxw9ehStW7fG6NGj4enpiZCQEDx+/Fg6Wjxz5kwEBwdDp9NBq9VCrVbjrbfeeu52169fj3feeQdhYWHo2rUrQkNDUVxcDABo2bIlFi5ciKioKLi6uiIiIgIAsGjRIkRHRyMmJgaenp4YOnQo9u3bh3bt2gF4ek3Anj17kJycDG9vb2zYsAGLFy+W9X5HjhyJGTNmICIiAj4+PsjIyEB0dHSFfh07dsTo0aMxbNgwDBkyBD179jS55e+kSZOwefNmbN26FV5eXvD390d8fLyUtSETRiHrRQ0bawhriFxyawjrCBG9LGyEuat7icgq3L9/H87OzhhoNxr2No2qtE6pMOBQ2V4UFRWZ/bnWP8XExGDv3r24ePEiVCoV+vXrhyVLlkjP+yEi61WdGgLIryPl1q5di2XLlqGwsBDe3t5YvXo1+vbtW53oNbL9Xbt2ITo6GpcvX0anTp2wZMkSDBs2rMrjle8/ufuBiGpebX0eeYaJqIGozSPDR44cQXh4OE6cOIG0tDQYDAYMGTJEOrNARNbPEmeYEhMTERkZCb1ej9OnT8Pb2xuBgYG4efNmjbwHudvPyMjAuHHjEBISgqysLAQFBSEoKAjnz5+vkTxE1DDwDBORlSs/mvI6hsEeVTzDBAOOIxVXr141OQLj4OBQpTuX3bp1Cy4uLjhy5Ih0wwAisk7VqSFA9eqIn58fXn31VaxZswYAYDQaodFo8NFHHyEqKurfvZFqbH/s2LEoLi5GSkqK1Pbaa6/Bx8cHGzZsqHSMJ0+e4MmTJ9LfRUVFaN26dYX9QESWd//+fWg0Gty7d69GHwfBu+QRWTmFQgE3NzccL0yVtV6TJk2g0WhM2vR6vcmzfcwpKioCADRr1kzWmERU/1S3hgDy6khJSQlOnTqFefPmSW22trYICAhAZmam7LFrYvuZmZmIjIw0aQsMDERycrLZcWJiYrBw4cIK7c/uByKqO3fu3OGEiYj+T6lUIj8/HyUlJbLWE0LAxsbGpK0qZ5eMRiOmT5+O/v37o0ePHrLGJKL6p7o1BJBXR27fvo2ysjK4urqatLu6uuLixYuyx66J7RcWFlbav7Cw0Ow48+bNM5lk3bt3D23atEFBQYFVPeC4/Ei8NZ0Zs8bMAHNbUvkZ35o+oMsJE1EDoFQqoVQqLTJWeHg4zp8/j+PHj1tkPCKqfZasIdbO3E8OnZ2dreZL5T85OTlZXW5rzAwwtyXZ2tbsbRo4YSKiKouIiEBKSgqOHj2KVq1a1XUcIrIizZs3h52dHW7cuGHSfuPGDek5WJbevpubW63lIaKGg3fJI6IXEkIgIiICSUlJOHjw4EvxTBoiqlkKhQK+vr5IT0+X2oxGI9LT06HVautk+1qt1qQ/AKSlpdVIHiJqOHiGiYheKDw8HDt27MC3334LtVot/b7f2dkZKpWqjtMRkbWIjIyETqdDnz590LdvX6xatQrFxcV4//33LbL9iRMnomXLloiJiQEATJs2Df7+/lixYgWGDx+OhIQEnDx5Ehs3bqzymA4ODtDr9VW6BrQ+scbc1pgZYG5Lqq3MvK04Eb3Qsxd1l9u6dSvee+89y4YhIqu2Zs0a6cGyPj4+iIuLg5+fn0W2/+abb6Jt27aIj4+X+u/atQuffPKJ9ODapUuXynpwLRE1fJwwERERERERmcFrmIiIiIiIiMzghImIiIiIiMgMTpiIiIiIiIjM4ISJiIiIiIjIDE6YiIiIiJ5j7dq1aNu2LZRKJfz8/PDrr78+t/+uXbvQtWtXKJVKeHl5ITU11UJJTcnJvWnTJgwYMABNmzZF06ZNERAQ8ML3WRvk7utyCQkJsLGxQVBQUO0GNENu7nv37iE8PBzu7u5wcHBA586dLf5/IjfzqlWr0KVLF6hUKmg0GsyYMQOPHz+2UNqnjh49ihEjRsDDwwM2NjZITk5+4TqHDx9G79694eDggI4dO5rcJbOqOGEiIiIiMiMxMRGRkZHQ6/U4ffo0vL29ERgYiJs3b1baPyMjA+PGjUNISAiysrIQFBSEoKAgnD9/vl7nPnz4MMaNG4dDhw4hMzMTGo0GQ4YMwZ9//llvM5e7fPkyZs2ahQEDBlgoqSm5uUtKSjB48GBcvnwZu3fvRnZ2NjZt2oSWLVvW28w7duxAVFQU9Ho9Lly4gC1btiAxMREff/yxxTIDQHFxMby9vbF27doq9c/Pz8fw4cMxcOBAnDlzBtOnT8ekSZNw4MABeQMLIiIiIqpU3759RXh4uPR3WVmZ8PDwEDExMZX2HzNmjBg+fLhJm5+fn/jwww9rNeez5OZ+VmlpqVCr1WLbtm21FbGC6mQuLS0V/fr1E5s3bxY6nU6MGjXKAklNyc29fv160b59e1FSUmKpiBXIzRweHi4GDRpk0hYZGSn69+9fqzmfB4BISkp6bp85c+aI7t27m7SNHTtWBAYGyhqLZ5iIiIiIKlFSUoJTp04hICBAarO1tUVAQAAyMzMrXSczM9OkPwAEBgaa7V8bqpP7WY8ePYLBYECzZs1qK6aJ6mb+73//CxcXF4SEhFgiZgXVyf3dd99Bq9UiPDwcrq6u6NGjBxYvXoyysrJ6m7lfv344deqU9LO9vLw8pKam1vuHPNfU59G+JkMRERERNRS3b99GWVkZXF1dTdpdXV1x8eLFStcpLCystH9hYWGt5XxWdXI/a+7cufDw8KjwZbO2VCfz8ePHsWXLFpw5c8YCCStXndx5eXk4ePAgJkyYgNTUVOTk5CAsLAwGgwF6vb5eZh4/fjxu376N119/HUIIlJaWYsqUKRb/SZ5c5j6P9+/fx99//w2VSlWl7fAMExERERFJYmNjkZCQgKSkJCiVyrqOU6kHDx4gODgYmzZtQvPmzes6jixGoxEuLi7YuHEjfH19MXbsWMyfPx8bNmyo62hmHT58GIsXL8a6detw+vRp7N27F/v27cOiRYvqOppF8AwTERERUSWaN28OOzs73Lhxw6T9xo0bcHNzq3QdNzc3Wf1rQ3Vyl1u+fDliY2Px008/oWfPnrUZ04TczLm5ubh8+TJGjBghtRmNRgCAvb09srOz0aFDh9oNjerta3d3dzRq1Ah2dnZSm6enJwoLC1FSUgKFQlHvMkdHRyM4OBiTJk0CAHh5eaG4uBiTJ0/G/PnzYWtbP8/BmPs8Ojk5VfnsEsAzTERERESVUigU8PX1RXp6utRmNBqRnp4OrVZb6TpardakPwCkpaWZ7V8bqpMbAJYuXYpFixZh//796NOnjyWiSuRm7tq1K86dO4czZ85Ir5EjR0p3Q9NoNPUyNwD0798fOTk50gQPAC5dugR3d/danyxVN/OjR48qTIrKJ3xP779QP9XY51He/SiIiIiIXh4JCQnCwcFBxMfHi99//11MnjxZvPLKK6KwsFAIIURwcLCIioqS+v/888/C3t5eLF++XFy4cEHo9XrRqFEjce7cuXqdOzY2VigUCrF7925x/fp16fXgwYN6m/lZdXWXPLm5CwoKhFqtFhERESI7O1ukpKQIFxcX8dlnn9XbzHq9XqjVavHNN9+IvLw88eOPP4oOHTqIMWPGWCyzEEI8ePBAZGVliaysLAFArFy5UmRlZYkrV64IIYSIiooSwcHBUv+8vDzh6OgoZs+eLS5cuCDWrl0r7OzsxP79+2WNywkTERER0XOsXr1atG7dWigUCtG3b19x4sQJaZm/v7/Q6XQm/Xfu3Ck6d+4sFAqF6N69u9i3b5+FEz8lJ3ebNm0EgAovvV5fbzM/q64mTELIz52RkSH8/PyEg4ODaN++vfj8889FaWlpvc1sMBjEggULRIcOHYRSqRQajUaEhYWJu3fvWjTzoUOHKv0/Lc+q0+mEv79/hXV8fHyEQqEQ7du3F1u3bpU9ro0Q9fg8GhERERERUR3iNUxERERERERmcMJERERERERkBidMREREREREZnDCREREREREZAYnTERERERERGZwwkRERERERGQGJ0xERERERERmcMJERERERERkBidMREREREREZnDCREREREREZAYnTERERERERGb8D9388OAeozZLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1200 with 17 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_conf_matrix(prediction, true):\n",
    "    s = 0\n",
    "    pl = []\n",
    "    for pred in prediction:\n",
    "        if pred[0] > pred[1]:\n",
    "            pl.append(0)\n",
    "        else:\n",
    "            pl.append(1)\n",
    "\n",
    "    for i in range(len(pl)):\n",
    "        if pl[i] == true.values[i]:\n",
    "            s+=1\n",
    "\n",
    "    c_train = confusion_matrix(true, pl)\n",
    "    disp = ConfusionMatrixDisplay(c_train)\n",
    "    return disp\n",
    "\n",
    "cf_2012 = build_conf_matrix(pred_2012, y_valid_2012)\n",
    "cf_2013 = build_conf_matrix(pred_2013, y_valid_2013)\n",
    "cf_2014 = build_conf_matrix(pred_2014, y_valid_2014)\n",
    "cf_2015 = build_conf_matrix(pred_2015, y_valid_2015)\n",
    "cf_2016 = build_conf_matrix(pred_2016, y_valid_2016)\n",
    "cf_2017 = build_conf_matrix(pred_2017, y_valid_2017)\n",
    "cf_2018 = build_conf_matrix(pred_2018, y_valid_2018)\n",
    "cf_2019 = build_conf_matrix(pred_2019, y_valid_2019)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,3)\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(12)\n",
    "fig.suptitle(\"Confusion Matrices: LSTM Model 2 Training/Validation Set 66.6%\")\n",
    "cf_2012.plot(ax=ax[0][0]), cf_2013.plot(ax=ax[0][1]), cf_2014.plot(ax=ax[0][2])\n",
    "cf_2015.plot(ax=ax[1][0]), cf_2016.plot(ax=ax[1][1]), cf_2017.plot(ax=ax[1][2])\n",
    "cf_2018.plot(ax=ax[2][0]), cf_2019.plot(ax=ax[2][1])\n",
    "\n",
    "ax[0][0].set_title(2012), ax[0][1].set_title(2013), ax[0][2].set_title(2014)\n",
    "ax[1][0].set_title(2015), ax[1][1].set_title(2016), ax[1][2].set_title(2017)\n",
    "ax[2][0].set_title(2018), ax[2][1].set_title(2019)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Res_1 =   model.add(LSTM( 128 ,input_shape = (88,1), activation = 'tanh' , dropout = 0.25, recurrent_dropout = 0.25, return_sequences=True))\n",
    "    model.add(LSTM( 64 ))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "\n",
    "Res_2 =   model.add(LSTM( 128 ,input_shape = (88,1), activation = 'sigmoid' , dropout = 0.25, recurrent_dropout = 0.25, return_sequences=True))\n",
    "    model.add(LSTM( 64 ))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "\n",
    "Res_3 =   model.add(LSTM( 128 ,input_shape = (88,1), activation = 'tanh' , dropout = 0.25, recurrent_dropout = 0.25, return_sequences=True))\n",
    "    model.add(LSTM( 64, activation='tanh ))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "\n",
    "Res_4 =   model.add(LSTM( 128 ,input_shape = (88,1), activation = 'tanh' , dropout = 0.2, recurrent_dropout = 0.2, return_sequences=True))\n",
    "    model.add(LSTM( 64 ))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "\n",
    "Res_5 =   model.add(LSTM( 128 ,input_shape = (88,1), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3, return_sequences=True))\n",
    "    model.add(LSTM( 64 ))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "Res_6 =   model.add(LSTM( 128 ,input_shape = (88,1), activation = 'tanh' , dropout = 0.4, recurrent_dropout = 0.4, return_sequences=True))\n",
    "    model.add(LSTM( 64 ))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "\n",
    "Res_7 =   model.add(LSTM( 128 ,input_shape = (88,1), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3, return_sequences=True))\n",
    "    model.add(LSTM( 64, return_sequences=True))\n",
    "    model.add(LSTM( 64 ))\n",
    "    model.add(Dense(64, activation=\"tanh))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "\n",
    "Res_8 =   model.add(LSTM( 128 ,input_shape = (88,1), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3, return_sequences=True))\n",
    "    model.add(LSTM( 64, return_sequences=True, dropout = 0.3))\n",
    "    model.add(LSTM( 64 ))\n",
    "    model.add(Dense(32, activation=\"tanh))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "\n",
    "Res_10 = model.add(LSTM( 128 ,input_shape = (88,1), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3, return_sequences=True))\n",
    "    model.add(LSTM( 64, return_sequences=True, dropout=0.3))\n",
    "    model.add(LSTM( 32, return_sequences=True, dropout= .1 ))\n",
    "    model.add(LSTM( 16, return_sequences=True ))\n",
    "    model.add(Dense(8))\n",
    "    model.add(LSTM( 32 ))\n",
    "    # model.add(LSTM( 64 ))\n",
    "    model.add(Dense(32, activation=\"tanh\"))    \n",
    "    model.add(Dense(16, activation=\"tanh\"))\n",
    "    model.add(Dense(2, activation=\"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,802\n",
      "Trainable params: 40,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 7s - loss: 0.4738 - accuracy: 0.5182 - mse: 0.4738 - val_loss: 0.2224 - val_accuracy: 0.7500 - val_mse: 0.2224 - lr: 0.0010 - 7s/epoch - 1s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2739 - accuracy: 0.5255 - mse: 0.2739 - val_loss: 0.3150 - val_accuracy: 0.2500 - val_mse: 0.3150 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2795 - accuracy: 0.4672 - mse: 0.2795 - val_loss: 0.2799 - val_accuracy: 0.2500 - val_mse: 0.2799 - lr: 0.0010 - 149ms/epoch - 30ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2555 - accuracy: 0.4745 - mse: 0.2555 - val_loss: 0.2606 - val_accuracy: 0.2500 - val_mse: 0.2606 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2588 - accuracy: 0.4964 - mse: 0.2588 - val_loss: 0.2425 - val_accuracy: 0.7500 - val_mse: 0.2425 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2533 - accuracy: 0.5328 - mse: 0.2533 - val_loss: 0.2348 - val_accuracy: 0.7500 - val_mse: 0.2348 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5474 - mse: 0.2489 - val_loss: 0.2432 - val_accuracy: 0.7500 - val_mse: 0.2432 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5401 - mse: 0.2487 - val_loss: 0.2524 - val_accuracy: 0.5000 - val_mse: 0.2524 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5255 - mse: 0.2496 - val_loss: 0.2587 - val_accuracy: 0.2500 - val_mse: 0.2587 - lr: 0.0010 - 209ms/epoch - 42ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5693 - mse: 0.2482 - val_loss: 0.2566 - val_accuracy: 0.2500 - val_mse: 0.2566 - lr: 0.0010 - 169ms/epoch - 34ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5839 - mse: 0.2484 - val_loss: 0.2511 - val_accuracy: 0.3750 - val_mse: 0.2511 - lr: 0.0010 - 173ms/epoch - 35ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2504 - accuracy: 0.5474 - mse: 0.2504 - val_loss: 0.2496 - val_accuracy: 0.7500 - val_mse: 0.2496 - lr: 0.0010 - 233ms/epoch - 47ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5985 - mse: 0.2453 - val_loss: 0.2526 - val_accuracy: 0.3750 - val_mse: 0.2526 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2502 - accuracy: 0.5182 - mse: 0.2502 - val_loss: 0.2605 - val_accuracy: 0.2500 - val_mse: 0.2605 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5766 - mse: 0.2466 - val_loss: 0.2628 - val_accuracy: 0.2500 - val_mse: 0.2628 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5693 - mse: 0.2452 - val_loss: 0.2593 - val_accuracy: 0.2500 - val_mse: 0.2593 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2428 - accuracy: 0.6204 - mse: 0.2428 - val_loss: 0.2604 - val_accuracy: 0.2500 - val_mse: 0.2604 - lr: 0.0010 - 145ms/epoch - 29ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5401 - mse: 0.2489 - val_loss: 0.2646 - val_accuracy: 0.2500 - val_mse: 0.2646 - lr: 0.0010 - 148ms/epoch - 30ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2437 - accuracy: 0.5839 - mse: 0.2437 - val_loss: 0.2698 - val_accuracy: 0.2500 - val_mse: 0.2698 - lr: 0.0010 - 150ms/epoch - 30ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5985 - mse: 0.2454 - val_loss: 0.2701 - val_accuracy: 0.2500 - val_mse: 0.2701 - lr: 0.0010 - 186ms/epoch - 37ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2433 - accuracy: 0.6277 - mse: 0.2433 - val_loss: 0.2703 - val_accuracy: 0.2500 - val_mse: 0.2703 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2388 - accuracy: 0.6204 - mse: 0.2388 - val_loss: 0.2790 - val_accuracy: 0.2500 - val_mse: 0.2790 - lr: 0.0010 - 149ms/epoch - 30ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5474 - mse: 0.2431 - val_loss: 0.2863 - val_accuracy: 0.2500 - val_mse: 0.2863 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5985 - mse: 0.2431 - val_loss: 0.2817 - val_accuracy: 0.2500 - val_mse: 0.2817 - lr: 0.0010 - 149ms/epoch - 30ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.6350 - mse: 0.2409 - val_loss: 0.2770 - val_accuracy: 0.2500 - val_mse: 0.2770 - lr: 0.0010 - 146ms/epoch - 29ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5766 - mse: 0.2425 - val_loss: 0.2879 - val_accuracy: 0.2500 - val_mse: 0.2879 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2399 - accuracy: 0.5985 - mse: 0.2399 - val_loss: 0.2914 - val_accuracy: 0.2500 - val_mse: 0.2914 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.6423 - mse: 0.2420 - val_loss: 0.2786 - val_accuracy: 0.2500 - val_mse: 0.2786 - lr: 0.0010 - 143ms/epoch - 29ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2335 - accuracy: 0.5912 - mse: 0.2335 - val_loss: 0.2850 - val_accuracy: 0.2500 - val_mse: 0.2850 - lr: 0.0010 - 143ms/epoch - 29ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2328 - accuracy: 0.6423 - mse: 0.2328 - val_loss: 0.2994 - val_accuracy: 0.2500 - val_mse: 0.2994 - lr: 0.0010 - 144ms/epoch - 29ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5839 - mse: 0.2418 - val_loss: 0.2981 - val_accuracy: 0.2500 - val_mse: 0.2981 - lr: 0.0010 - 148ms/epoch - 30ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2269 - accuracy: 0.5985 - mse: 0.2269 - val_loss: 0.3075 - val_accuracy: 0.2500 - val_mse: 0.3075 - lr: 0.0010 - 143ms/epoch - 29ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2342 - accuracy: 0.6131 - mse: 0.2342 - val_loss: 0.2926 - val_accuracy: 0.2500 - val_mse: 0.2926 - lr: 0.0010 - 144ms/epoch - 29ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2327 - accuracy: 0.6204 - mse: 0.2327 - val_loss: 0.3003 - val_accuracy: 0.2500 - val_mse: 0.3003 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2314 - accuracy: 0.5985 - mse: 0.2314 - val_loss: 0.2985 - val_accuracy: 0.2500 - val_mse: 0.2985 - lr: 0.0010 - 145ms/epoch - 29ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2304 - accuracy: 0.6204 - mse: 0.2304 - val_loss: 0.2877 - val_accuracy: 0.2500 - val_mse: 0.2877 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2286 - accuracy: 0.6423 - mse: 0.2286 - val_loss: 0.2851 - val_accuracy: 0.3125 - val_mse: 0.2851 - lr: 0.0010 - 168ms/epoch - 34ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2245 - accuracy: 0.6642 - mse: 0.2245 - val_loss: 0.3079 - val_accuracy: 0.2500 - val_mse: 0.3079 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2153 - accuracy: 0.6861 - mse: 0.2153 - val_loss: 0.2981 - val_accuracy: 0.3125 - val_mse: 0.2981 - lr: 0.0010 - 144ms/epoch - 29ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2120 - accuracy: 0.6423 - mse: 0.2120 - val_loss: 0.2987 - val_accuracy: 0.3125 - val_mse: 0.2987 - lr: 0.0010 - 146ms/epoch - 29ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2108 - accuracy: 0.7226 - mse: 0.2108 - val_loss: 0.2872 - val_accuracy: 0.3750 - val_mse: 0.2872 - lr: 0.0010 - 187ms/epoch - 37ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2157 - accuracy: 0.6277 - mse: 0.2157 - val_loss: 0.2567 - val_accuracy: 0.6250 - val_mse: 0.2567 - lr: 0.0010 - 250ms/epoch - 50ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2039 - accuracy: 0.6934 - mse: 0.2039 - val_loss: 0.3233 - val_accuracy: 0.3750 - val_mse: 0.3233 - lr: 0.0010 - 185ms/epoch - 37ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2125 - accuracy: 0.6569 - mse: 0.2125 - val_loss: 0.2504 - val_accuracy: 0.6875 - val_mse: 0.2504 - lr: 0.0010 - 150ms/epoch - 30ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2024 - accuracy: 0.7080 - mse: 0.2024 - val_loss: 0.3077 - val_accuracy: 0.3750 - val_mse: 0.3077 - lr: 0.0010 - 150ms/epoch - 30ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1884 - accuracy: 0.7372 - mse: 0.1884 - val_loss: 0.2796 - val_accuracy: 0.5000 - val_mse: 0.2796 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1973 - accuracy: 0.7226 - mse: 0.1973 - val_loss: 0.2996 - val_accuracy: 0.5000 - val_mse: 0.2996 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1850 - accuracy: 0.7445 - mse: 0.1850 - val_loss: 0.2634 - val_accuracy: 0.6250 - val_mse: 0.2634 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1779 - accuracy: 0.7445 - mse: 0.1779 - val_loss: 0.3011 - val_accuracy: 0.5000 - val_mse: 0.3011 - lr: 0.0010 - 145ms/epoch - 29ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1938 - accuracy: 0.7153 - mse: 0.1938 - val_loss: 0.2583 - val_accuracy: 0.6250 - val_mse: 0.2583 - lr: 0.0010 - 146ms/epoch - 29ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2249 - accuracy: 0.7222 - mse: 0.2249\n",
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7222\n",
      "Loss: 0.22493839263916016\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,802\n",
      "Trainable params: 40,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 8s - loss: 0.4449 - accuracy: 0.5839 - mse: 0.4449 - val_loss: 0.2672 - val_accuracy: 0.5000 - val_mse: 0.2672 - lr: 0.0010 - 8s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2698 - accuracy: 0.5693 - mse: 0.2698 - val_loss: 0.3143 - val_accuracy: 0.5000 - val_mse: 0.3143 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2731 - accuracy: 0.5693 - mse: 0.2731 - val_loss: 0.2939 - val_accuracy: 0.5000 - val_mse: 0.2939 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2550 - accuracy: 0.5693 - mse: 0.2550 - val_loss: 0.2908 - val_accuracy: 0.5000 - val_mse: 0.2908 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2592 - accuracy: 0.5693 - mse: 0.2592 - val_loss: 0.2723 - val_accuracy: 0.5000 - val_mse: 0.2723 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2494 - accuracy: 0.5693 - mse: 0.2494 - val_loss: 0.2610 - val_accuracy: 0.5000 - val_mse: 0.2610 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5620 - mse: 0.2458 - val_loss: 0.2656 - val_accuracy: 0.5000 - val_mse: 0.2656 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2424 - accuracy: 0.5693 - mse: 0.2424 - val_loss: 0.2747 - val_accuracy: 0.5000 - val_mse: 0.2747 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5693 - mse: 0.2470 - val_loss: 0.2816 - val_accuracy: 0.5000 - val_mse: 0.2816 - lr: 0.0010 - 139ms/epoch - 28ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5693 - mse: 0.2472 - val_loss: 0.2808 - val_accuracy: 0.5000 - val_mse: 0.2808 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.5693 - mse: 0.2401 - val_loss: 0.2751 - val_accuracy: 0.5000 - val_mse: 0.2751 - lr: 0.0010 - 141ms/epoch - 28ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2424 - accuracy: 0.5839 - mse: 0.2424 - val_loss: 0.2750 - val_accuracy: 0.5000 - val_mse: 0.2750 - lr: 1.0000e-05 - 144ms/epoch - 29ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5766 - mse: 0.2432 - val_loss: 0.2751 - val_accuracy: 0.5000 - val_mse: 0.2751 - lr: 1.0000e-05 - 144ms/epoch - 29ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2400 - accuracy: 0.5839 - mse: 0.2400 - val_loss: 0.2752 - val_accuracy: 0.5000 - val_mse: 0.2752 - lr: 1.0000e-05 - 146ms/epoch - 29ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5693 - mse: 0.2454 - val_loss: 0.2752 - val_accuracy: 0.5000 - val_mse: 0.2752 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5620 - mse: 0.2432 - val_loss: 0.2753 - val_accuracy: 0.5000 - val_mse: 0.2753 - lr: 1.0000e-05 - 144ms/epoch - 29ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5547 - mse: 0.2493 - val_loss: 0.2754 - val_accuracy: 0.5000 - val_mse: 0.2754 - lr: 1.0000e-05 - 143ms/epoch - 29ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5693 - mse: 0.2465 - val_loss: 0.2754 - val_accuracy: 0.5000 - val_mse: 0.2754 - lr: 1.0000e-05 - 142ms/epoch - 28ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5839 - mse: 0.2490 - val_loss: 0.2755 - val_accuracy: 0.5000 - val_mse: 0.2755 - lr: 1.0000e-05 - 141ms/epoch - 28ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5912 - mse: 0.2426 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-05 - 143ms/epoch - 29ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5985 - mse: 0.2418 - val_loss: 0.2757 - val_accuracy: 0.5000 - val_mse: 0.2757 - lr: 1.0000e-05 - 148ms/epoch - 30ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2386 - accuracy: 0.5693 - mse: 0.2386 - val_loss: 0.2757 - val_accuracy: 0.5000 - val_mse: 0.2757 - lr: 1.0000e-05 - 144ms/epoch - 29ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2443 - accuracy: 0.5693 - mse: 0.2443 - val_loss: 0.2758 - val_accuracy: 0.5000 - val_mse: 0.2758 - lr: 1.0000e-05 - 145ms/epoch - 29ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5547 - mse: 0.2423 - val_loss: 0.2758 - val_accuracy: 0.5000 - val_mse: 0.2758 - lr: 1.0000e-05 - 143ms/epoch - 29ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5693 - mse: 0.2432 - val_loss: 0.2759 - val_accuracy: 0.5000 - val_mse: 0.2759 - lr: 1.0000e-05 - 142ms/epoch - 28ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2402 - accuracy: 0.5693 - mse: 0.2402 - val_loss: 0.2760 - val_accuracy: 0.5000 - val_mse: 0.2760 - lr: 1.0000e-05 - 144ms/epoch - 29ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5766 - mse: 0.2430 - val_loss: 0.2760 - val_accuracy: 0.5000 - val_mse: 0.2760 - lr: 1.0000e-05 - 143ms/epoch - 29ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2441 - accuracy: 0.5766 - mse: 0.2441 - val_loss: 0.2761 - val_accuracy: 0.5000 - val_mse: 0.2761 - lr: 1.0000e-05 - 143ms/epoch - 29ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2376 - accuracy: 0.5912 - mse: 0.2376 - val_loss: 0.2762 - val_accuracy: 0.5000 - val_mse: 0.2762 - lr: 1.0000e-05 - 141ms/epoch - 28ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5912 - mse: 0.2426 - val_loss: 0.2763 - val_accuracy: 0.5000 - val_mse: 0.2763 - lr: 1.0000e-05 - 141ms/epoch - 28ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2451 - accuracy: 0.5620 - mse: 0.2451 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-05 - 144ms/epoch - 29ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2441 - accuracy: 0.5547 - mse: 0.2441 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 143ms/epoch - 29ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5547 - mse: 0.2489 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 140ms/epoch - 28ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5620 - mse: 0.2438 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 140ms/epoch - 28ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2410 - accuracy: 0.5766 - mse: 0.2410 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 144ms/epoch - 29ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.5766 - mse: 0.2447 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 143ms/epoch - 29ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5766 - mse: 0.2446 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 141ms/epoch - 28ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2402 - accuracy: 0.5766 - mse: 0.2402 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 140ms/epoch - 28ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2402 - accuracy: 0.5693 - mse: 0.2402 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 139ms/epoch - 28ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.5766 - mse: 0.2401 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 189ms/epoch - 38ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2441 - accuracy: 0.5839 - mse: 0.2441 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-07 - 144ms/epoch - 29ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2457 - accuracy: 0.5839 - mse: 0.2457 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-09 - 142ms/epoch - 28ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5693 - mse: 0.2416 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-09 - 142ms/epoch - 28ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5693 - mse: 0.2464 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-09 - 144ms/epoch - 29ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5547 - mse: 0.2478 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-09 - 144ms/epoch - 29ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5766 - mse: 0.2413 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-09 - 141ms/epoch - 28ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5693 - mse: 0.2491 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-09 - 144ms/epoch - 29ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5547 - mse: 0.2440 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-09 - 144ms/epoch - 29ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5839 - mse: 0.2421 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-09 - 146ms/epoch - 29ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5693 - mse: 0.2456 - val_loss: 0.2764 - val_accuracy: 0.5000 - val_mse: 0.2764 - lr: 1.0000e-09 - 142ms/epoch - 28ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2455 - accuracy: 0.5833 - mse: 0.2455\n",
      "2/2 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833\n",
      "Loss: 0.24545802175998688\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,802\n",
      "Trainable params: 40,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 8s - loss: 0.4671 - accuracy: 0.5985 - mse: 0.4671 - val_loss: 0.2480 - val_accuracy: 0.5625 - val_mse: 0.2480 - lr: 0.0010 - 8s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2653 - accuracy: 0.5693 - mse: 0.2653 - val_loss: 0.3041 - val_accuracy: 0.5625 - val_mse: 0.3041 - lr: 0.0010 - 229ms/epoch - 46ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2663 - accuracy: 0.5693 - mse: 0.2663 - val_loss: 0.2548 - val_accuracy: 0.5625 - val_mse: 0.2548 - lr: 0.0010 - 205ms/epoch - 41ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5693 - mse: 0.2448 - val_loss: 0.2484 - val_accuracy: 0.5625 - val_mse: 0.2484 - lr: 0.0010 - 190ms/epoch - 38ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5839 - mse: 0.2498 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 0.0010 - 166ms/epoch - 33ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5693 - mse: 0.2476 - val_loss: 0.2456 - val_accuracy: 0.5625 - val_mse: 0.2456 - lr: 0.0010 - 165ms/epoch - 33ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5474 - mse: 0.2459 - val_loss: 0.2499 - val_accuracy: 0.5625 - val_mse: 0.2499 - lr: 0.0010 - 225ms/epoch - 45ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2429 - accuracy: 0.5766 - mse: 0.2429 - val_loss: 0.2502 - val_accuracy: 0.5625 - val_mse: 0.2502 - lr: 0.0010 - 168ms/epoch - 34ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2387 - accuracy: 0.5985 - mse: 0.2387 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 0.0010 - 175ms/epoch - 35ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2356 - accuracy: 0.5985 - mse: 0.2356 - val_loss: 0.2457 - val_accuracy: 0.5625 - val_mse: 0.2457 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2370 - accuracy: 0.5912 - mse: 0.2370 - val_loss: 0.2453 - val_accuracy: 0.5625 - val_mse: 0.2453 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2394 - accuracy: 0.5693 - mse: 0.2394 - val_loss: 0.2453 - val_accuracy: 0.5625 - val_mse: 0.2453 - lr: 1.0000e-05 - 183ms/epoch - 37ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2369 - accuracy: 0.6496 - mse: 0.2369 - val_loss: 0.2454 - val_accuracy: 0.5625 - val_mse: 0.2454 - lr: 1.0000e-05 - 167ms/epoch - 33ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2396 - accuracy: 0.5547 - mse: 0.2396 - val_loss: 0.2454 - val_accuracy: 0.5625 - val_mse: 0.2454 - lr: 1.0000e-05 - 198ms/epoch - 40ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2337 - accuracy: 0.6204 - mse: 0.2337 - val_loss: 0.2455 - val_accuracy: 0.5625 - val_mse: 0.2455 - lr: 1.0000e-05 - 196ms/epoch - 39ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2377 - accuracy: 0.5839 - mse: 0.2377 - val_loss: 0.2455 - val_accuracy: 0.5625 - val_mse: 0.2455 - lr: 1.0000e-05 - 186ms/epoch - 37ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2342 - accuracy: 0.6569 - mse: 0.2342 - val_loss: 0.2456 - val_accuracy: 0.5625 - val_mse: 0.2456 - lr: 1.0000e-05 - 190ms/epoch - 38ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2372 - accuracy: 0.6204 - mse: 0.2372 - val_loss: 0.2457 - val_accuracy: 0.5625 - val_mse: 0.2457 - lr: 1.0000e-05 - 164ms/epoch - 33ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2392 - accuracy: 0.5912 - mse: 0.2392 - val_loss: 0.2457 - val_accuracy: 0.5625 - val_mse: 0.2457 - lr: 1.0000e-05 - 181ms/epoch - 36ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2349 - accuracy: 0.6058 - mse: 0.2349 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 200ms/epoch - 40ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.6058 - mse: 0.2416 - val_loss: 0.2459 - val_accuracy: 0.5625 - val_mse: 0.2459 - lr: 1.0000e-05 - 163ms/epoch - 33ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2362 - accuracy: 0.6350 - mse: 0.2362 - val_loss: 0.2460 - val_accuracy: 0.5625 - val_mse: 0.2460 - lr: 1.0000e-05 - 236ms/epoch - 47ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2347 - accuracy: 0.6350 - mse: 0.2347 - val_loss: 0.2460 - val_accuracy: 0.5625 - val_mse: 0.2460 - lr: 1.0000e-05 - 181ms/epoch - 36ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2405 - accuracy: 0.5912 - mse: 0.2405 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 165ms/epoch - 33ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2385 - accuracy: 0.5839 - mse: 0.2385 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 166ms/epoch - 33ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2349 - accuracy: 0.6423 - mse: 0.2349 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 204ms/epoch - 41ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2365 - accuracy: 0.6277 - mse: 0.2365 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-05 - 216ms/epoch - 43ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2391 - accuracy: 0.5839 - mse: 0.2391 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 192ms/epoch - 38ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2380 - accuracy: 0.6058 - mse: 0.2380 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 168ms/epoch - 34ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2347 - accuracy: 0.6423 - mse: 0.2347 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 161ms/epoch - 32ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2388 - accuracy: 0.5839 - mse: 0.2388 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 165ms/epoch - 33ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2390 - accuracy: 0.6058 - mse: 0.2390 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 167ms/epoch - 33ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5328 - mse: 0.2423 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 211ms/epoch - 42ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2345 - accuracy: 0.6423 - mse: 0.2345 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 158ms/epoch - 32ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2346 - accuracy: 0.5474 - mse: 0.2346 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 157ms/epoch - 31ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2344 - accuracy: 0.6496 - mse: 0.2344 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 155ms/epoch - 31ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2397 - accuracy: 0.5912 - mse: 0.2397 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-07 - 162ms/epoch - 32ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2345 - accuracy: 0.6496 - mse: 0.2345 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 158ms/epoch - 32ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2381 - accuracy: 0.5766 - mse: 0.2381 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 162ms/epoch - 32ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2381 - accuracy: 0.5839 - mse: 0.2381 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 166ms/epoch - 33ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.5766 - mse: 0.2411 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 168ms/epoch - 34ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2356 - accuracy: 0.6277 - mse: 0.2356 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 161ms/epoch - 32ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2365 - accuracy: 0.5839 - mse: 0.2365 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 156ms/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2353 - accuracy: 0.6496 - mse: 0.2353 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 154ms/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2339 - accuracy: 0.6058 - mse: 0.2339 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 155ms/epoch - 31ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2400 - accuracy: 0.5839 - mse: 0.2400 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 174ms/epoch - 35ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2408 - accuracy: 0.6350 - mse: 0.2408 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-09 - 165ms/epoch - 33ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2379 - accuracy: 0.5766 - mse: 0.2379 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-11 - 161ms/epoch - 32ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2394 - accuracy: 0.5620 - mse: 0.2394 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-11 - 154ms/epoch - 31ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5693 - mse: 0.2469 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 1.0000e-11 - 160ms/epoch - 32ms/step\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2484 - accuracy: 0.5556 - mse: 0.2484\n",
      "2/2 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5556\n",
      "Loss: 0.24838876724243164\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,802\n",
      "Trainable params: 40,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 8s - loss: 0.4660 - accuracy: 0.5074 - mse: 0.4660 - val_loss: 0.2501 - val_accuracy: 0.5625 - val_mse: 0.2501 - lr: 0.0010 - 8s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2791 - accuracy: 0.4485 - mse: 0.2791 - val_loss: 0.3031 - val_accuracy: 0.4375 - val_mse: 0.3031 - lr: 0.0010 - 168ms/epoch - 34ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2750 - accuracy: 0.4559 - mse: 0.2750 - val_loss: 0.2545 - val_accuracy: 0.4375 - val_mse: 0.2545 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2509 - accuracy: 0.5588 - mse: 0.2509 - val_loss: 0.2497 - val_accuracy: 0.5625 - val_mse: 0.2497 - lr: 0.0010 - 164ms/epoch - 33ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2557 - accuracy: 0.5294 - mse: 0.2557 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 0.0010 - 233ms/epoch - 47ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2525 - accuracy: 0.4926 - mse: 0.2525 - val_loss: 0.2460 - val_accuracy: 0.5625 - val_mse: 0.2460 - lr: 0.0010 - 223ms/epoch - 45ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5956 - mse: 0.2482 - val_loss: 0.2494 - val_accuracy: 0.5625 - val_mse: 0.2494 - lr: 0.0010 - 175ms/epoch - 35ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2524 - accuracy: 0.4632 - mse: 0.2524 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5735 - mse: 0.2465 - val_loss: 0.2445 - val_accuracy: 0.5625 - val_mse: 0.2445 - lr: 0.0010 - 246ms/epoch - 49ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2510 - accuracy: 0.5294 - mse: 0.2510 - val_loss: 0.2433 - val_accuracy: 0.5625 - val_mse: 0.2433 - lr: 0.0010 - 186ms/epoch - 37ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5368 - mse: 0.2465 - val_loss: 0.2433 - val_accuracy: 0.5625 - val_mse: 0.2433 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2537 - accuracy: 0.5074 - mse: 0.2537 - val_loss: 0.2437 - val_accuracy: 0.5625 - val_mse: 0.2437 - lr: 0.0010 - 186ms/epoch - 37ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5441 - mse: 0.2482 - val_loss: 0.2438 - val_accuracy: 0.5625 - val_mse: 0.2438 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5588 - mse: 0.2466 - val_loss: 0.2427 - val_accuracy: 0.5625 - val_mse: 0.2427 - lr: 0.0010 - 169ms/epoch - 34ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5441 - mse: 0.2466 - val_loss: 0.2423 - val_accuracy: 0.5625 - val_mse: 0.2423 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.6176 - mse: 0.2488 - val_loss: 0.2416 - val_accuracy: 0.5625 - val_mse: 0.2416 - lr: 0.0010 - 165ms/epoch - 33ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2443 - accuracy: 0.5368 - mse: 0.2443 - val_loss: 0.2412 - val_accuracy: 0.5625 - val_mse: 0.2412 - lr: 0.0010 - 162ms/epoch - 32ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.6103 - mse: 0.2430 - val_loss: 0.2411 - val_accuracy: 0.5625 - val_mse: 0.2411 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2372 - accuracy: 0.6250 - mse: 0.2372 - val_loss: 0.2410 - val_accuracy: 0.5625 - val_mse: 0.2410 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5515 - mse: 0.2430 - val_loss: 0.2399 - val_accuracy: 0.5625 - val_mse: 0.2399 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5515 - mse: 0.2485 - val_loss: 0.2396 - val_accuracy: 0.5625 - val_mse: 0.2396 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2439 - accuracy: 0.6103 - mse: 0.2439 - val_loss: 0.2392 - val_accuracy: 0.5625 - val_mse: 0.2392 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5441 - mse: 0.2473 - val_loss: 0.2388 - val_accuracy: 0.5625 - val_mse: 0.2388 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.6176 - mse: 0.2401 - val_loss: 0.2384 - val_accuracy: 0.5625 - val_mse: 0.2384 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.6029 - mse: 0.2409 - val_loss: 0.2374 - val_accuracy: 0.5625 - val_mse: 0.2374 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5441 - mse: 0.2427 - val_loss: 0.2361 - val_accuracy: 0.5625 - val_mse: 0.2361 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5809 - mse: 0.2426 - val_loss: 0.2353 - val_accuracy: 0.5625 - val_mse: 0.2353 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2397 - accuracy: 0.5956 - mse: 0.2397 - val_loss: 0.2343 - val_accuracy: 0.6250 - val_mse: 0.2343 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2368 - accuracy: 0.5735 - mse: 0.2368 - val_loss: 0.2326 - val_accuracy: 0.6875 - val_mse: 0.2326 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.5735 - mse: 0.2406 - val_loss: 0.2326 - val_accuracy: 0.6875 - val_mse: 0.2326 - lr: 1.0000e-05 - 149ms/epoch - 30ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2296 - accuracy: 0.6544 - mse: 0.2296 - val_loss: 0.2325 - val_accuracy: 0.6875 - val_mse: 0.2325 - lr: 1.0000e-05 - 153ms/epoch - 31ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2319 - accuracy: 0.6544 - mse: 0.2319 - val_loss: 0.2325 - val_accuracy: 0.6875 - val_mse: 0.2325 - lr: 1.0000e-05 - 154ms/epoch - 31ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2303 - accuracy: 0.6765 - mse: 0.2303 - val_loss: 0.2324 - val_accuracy: 0.6875 - val_mse: 0.2324 - lr: 1.0000e-05 - 152ms/epoch - 30ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2317 - accuracy: 0.6471 - mse: 0.2317 - val_loss: 0.2323 - val_accuracy: 0.6875 - val_mse: 0.2323 - lr: 1.0000e-05 - 151ms/epoch - 30ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2355 - accuracy: 0.6176 - mse: 0.2355 - val_loss: 0.2323 - val_accuracy: 0.6875 - val_mse: 0.2323 - lr: 1.0000e-05 - 152ms/epoch - 30ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2345 - accuracy: 0.6544 - mse: 0.2345 - val_loss: 0.2323 - val_accuracy: 0.6875 - val_mse: 0.2323 - lr: 1.0000e-05 - 201ms/epoch - 40ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2371 - accuracy: 0.6029 - mse: 0.2371 - val_loss: 0.2322 - val_accuracy: 0.6875 - val_mse: 0.2322 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2386 - accuracy: 0.5809 - mse: 0.2386 - val_loss: 0.2322 - val_accuracy: 0.6875 - val_mse: 0.2322 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2370 - accuracy: 0.5662 - mse: 0.2370 - val_loss: 0.2322 - val_accuracy: 0.6875 - val_mse: 0.2322 - lr: 1.0000e-05 - 164ms/epoch - 33ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2371 - accuracy: 0.6324 - mse: 0.2371 - val_loss: 0.2322 - val_accuracy: 0.6875 - val_mse: 0.2322 - lr: 1.0000e-05 - 146ms/epoch - 29ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2349 - accuracy: 0.6324 - mse: 0.2349 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-05 - 147ms/epoch - 29ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2357 - accuracy: 0.5956 - mse: 0.2357 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-05 - 146ms/epoch - 29ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2313 - accuracy: 0.5956 - mse: 0.2313 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-05 - 144ms/epoch - 29ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2272 - accuracy: 0.6544 - mse: 0.2272 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-07 - 143ms/epoch - 29ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2359 - accuracy: 0.6324 - mse: 0.2359 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-07 - 144ms/epoch - 29ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2296 - accuracy: 0.6029 - mse: 0.2296 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-07 - 143ms/epoch - 29ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5662 - mse: 0.2412 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-07 - 144ms/epoch - 29ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2338 - accuracy: 0.6397 - mse: 0.2338 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-07 - 144ms/epoch - 29ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2325 - accuracy: 0.6397 - mse: 0.2325 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-07 - 142ms/epoch - 28ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2280 - accuracy: 0.6838 - mse: 0.2280 - val_loss: 0.2321 - val_accuracy: 0.6875 - val_mse: 0.2321 - lr: 1.0000e-07 - 143ms/epoch - 29ms/step\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2473 - accuracy: 0.5556 - mse: 0.2473\n",
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5556\n",
      "Loss: 0.2472878247499466\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,802\n",
      "Trainable params: 40,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 7s - loss: 0.4892 - accuracy: 0.5839 - mse: 0.4892 - val_loss: 0.2228 - val_accuracy: 0.6875 - val_mse: 0.2228 - lr: 0.0010 - 7s/epoch - 1s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2638 - accuracy: 0.5912 - mse: 0.2638 - val_loss: 0.2878 - val_accuracy: 0.6875 - val_mse: 0.2878 - lr: 0.0010 - 143ms/epoch - 29ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2702 - accuracy: 0.5912 - mse: 0.2702 - val_loss: 0.2314 - val_accuracy: 0.6875 - val_mse: 0.2314 - lr: 0.0010 - 145ms/epoch - 29ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5912 - mse: 0.2472 - val_loss: 0.2174 - val_accuracy: 0.6875 - val_mse: 0.2174 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5912 - mse: 0.2496 - val_loss: 0.2251 - val_accuracy: 0.6875 - val_mse: 0.2251 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5912 - mse: 0.2469 - val_loss: 0.2273 - val_accuracy: 0.6875 - val_mse: 0.2273 - lr: 0.0010 - 142ms/epoch - 28ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5912 - mse: 0.2448 - val_loss: 0.2299 - val_accuracy: 0.6875 - val_mse: 0.2299 - lr: 0.0010 - 146ms/epoch - 29ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5912 - mse: 0.2427 - val_loss: 0.2259 - val_accuracy: 0.6875 - val_mse: 0.2259 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5912 - mse: 0.2421 - val_loss: 0.2206 - val_accuracy: 0.6875 - val_mse: 0.2206 - lr: 0.0010 - 149ms/epoch - 30ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5912 - mse: 0.2440 - val_loss: 0.2204 - val_accuracy: 0.6875 - val_mse: 0.2204 - lr: 0.0010 - 148ms/epoch - 30ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2224 - val_accuracy: 0.6875 - val_mse: 0.2224 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.5912 - mse: 0.2409 - val_loss: 0.2241 - val_accuracy: 0.6875 - val_mse: 0.2241 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5912 - mse: 0.2425 - val_loss: 0.2241 - val_accuracy: 0.6875 - val_mse: 0.2241 - lr: 1.0000e-05 - 150ms/epoch - 30ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2417 - accuracy: 0.5912 - mse: 0.2417 - val_loss: 0.2240 - val_accuracy: 0.6875 - val_mse: 0.2240 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.5912 - mse: 0.2409 - val_loss: 0.2240 - val_accuracy: 0.6875 - val_mse: 0.2240 - lr: 1.0000e-05 - 166ms/epoch - 33ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5912 - mse: 0.2423 - val_loss: 0.2239 - val_accuracy: 0.6875 - val_mse: 0.2239 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.5912 - mse: 0.2406 - val_loss: 0.2238 - val_accuracy: 0.6875 - val_mse: 0.2238 - lr: 1.0000e-05 - 207ms/epoch - 41ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5912 - mse: 0.2412 - val_loss: 0.2238 - val_accuracy: 0.6875 - val_mse: 0.2238 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2397 - accuracy: 0.5912 - mse: 0.2397 - val_loss: 0.2237 - val_accuracy: 0.6875 - val_mse: 0.2237 - lr: 1.0000e-05 - 147ms/epoch - 29ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2392 - accuracy: 0.5912 - mse: 0.2392 - val_loss: 0.2236 - val_accuracy: 0.6875 - val_mse: 0.2236 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5912 - mse: 0.2425 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2384 - accuracy: 0.5912 - mse: 0.2384 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-05 - 216ms/epoch - 43ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2397 - accuracy: 0.5912 - mse: 0.2397 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 163ms/epoch - 33ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2391 - accuracy: 0.5912 - mse: 0.2391 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 191ms/epoch - 38ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2408 - accuracy: 0.5912 - mse: 0.2408 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 230ms/epoch - 46ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2373 - accuracy: 0.5912 - mse: 0.2373 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 164ms/epoch - 33ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5912 - mse: 0.2427 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 155ms/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2396 - accuracy: 0.5912 - mse: 0.2396 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2392 - accuracy: 0.5912 - mse: 0.2392 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 156ms/epoch - 31ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2402 - accuracy: 0.5912 - mse: 0.2402 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 154ms/epoch - 31ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5912 - mse: 0.2416 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 157ms/epoch - 31ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.5912 - mse: 0.2401 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-07 - 160ms/epoch - 32ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2407 - accuracy: 0.5912 - mse: 0.2407 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 161ms/epoch - 32ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5912 - mse: 0.2412 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 160ms/epoch - 32ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2383 - accuracy: 0.5912 - mse: 0.2383 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 156ms/epoch - 31ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5912 - mse: 0.2423 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 154ms/epoch - 31ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5912 - mse: 0.2416 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 152ms/epoch - 30ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5912 - mse: 0.2432 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 152ms/epoch - 30ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 158ms/epoch - 32ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.5912 - mse: 0.2401 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 163ms/epoch - 33ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2381 - accuracy: 0.5912 - mse: 0.2381 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 173ms/epoch - 35ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2397 - accuracy: 0.5912 - mse: 0.2397 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-09 - 161ms/epoch - 32ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.5912 - mse: 0.2409 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-11 - 191ms/epoch - 38ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2387 - accuracy: 0.5912 - mse: 0.2387 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-11 - 161ms/epoch - 32ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2397 - accuracy: 0.5912 - mse: 0.2397 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-11 - 161ms/epoch - 32ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2365 - accuracy: 0.5912 - mse: 0.2365 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-11 - 156ms/epoch - 31ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2403 - accuracy: 0.5912 - mse: 0.2403 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-11 - 158ms/epoch - 32ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2381 - accuracy: 0.5912 - mse: 0.2381 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-11 - 162ms/epoch - 32ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2408 - accuracy: 0.5912 - mse: 0.2408 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-11 - 161ms/epoch - 32ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2394 - accuracy: 0.5912 - mse: 0.2394 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 1.0000e-11 - 165ms/epoch - 33ms/step\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2651 - accuracy: 0.4722 - mse: 0.2651\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020F83A63310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020F83A63310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4722\n",
      "Loss: 0.26513832807540894\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,802\n",
      "Trainable params: 40,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 7s - loss: 0.4602 - accuracy: 0.5766 - mse: 0.4602 - val_loss: 0.2364 - val_accuracy: 0.6250 - val_mse: 0.2364 - lr: 0.0010 - 7s/epoch - 1s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2715 - accuracy: 0.5620 - mse: 0.2715 - val_loss: 0.2893 - val_accuracy: 0.6250 - val_mse: 0.2893 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2760 - accuracy: 0.5620 - mse: 0.2760 - val_loss: 0.2457 - val_accuracy: 0.6250 - val_mse: 0.2457 - lr: 0.0010 - 182ms/epoch - 36ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2587 - accuracy: 0.5620 - mse: 0.2587 - val_loss: 0.2365 - val_accuracy: 0.6250 - val_mse: 0.2365 - lr: 0.0010 - 165ms/epoch - 33ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2564 - accuracy: 0.5620 - mse: 0.2564 - val_loss: 0.2357 - val_accuracy: 0.6250 - val_mse: 0.2357 - lr: 0.0010 - 183ms/epoch - 37ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2513 - accuracy: 0.5620 - mse: 0.2513 - val_loss: 0.2340 - val_accuracy: 0.6250 - val_mse: 0.2340 - lr: 0.0010 - 171ms/epoch - 34ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2449 - accuracy: 0.5620 - mse: 0.2449 - val_loss: 0.2358 - val_accuracy: 0.6250 - val_mse: 0.2358 - lr: 0.0010 - 211ms/epoch - 42ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5620 - mse: 0.2476 - val_loss: 0.2362 - val_accuracy: 0.6250 - val_mse: 0.2362 - lr: 0.0010 - 149ms/epoch - 30ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2497 - accuracy: 0.5620 - mse: 0.2497 - val_loss: 0.2341 - val_accuracy: 0.6250 - val_mse: 0.2341 - lr: 0.0010 - 149ms/epoch - 30ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2514 - accuracy: 0.5620 - mse: 0.2514 - val_loss: 0.2333 - val_accuracy: 0.6250 - val_mse: 0.2333 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5620 - mse: 0.2481 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 0.0010 - 169ms/epoch - 34ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5620 - mse: 0.2454 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 166ms/epoch - 33ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2524 - accuracy: 0.5620 - mse: 0.2524 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5620 - mse: 0.2475 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5620 - mse: 0.2471 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 192ms/epoch - 38ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 178ms/epoch - 36ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2510 - accuracy: 0.5620 - mse: 0.2510 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 167ms/epoch - 33ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5620 - mse: 0.2486 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 163ms/epoch - 33ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5620 - mse: 0.2483 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 165ms/epoch - 33ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5620 - mse: 0.2467 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 164ms/epoch - 33ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5620 - mse: 0.2476 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 162ms/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2457 - accuracy: 0.5620 - mse: 0.2457 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 232ms/epoch - 46ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5620 - mse: 0.2496 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 171ms/epoch - 34ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5620 - mse: 0.2475 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 180ms/epoch - 36ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5620 - mse: 0.2465 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2510 - accuracy: 0.5620 - mse: 0.2510 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5620 - mse: 0.2452 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 164ms/epoch - 33ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2508 - accuracy: 0.5620 - mse: 0.2508 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5620 - mse: 0.2469 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 169ms/epoch - 34ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5620 - mse: 0.2473 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 172ms/epoch - 34ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2495 - accuracy: 0.5620 - mse: 0.2495 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-07 - 192ms/epoch - 38ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5620 - mse: 0.2452 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 211ms/epoch - 42ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.5620 - mse: 0.2442 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 178ms/epoch - 36ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2524 - accuracy: 0.5620 - mse: 0.2524 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 217ms/epoch - 43ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5620 - mse: 0.2456 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 233ms/epoch - 47ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5620 - mse: 0.2489 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 165ms/epoch - 33ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2494 - accuracy: 0.5620 - mse: 0.2494 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 166ms/epoch - 33ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5620 - mse: 0.2491 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 167ms/epoch - 33ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2497 - accuracy: 0.5620 - mse: 0.2497 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 156ms/epoch - 31ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5620 - mse: 0.2487 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 163ms/epoch - 33ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5620 - mse: 0.2484 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-09 - 160ms/epoch - 32ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5620 - mse: 0.2483 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-11 - 162ms/epoch - 32ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2515 - accuracy: 0.5620 - mse: 0.2515 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-11 - 163ms/epoch - 33ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5620 - mse: 0.2493 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-11 - 172ms/epoch - 34ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5620 - mse: 0.2473 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-11 - 166ms/epoch - 33ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5620 - mse: 0.2492 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-11 - 158ms/epoch - 32ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5620 - mse: 0.2472 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-11 - 170ms/epoch - 34ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5620 - mse: 0.2465 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-11 - 170ms/epoch - 34ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5620 - mse: 0.2456 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-11 - 157ms/epoch - 31ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2505 - accuracy: 0.5620 - mse: 0.2505 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-11 - 166ms/epoch - 33ms/step\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2156 - accuracy: 0.6944 - mse: 0.2156\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020F8A55E3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020F8A55E3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6944\n",
      "Loss: 0.2156161665916443\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,802\n",
      "Trainable params: 40,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 7s - loss: 0.4588 - accuracy: 0.5474 - mse: 0.4588 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 0.0010 - 7s/epoch - 1s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2757 - accuracy: 0.5547 - mse: 0.2757 - val_loss: 0.2924 - val_accuracy: 0.5625 - val_mse: 0.2924 - lr: 0.0010 - 165ms/epoch - 33ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2784 - accuracy: 0.5547 - mse: 0.2784 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2512 - accuracy: 0.5474 - mse: 0.2512 - val_loss: 0.2577 - val_accuracy: 0.5625 - val_mse: 0.2577 - lr: 0.0010 - 171ms/epoch - 34ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2580 - accuracy: 0.5474 - mse: 0.2580 - val_loss: 0.2540 - val_accuracy: 0.5625 - val_mse: 0.2540 - lr: 0.0010 - 194ms/epoch - 39ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2514 - accuracy: 0.5401 - mse: 0.2514 - val_loss: 0.2453 - val_accuracy: 0.5625 - val_mse: 0.2453 - lr: 0.0010 - 169ms/epoch - 34ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2508 - accuracy: 0.5547 - mse: 0.2508 - val_loss: 0.2469 - val_accuracy: 0.5625 - val_mse: 0.2469 - lr: 0.0010 - 170ms/epoch - 34ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2497 - accuracy: 0.5547 - mse: 0.2497 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 0.0010 - 179ms/epoch - 36ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2451 - val_accuracy: 0.5625 - val_mse: 0.2451 - lr: 0.0010 - 162ms/epoch - 32ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5547 - mse: 0.2489 - val_loss: 0.2459 - val_accuracy: 0.5625 - val_mse: 0.2459 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2452 - val_accuracy: 0.5625 - val_mse: 0.2452 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5620 - mse: 0.2440 - val_loss: 0.2451 - val_accuracy: 0.5625 - val_mse: 0.2451 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2452 - val_accuracy: 0.5625 - val_mse: 0.2452 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5693 - mse: 0.2461 - val_loss: 0.2449 - val_accuracy: 0.5625 - val_mse: 0.2449 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2450 - accuracy: 0.5620 - mse: 0.2450 - val_loss: 0.2448 - val_accuracy: 0.5625 - val_mse: 0.2448 - lr: 0.0010 - 240ms/epoch - 48ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5547 - mse: 0.2467 - val_loss: 0.2447 - val_accuracy: 0.5625 - val_mse: 0.2447 - lr: 0.0010 - 216ms/epoch - 43ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5620 - mse: 0.2477 - val_loss: 0.2446 - val_accuracy: 0.5625 - val_mse: 0.2446 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5547 - mse: 0.2487 - val_loss: 0.2447 - val_accuracy: 0.5625 - val_mse: 0.2447 - lr: 0.0010 - 164ms/epoch - 33ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5693 - mse: 0.2453 - val_loss: 0.2446 - val_accuracy: 0.5625 - val_mse: 0.2446 - lr: 0.0010 - 162ms/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2449 - accuracy: 0.5547 - mse: 0.2449 - val_loss: 0.2444 - val_accuracy: 0.5625 - val_mse: 0.2444 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5766 - mse: 0.2427 - val_loss: 0.2441 - val_accuracy: 0.5625 - val_mse: 0.2441 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5693 - mse: 0.2456 - val_loss: 0.2440 - val_accuracy: 0.5625 - val_mse: 0.2440 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5547 - mse: 0.2461 - val_loss: 0.2438 - val_accuracy: 0.5625 - val_mse: 0.2438 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5620 - mse: 0.2461 - val_loss: 0.2440 - val_accuracy: 0.5625 - val_mse: 0.2440 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5620 - mse: 0.2484 - val_loss: 0.2435 - val_accuracy: 0.5625 - val_mse: 0.2435 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2449 - accuracy: 0.5620 - mse: 0.2449 - val_loss: 0.2429 - val_accuracy: 0.5625 - val_mse: 0.2429 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5766 - mse: 0.2431 - val_loss: 0.2429 - val_accuracy: 0.5625 - val_mse: 0.2429 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.5620 - mse: 0.2409 - val_loss: 0.2424 - val_accuracy: 0.5625 - val_mse: 0.2424 - lr: 0.0010 - 167ms/epoch - 33ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2376 - accuracy: 0.5912 - mse: 0.2376 - val_loss: 0.2416 - val_accuracy: 0.5625 - val_mse: 0.2416 - lr: 0.0010 - 168ms/epoch - 34ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2352 - accuracy: 0.6277 - mse: 0.2352 - val_loss: 0.2407 - val_accuracy: 0.5625 - val_mse: 0.2407 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5912 - mse: 0.2426 - val_loss: 0.2395 - val_accuracy: 0.5625 - val_mse: 0.2395 - lr: 0.0010 - 185ms/epoch - 37ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.5547 - mse: 0.2401 - val_loss: 0.2388 - val_accuracy: 0.5625 - val_mse: 0.2388 - lr: 0.0010 - 165ms/epoch - 33ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.6058 - mse: 0.2406 - val_loss: 0.2373 - val_accuracy: 0.6250 - val_mse: 0.2373 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2366 - accuracy: 0.6058 - mse: 0.2366 - val_loss: 0.2359 - val_accuracy: 0.6250 - val_mse: 0.2359 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2366 - accuracy: 0.6204 - mse: 0.2366 - val_loss: 0.2344 - val_accuracy: 0.6250 - val_mse: 0.2344 - lr: 0.0010 - 169ms/epoch - 34ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2321 - accuracy: 0.6350 - mse: 0.2321 - val_loss: 0.2330 - val_accuracy: 0.6250 - val_mse: 0.2330 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2233 - accuracy: 0.6569 - mse: 0.2233 - val_loss: 0.2317 - val_accuracy: 0.6250 - val_mse: 0.2317 - lr: 0.0010 - 167ms/epoch - 33ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2264 - accuracy: 0.6204 - mse: 0.2264 - val_loss: 0.2301 - val_accuracy: 0.6875 - val_mse: 0.2301 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2280 - accuracy: 0.6204 - mse: 0.2280 - val_loss: 0.2285 - val_accuracy: 0.6875 - val_mse: 0.2285 - lr: 0.0010 - 166ms/epoch - 33ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2371 - accuracy: 0.6350 - mse: 0.2371 - val_loss: 0.2290 - val_accuracy: 0.6250 - val_mse: 0.2290 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2259 - accuracy: 0.6131 - mse: 0.2259 - val_loss: 0.2272 - val_accuracy: 0.5625 - val_mse: 0.2272 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2222 - accuracy: 0.6423 - mse: 0.2222 - val_loss: 0.2234 - val_accuracy: 0.7500 - val_mse: 0.2234 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2295 - accuracy: 0.6496 - mse: 0.2295 - val_loss: 0.2194 - val_accuracy: 0.7500 - val_mse: 0.2194 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2192 - accuracy: 0.6423 - mse: 0.2192 - val_loss: 0.2249 - val_accuracy: 0.6250 - val_mse: 0.2249 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2099 - accuracy: 0.6934 - mse: 0.2099 - val_loss: 0.2219 - val_accuracy: 0.5625 - val_mse: 0.2219 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2147 - accuracy: 0.6569 - mse: 0.2147 - val_loss: 0.2311 - val_accuracy: 0.6250 - val_mse: 0.2311 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1838 - accuracy: 0.6861 - mse: 0.1838 - val_loss: 0.2178 - val_accuracy: 0.5625 - val_mse: 0.2178 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2200 - accuracy: 0.6642 - mse: 0.2200 - val_loss: 0.2267 - val_accuracy: 0.6875 - val_mse: 0.2267 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2098 - accuracy: 0.6496 - mse: 0.2098 - val_loss: 0.2154 - val_accuracy: 0.5000 - val_mse: 0.2154 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2151 - accuracy: 0.6350 - mse: 0.2151 - val_loss: 0.2142 - val_accuracy: 0.6875 - val_mse: 0.2142 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2346 - accuracy: 0.5278 - mse: 0.2346\n",
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5278\n",
      "Loss: 0.23459015786647797\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,802\n",
      "Trainable params: 40,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 7s - loss: 0.4839 - accuracy: 0.5839 - mse: 0.4839 - val_loss: 0.2348 - val_accuracy: 0.6250 - val_mse: 0.2348 - lr: 0.0010 - 7s/epoch - 1s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2702 - accuracy: 0.5474 - mse: 0.2702 - val_loss: 0.2996 - val_accuracy: 0.6250 - val_mse: 0.2996 - lr: 0.0010 - 177ms/epoch - 35ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2762 - accuracy: 0.5401 - mse: 0.2762 - val_loss: 0.2516 - val_accuracy: 0.6250 - val_mse: 0.2516 - lr: 0.0010 - 180ms/epoch - 36ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5474 - mse: 0.2472 - val_loss: 0.2369 - val_accuracy: 0.6250 - val_mse: 0.2369 - lr: 0.0010 - 174ms/epoch - 35ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2530 - accuracy: 0.5474 - mse: 0.2530 - val_loss: 0.2387 - val_accuracy: 0.6250 - val_mse: 0.2387 - lr: 0.0010 - 165ms/epoch - 33ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2552 - accuracy: 0.5401 - mse: 0.2552 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 0.0010 - 196ms/epoch - 39ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5693 - mse: 0.2458 - val_loss: 0.2415 - val_accuracy: 0.6250 - val_mse: 0.2415 - lr: 0.0010 - 180ms/epoch - 36ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2441 - accuracy: 0.5693 - mse: 0.2441 - val_loss: 0.2388 - val_accuracy: 0.6250 - val_mse: 0.2388 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2443 - accuracy: 0.5474 - mse: 0.2443 - val_loss: 0.2367 - val_accuracy: 0.6250 - val_mse: 0.2367 - lr: 0.0010 - 164ms/epoch - 33ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5766 - mse: 0.2455 - val_loss: 0.2358 - val_accuracy: 0.6250 - val_mse: 0.2358 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5547 - mse: 0.2462 - val_loss: 0.2358 - val_accuracy: 0.6250 - val_mse: 0.2358 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2441 - accuracy: 0.6058 - mse: 0.2441 - val_loss: 0.2358 - val_accuracy: 0.6250 - val_mse: 0.2358 - lr: 1.0000e-05 - 157ms/epoch - 31ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5620 - mse: 0.2430 - val_loss: 0.2358 - val_accuracy: 0.6250 - val_mse: 0.2358 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5036 - mse: 0.2485 - val_loss: 0.2358 - val_accuracy: 0.6250 - val_mse: 0.2358 - lr: 1.0000e-05 - 159ms/epoch - 32ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5620 - mse: 0.2483 - val_loss: 0.2359 - val_accuracy: 0.6250 - val_mse: 0.2359 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5839 - mse: 0.2418 - val_loss: 0.2359 - val_accuracy: 0.6250 - val_mse: 0.2359 - lr: 1.0000e-05 - 168ms/epoch - 34ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5401 - mse: 0.2423 - val_loss: 0.2359 - val_accuracy: 0.6250 - val_mse: 0.2359 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5693 - mse: 0.2471 - val_loss: 0.2359 - val_accuracy: 0.6250 - val_mse: 0.2359 - lr: 1.0000e-05 - 157ms/epoch - 31ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2428 - accuracy: 0.5547 - mse: 0.2428 - val_loss: 0.2360 - val_accuracy: 0.6250 - val_mse: 0.2360 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2523 - accuracy: 0.5474 - mse: 0.2523 - val_loss: 0.2360 - val_accuracy: 0.6250 - val_mse: 0.2360 - lr: 1.0000e-05 - 157ms/epoch - 31ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5255 - mse: 0.2467 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5766 - mse: 0.2448 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5766 - mse: 0.2446 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 156ms/epoch - 31ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.6058 - mse: 0.2442 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2495 - accuracy: 0.5547 - mse: 0.2495 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 155ms/epoch - 31ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5547 - mse: 0.2491 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 162ms/epoch - 32ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2494 - accuracy: 0.5766 - mse: 0.2494 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 158ms/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5693 - mse: 0.2444 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 160ms/epoch - 32ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5912 - mse: 0.2420 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 157ms/epoch - 31ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5620 - mse: 0.2468 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 161ms/epoch - 32ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5766 - mse: 0.2454 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5693 - mse: 0.2479 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-07 - 182ms/epoch - 36ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5474 - mse: 0.2458 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 161ms/epoch - 32ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 160ms/epoch - 32ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5474 - mse: 0.2483 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 158ms/epoch - 32ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2495 - accuracy: 0.5766 - mse: 0.2495 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 163ms/epoch - 33ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5912 - mse: 0.2414 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 157ms/epoch - 31ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5474 - mse: 0.2465 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 158ms/epoch - 32ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5474 - mse: 0.2477 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 158ms/epoch - 32ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2434 - accuracy: 0.5693 - mse: 0.2434 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 169ms/epoch - 34ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5547 - mse: 0.2491 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 155ms/epoch - 31ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2457 - accuracy: 0.5255 - mse: 0.2457 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-09 - 158ms/epoch - 32ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2495 - accuracy: 0.5109 - mse: 0.2495 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-11 - 156ms/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5693 - mse: 0.2475 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-11 - 209ms/epoch - 42ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5401 - mse: 0.2426 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-11 - 160ms/epoch - 32ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5839 - mse: 0.2432 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-11 - 151ms/epoch - 30ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5547 - mse: 0.2446 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-11 - 158ms/epoch - 32ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2451 - accuracy: 0.5620 - mse: 0.2451 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-11 - 162ms/epoch - 32ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5766 - mse: 0.2472 - val_loss: 0.2361 - val_accuracy: 0.6250 - val_mse: 0.2361 - lr: 1.0000e-11 - 154ms/epoch - 31ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2338 - accuracy: 0.6389 - mse: 0.2338\n",
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6389\n",
      "Loss: 0.23384849727153778\n"
     ]
    }
   ],
   "source": [
    "def train_model_2_2( xTrain, yTrain, xValid , yValid):\n",
    "    random.seed(26)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM( 32 ,input_shape = (19,75), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.3))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "    model.build()   \n",
    "    model.summary()\n",
    "    model.compile( optimizer = \"adam\" , loss = 'mean_squared_error' , metrics = ['accuracy', 'mse'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau( monitor = 'accuracy', factor = 0.01, patience=10, cooldown=0)\n",
    "    \n",
    "    callbacks = [ reduce_lr ]\n",
    "    train_history = model.fit( xTrain, yTrain , epochs = 50, shuffle=False, callbacks=callbacks, verbose = 2, validation_split = 0.1)\n",
    "\n",
    "    score = model.evaluate( xValid , yValid )\n",
    "    pred = model.predict(xValid)\n",
    "    model.save(\"LSTM_1\")\n",
    "    \n",
    "    print( \"Accuracy: {:0.4}\".format( score[1] ))\n",
    "    print( \"Loss:\", score[0] )\n",
    "    return score, pred, train_history\n",
    "\n",
    "results_2012, pred_2012, history_2012 = train_model_2_2(x_train_2012, y_train_2012_OHE, x_valid_2012, y_valid_2012_OHE) \n",
    "results_2013, pred_2013, history_2013 = train_model_2_2(x_train_2013, y_train_2013_OHE, x_valid_2013, y_valid_2013_OHE) \n",
    "results_2014, pred_2014, history_2014 = train_model_2_2(x_train_2014, y_train_2014_OHE, x_valid_2014, y_valid_2014_OHE) \n",
    "results_2015, pred_2015, history_2015 = train_model_2_2(x_train_2015, y_train_2015_OHE, x_valid_2015, y_valid_2015_OHE) \n",
    "results_2016, pred_2016, history_2016 = train_model_2_2(x_train_2016, y_train_2016_OHE, x_valid_2016, y_valid_2016_OHE) \n",
    "results_2017, pred_2017, history_2017 = train_model_2_2(x_train_2017, y_train_2017_OHE, x_valid_2017, y_valid_2017_OHE) \n",
    "results_2018, pred_2018, history_2018 = train_model_2_2(x_train_2018, y_train_2018_OHE, x_valid_2018, y_valid_2018_OHE) \n",
    "results_2019, pred_2019, history_2019 = train_model_2_2(x_train_2019, y_train_2019_OHE, x_valid_2019, y_valid_2019_OHE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_34 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,314\n",
      "Trainable params: 55,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 14s - loss: 0.4113 - accuracy: 0.4307 - mse: 0.4113 - val_loss: 0.2676 - val_accuracy: 0.7500 - val_mse: 0.2676 - lr: 0.0010 - 14s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2674 - accuracy: 0.4599 - mse: 0.2674 - val_loss: 0.2742 - val_accuracy: 0.2500 - val_mse: 0.2742 - lr: 0.0010 - 251ms/epoch - 50ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2647 - accuracy: 0.4307 - mse: 0.2647 - val_loss: 0.2608 - val_accuracy: 0.7500 - val_mse: 0.2608 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2569 - accuracy: 0.5255 - mse: 0.2569 - val_loss: 0.2301 - val_accuracy: 0.7500 - val_mse: 0.2301 - lr: 0.0010 - 256ms/epoch - 51ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.5255 - mse: 0.2500 - val_loss: 0.2538 - val_accuracy: 0.2500 - val_mse: 0.2538 - lr: 0.0010 - 307ms/epoch - 61ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2521 - accuracy: 0.5036 - mse: 0.2521 - val_loss: 0.2734 - val_accuracy: 0.2500 - val_mse: 0.2734 - lr: 0.0010 - 273ms/epoch - 55ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2533 - accuracy: 0.4599 - mse: 0.2533 - val_loss: 0.2549 - val_accuracy: 0.2500 - val_mse: 0.2549 - lr: 0.0010 - 244ms/epoch - 49ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2512 - accuracy: 0.5255 - mse: 0.2512 - val_loss: 0.2413 - val_accuracy: 0.7500 - val_mse: 0.2413 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.5255 - mse: 0.2500 - val_loss: 0.2459 - val_accuracy: 0.7500 - val_mse: 0.2459 - lr: 0.0010 - 263ms/epoch - 53ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.5182 - mse: 0.2500 - val_loss: 0.2548 - val_accuracy: 0.2500 - val_mse: 0.2548 - lr: 0.0010 - 248ms/epoch - 50ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2512 - accuracy: 0.4672 - mse: 0.2512 - val_loss: 0.2567 - val_accuracy: 0.2500 - val_mse: 0.2567 - lr: 0.0010 - 284ms/epoch - 57ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2507 - accuracy: 0.4453 - mse: 0.2507 - val_loss: 0.2531 - val_accuracy: 0.2500 - val_mse: 0.2531 - lr: 0.0010 - 281ms/epoch - 56ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5401 - mse: 0.2489 - val_loss: 0.2520 - val_accuracy: 0.2500 - val_mse: 0.2520 - lr: 0.0010 - 251ms/epoch - 50ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5547 - mse: 0.2491 - val_loss: 0.2541 - val_accuracy: 0.2500 - val_mse: 0.2541 - lr: 0.0010 - 252ms/epoch - 50ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5328 - mse: 0.2489 - val_loss: 0.2552 - val_accuracy: 0.2500 - val_mse: 0.2552 - lr: 0.0010 - 242ms/epoch - 48ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5182 - mse: 0.2496 - val_loss: 0.2549 - val_accuracy: 0.2500 - val_mse: 0.2549 - lr: 0.0010 - 247ms/epoch - 49ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5255 - mse: 0.2498 - val_loss: 0.2570 - val_accuracy: 0.2500 - val_mse: 0.2570 - lr: 0.0010 - 241ms/epoch - 48ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5693 - mse: 0.2477 - val_loss: 0.2591 - val_accuracy: 0.2500 - val_mse: 0.2591 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2508 - accuracy: 0.5182 - mse: 0.2508 - val_loss: 0.2614 - val_accuracy: 0.2500 - val_mse: 0.2614 - lr: 0.0010 - 240ms/epoch - 48ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2517 - accuracy: 0.5109 - mse: 0.2517 - val_loss: 0.2642 - val_accuracy: 0.2500 - val_mse: 0.2642 - lr: 0.0010 - 289ms/epoch - 58ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5474 - mse: 0.2492 - val_loss: 0.2645 - val_accuracy: 0.2500 - val_mse: 0.2645 - lr: 0.0010 - 293ms/epoch - 59ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5474 - mse: 0.2473 - val_loss: 0.2670 - val_accuracy: 0.2500 - val_mse: 0.2670 - lr: 0.0010 - 266ms/epoch - 53ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2506 - accuracy: 0.5328 - mse: 0.2506 - val_loss: 0.2713 - val_accuracy: 0.2500 - val_mse: 0.2713 - lr: 0.0010 - 267ms/epoch - 53ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5547 - mse: 0.2478 - val_loss: 0.2752 - val_accuracy: 0.2500 - val_mse: 0.2752 - lr: 0.0010 - 244ms/epoch - 49ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5474 - mse: 0.2493 - val_loss: 0.2789 - val_accuracy: 0.2500 - val_mse: 0.2789 - lr: 0.0010 - 242ms/epoch - 48ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5620 - mse: 0.2496 - val_loss: 0.2840 - val_accuracy: 0.2500 - val_mse: 0.2840 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5693 - mse: 0.2465 - val_loss: 0.2884 - val_accuracy: 0.2500 - val_mse: 0.2884 - lr: 0.0010 - 321ms/epoch - 64ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.6277 - mse: 0.2446 - val_loss: 0.3091 - val_accuracy: 0.2500 - val_mse: 0.3091 - lr: 0.0010 - 232ms/epoch - 46ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2443 - accuracy: 0.5620 - mse: 0.2443 - val_loss: 0.3367 - val_accuracy: 0.2500 - val_mse: 0.3367 - lr: 0.0010 - 223ms/epoch - 45ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5985 - mse: 0.2412 - val_loss: 0.3459 - val_accuracy: 0.2500 - val_mse: 0.3459 - lr: 0.0010 - 229ms/epoch - 46ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5985 - mse: 0.2438 - val_loss: 0.3387 - val_accuracy: 0.2500 - val_mse: 0.3387 - lr: 0.0010 - 229ms/epoch - 46ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2405 - accuracy: 0.5839 - mse: 0.2405 - val_loss: 0.3249 - val_accuracy: 0.2500 - val_mse: 0.3249 - lr: 0.0010 - 234ms/epoch - 47ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5766 - mse: 0.2455 - val_loss: 0.3363 - val_accuracy: 0.2500 - val_mse: 0.3363 - lr: 0.0010 - 242ms/epoch - 48ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5693 - mse: 0.2427 - val_loss: 0.2970 - val_accuracy: 0.2500 - val_mse: 0.2970 - lr: 0.0010 - 240ms/epoch - 48ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2451 - accuracy: 0.5474 - mse: 0.2451 - val_loss: 0.3036 - val_accuracy: 0.2500 - val_mse: 0.3036 - lr: 0.0010 - 232ms/epoch - 46ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2381 - accuracy: 0.6058 - mse: 0.2381 - val_loss: 0.3264 - val_accuracy: 0.2500 - val_mse: 0.3264 - lr: 0.0010 - 240ms/epoch - 48ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2419 - accuracy: 0.5985 - mse: 0.2419 - val_loss: 0.3390 - val_accuracy: 0.2500 - val_mse: 0.3390 - lr: 0.0010 - 249ms/epoch - 50ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5839 - mse: 0.2413 - val_loss: 0.3269 - val_accuracy: 0.2500 - val_mse: 0.3269 - lr: 0.0010 - 245ms/epoch - 49ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5401 - mse: 0.2448 - val_loss: 0.3269 - val_accuracy: 0.2500 - val_mse: 0.3269 - lr: 1.0000e-05 - 253ms/epoch - 51ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5693 - mse: 0.2454 - val_loss: 0.3269 - val_accuracy: 0.2500 - val_mse: 0.3269 - lr: 1.0000e-05 - 231ms/epoch - 46ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5839 - mse: 0.2423 - val_loss: 0.3270 - val_accuracy: 0.2500 - val_mse: 0.3270 - lr: 1.0000e-05 - 315ms/epoch - 63ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5912 - mse: 0.2416 - val_loss: 0.3272 - val_accuracy: 0.2500 - val_mse: 0.3272 - lr: 1.0000e-05 - 242ms/epoch - 48ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2404 - accuracy: 0.5912 - mse: 0.2404 - val_loss: 0.3275 - val_accuracy: 0.2500 - val_mse: 0.3275 - lr: 1.0000e-05 - 255ms/epoch - 51ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2337 - accuracy: 0.5985 - mse: 0.2337 - val_loss: 0.3279 - val_accuracy: 0.2500 - val_mse: 0.3279 - lr: 1.0000e-05 - 250ms/epoch - 50ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2398 - accuracy: 0.5620 - mse: 0.2398 - val_loss: 0.3283 - val_accuracy: 0.2500 - val_mse: 0.3283 - lr: 1.0000e-05 - 242ms/epoch - 48ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5401 - mse: 0.2492 - val_loss: 0.3286 - val_accuracy: 0.2500 - val_mse: 0.3286 - lr: 1.0000e-05 - 253ms/epoch - 51ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5547 - mse: 0.2452 - val_loss: 0.3286 - val_accuracy: 0.2500 - val_mse: 0.3286 - lr: 1.0000e-05 - 241ms/epoch - 48ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2376 - accuracy: 0.5912 - mse: 0.2376 - val_loss: 0.3286 - val_accuracy: 0.2500 - val_mse: 0.3286 - lr: 1.0000e-05 - 257ms/epoch - 51ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2383 - accuracy: 0.5766 - mse: 0.2383 - val_loss: 0.3286 - val_accuracy: 0.2500 - val_mse: 0.3286 - lr: 1.0000e-07 - 246ms/epoch - 49ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5839 - mse: 0.2444 - val_loss: 0.3286 - val_accuracy: 0.2500 - val_mse: 0.3286 - lr: 1.0000e-07 - 224ms/epoch - 45ms/step\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2810 - accuracy: 0.4444 - mse: 0.2810\n",
      "2/2 [==============================] - 2s 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_35_layer_call_fn, lstm_cell_35_layer_call_and_return_conditional_losses, lstm_cell_36_layer_call_fn, lstm_cell_36_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4444\n",
      "Loss: 0.28101423382759094\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_40 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,314\n",
      "Trainable params: 55,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 13s - loss: 0.4118 - accuracy: 0.4745 - mse: 0.4118 - val_loss: 0.2840 - val_accuracy: 0.5000 - val_mse: 0.2840 - lr: 0.0010 - 13s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2644 - accuracy: 0.5693 - mse: 0.2644 - val_loss: 0.2696 - val_accuracy: 0.5000 - val_mse: 0.2696 - lr: 0.0010 - 238ms/epoch - 48ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2561 - accuracy: 0.5693 - mse: 0.2561 - val_loss: 0.2853 - val_accuracy: 0.5000 - val_mse: 0.2853 - lr: 0.0010 - 268ms/epoch - 54ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2611 - accuracy: 0.5693 - mse: 0.2611 - val_loss: 0.2875 - val_accuracy: 0.5000 - val_mse: 0.2875 - lr: 0.0010 - 240ms/epoch - 48ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2589 - accuracy: 0.5693 - mse: 0.2589 - val_loss: 0.2733 - val_accuracy: 0.5000 - val_mse: 0.2733 - lr: 0.0010 - 242ms/epoch - 48ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2505 - accuracy: 0.5693 - mse: 0.2505 - val_loss: 0.2611 - val_accuracy: 0.5000 - val_mse: 0.2611 - lr: 0.0010 - 249ms/epoch - 50ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5693 - mse: 0.2468 - val_loss: 0.2597 - val_accuracy: 0.5000 - val_mse: 0.2597 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5693 - mse: 0.2467 - val_loss: 0.2636 - val_accuracy: 0.5000 - val_mse: 0.2636 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5693 - mse: 0.2474 - val_loss: 0.2667 - val_accuracy: 0.5000 - val_mse: 0.2667 - lr: 0.0010 - 238ms/epoch - 48ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5693 - mse: 0.2468 - val_loss: 0.2685 - val_accuracy: 0.5000 - val_mse: 0.2685 - lr: 0.0010 - 234ms/epoch - 47ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5693 - mse: 0.2462 - val_loss: 0.2707 - val_accuracy: 0.5000 - val_mse: 0.2707 - lr: 0.0010 - 238ms/epoch - 48ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5693 - mse: 0.2465 - val_loss: 0.2723 - val_accuracy: 0.5000 - val_mse: 0.2723 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5693 - mse: 0.2456 - val_loss: 0.2724 - val_accuracy: 0.5000 - val_mse: 0.2724 - lr: 1.0000e-05 - 238ms/epoch - 48ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5693 - mse: 0.2465 - val_loss: 0.2723 - val_accuracy: 0.5000 - val_mse: 0.2723 - lr: 1.0000e-05 - 237ms/epoch - 47ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2460 - accuracy: 0.5693 - mse: 0.2460 - val_loss: 0.2723 - val_accuracy: 0.5000 - val_mse: 0.2723 - lr: 1.0000e-05 - 233ms/epoch - 47ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5693 - mse: 0.2464 - val_loss: 0.2723 - val_accuracy: 0.5000 - val_mse: 0.2723 - lr: 1.0000e-05 - 232ms/epoch - 46ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5693 - mse: 0.2466 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-05 - 234ms/epoch - 47ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5693 - mse: 0.2458 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-05 - 236ms/epoch - 47ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5693 - mse: 0.2469 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-05 - 236ms/epoch - 47ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5693 - mse: 0.2453 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-05 - 236ms/epoch - 47ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5693 - mse: 0.2453 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-05 - 236ms/epoch - 47ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5693 - mse: 0.2463 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-05 - 237ms/epoch - 47ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5693 - mse: 0.2453 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 235ms/epoch - 47ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5693 - mse: 0.2454 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 240ms/epoch - 48ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5693 - mse: 0.2456 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 241ms/epoch - 48ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5693 - mse: 0.2461 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 239ms/epoch - 48ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5693 - mse: 0.2459 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 239ms/epoch - 48ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5693 - mse: 0.2454 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 311ms/epoch - 62ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2460 - accuracy: 0.5693 - mse: 0.2460 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5693 - mse: 0.2454 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 243ms/epoch - 49ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5693 - mse: 0.2464 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 240ms/epoch - 48ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.5693 - mse: 0.2447 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-07 - 241ms/epoch - 48ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5693 - mse: 0.2455 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 245ms/epoch - 49ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5693 - mse: 0.2444 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 250ms/epoch - 50ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5693 - mse: 0.2466 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 235ms/epoch - 47ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5693 - mse: 0.2438 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 240ms/epoch - 48ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5693 - mse: 0.2466 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 246ms/epoch - 49ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5693 - mse: 0.2462 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 244ms/epoch - 49ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5693 - mse: 0.2454 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 241ms/epoch - 48ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2449 - accuracy: 0.5693 - mse: 0.2449 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 243ms/epoch - 49ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5693 - mse: 0.2455 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 234ms/epoch - 47ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5693 - mse: 0.2456 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-09 - 245ms/epoch - 49ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.5693 - mse: 0.2447 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-11 - 241ms/epoch - 48ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5693 - mse: 0.2455 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-11 - 247ms/epoch - 49ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5693 - mse: 0.2464 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-11 - 245ms/epoch - 49ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2445 - accuracy: 0.5693 - mse: 0.2445 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-11 - 247ms/epoch - 49ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2443 - accuracy: 0.5693 - mse: 0.2443 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-11 - 240ms/epoch - 48ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5693 - mse: 0.2463 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-11 - 242ms/epoch - 48ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5693 - mse: 0.2470 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-11 - 238ms/epoch - 48ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5693 - mse: 0.2463 - val_loss: 0.2722 - val_accuracy: 0.5000 - val_mse: 0.2722 - lr: 1.0000e-11 - 235ms/epoch - 47ms/step\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2466 - accuracy: 0.5833 - mse: 0.2466\n",
      "2/2 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_39_layer_call_fn, lstm_cell_39_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833\n",
      "Loss: 0.24660488963127136\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_42 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_44 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,314\n",
      "Trainable params: 55,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 15s - loss: 0.4178 - accuracy: 0.4599 - mse: 0.4178 - val_loss: 0.2777 - val_accuracy: 0.5625 - val_mse: 0.2777 - lr: 0.0010 - 15s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2646 - accuracy: 0.5693 - mse: 0.2646 - val_loss: 0.2558 - val_accuracy: 0.5625 - val_mse: 0.2558 - lr: 0.0010 - 249ms/epoch - 50ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2541 - accuracy: 0.5693 - mse: 0.2541 - val_loss: 0.2599 - val_accuracy: 0.5625 - val_mse: 0.2599 - lr: 0.0010 - 258ms/epoch - 52ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2530 - accuracy: 0.5693 - mse: 0.2530 - val_loss: 0.2501 - val_accuracy: 0.5625 - val_mse: 0.2501 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5693 - mse: 0.2467 - val_loss: 0.2465 - val_accuracy: 0.5625 - val_mse: 0.2465 - lr: 0.0010 - 254ms/epoch - 51ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2457 - accuracy: 0.5693 - mse: 0.2457 - val_loss: 0.2486 - val_accuracy: 0.5625 - val_mse: 0.2486 - lr: 0.0010 - 241ms/epoch - 48ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5693 - mse: 0.2459 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 260ms/epoch - 52ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5693 - mse: 0.2432 - val_loss: 0.2473 - val_accuracy: 0.5625 - val_mse: 0.2473 - lr: 0.0010 - 325ms/epoch - 65ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5693 - mse: 0.2432 - val_loss: 0.2483 - val_accuracy: 0.5625 - val_mse: 0.2483 - lr: 0.0010 - 332ms/epoch - 66ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2424 - accuracy: 0.5693 - mse: 0.2424 - val_loss: 0.2473 - val_accuracy: 0.5625 - val_mse: 0.2473 - lr: 0.0010 - 309ms/epoch - 62ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5693 - mse: 0.2430 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 0.0010 - 307ms/epoch - 61ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5620 - mse: 0.2421 - val_loss: 0.2477 - val_accuracy: 0.5625 - val_mse: 0.2477 - lr: 0.0010 - 288ms/epoch - 58ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.5839 - mse: 0.2406 - val_loss: 0.2477 - val_accuracy: 0.5625 - val_mse: 0.2477 - lr: 1.0000e-05 - 288ms/epoch - 58ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2419 - accuracy: 0.5839 - mse: 0.2419 - val_loss: 0.2477 - val_accuracy: 0.5625 - val_mse: 0.2477 - lr: 1.0000e-05 - 316ms/epoch - 63ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5620 - mse: 0.2415 - val_loss: 0.2477 - val_accuracy: 0.5625 - val_mse: 0.2477 - lr: 1.0000e-05 - 301ms/epoch - 60ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2405 - accuracy: 0.5766 - mse: 0.2405 - val_loss: 0.2477 - val_accuracy: 0.5625 - val_mse: 0.2477 - lr: 1.0000e-05 - 249ms/epoch - 50ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5985 - mse: 0.2416 - val_loss: 0.2477 - val_accuracy: 0.5625 - val_mse: 0.2477 - lr: 1.0000e-05 - 270ms/epoch - 54ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2435 - accuracy: 0.5766 - mse: 0.2435 - val_loss: 0.2477 - val_accuracy: 0.5625 - val_mse: 0.2477 - lr: 1.0000e-05 - 256ms/epoch - 51ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2439 - accuracy: 0.5547 - mse: 0.2439 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 304ms/epoch - 61ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2407 - accuracy: 0.5912 - mse: 0.2407 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 260ms/epoch - 52ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2405 - accuracy: 0.5839 - mse: 0.2405 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 255ms/epoch - 51ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2403 - accuracy: 0.5766 - mse: 0.2403 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 257ms/epoch - 51ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2417 - accuracy: 0.5620 - mse: 0.2417 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 253ms/epoch - 51ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5474 - mse: 0.2421 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 246ms/epoch - 49ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2441 - accuracy: 0.5620 - mse: 0.2441 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 250ms/epoch - 50ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2429 - accuracy: 0.5620 - mse: 0.2429 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 267ms/epoch - 53ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5547 - mse: 0.2414 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 426ms/epoch - 85ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.5985 - mse: 0.2401 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 424ms/epoch - 85ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.6058 - mse: 0.2416 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 270ms/epoch - 54ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2417 - accuracy: 0.5839 - mse: 0.2417 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 271ms/epoch - 54ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5547 - mse: 0.2418 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 248ms/epoch - 50ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5182 - mse: 0.2423 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 247ms/epoch - 49ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5766 - mse: 0.2413 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 248ms/epoch - 50ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2429 - accuracy: 0.5547 - mse: 0.2429 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 243ms/epoch - 49ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5620 - mse: 0.2413 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2437 - accuracy: 0.5693 - mse: 0.2437 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2437 - accuracy: 0.5620 - mse: 0.2437 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 248ms/epoch - 50ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2417 - accuracy: 0.5620 - mse: 0.2417 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 236ms/epoch - 47ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5328 - mse: 0.2427 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-07 - 263ms/epoch - 53ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.5766 - mse: 0.2411 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 252ms/epoch - 50ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5766 - mse: 0.2420 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 255ms/epoch - 51ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2435 - accuracy: 0.5547 - mse: 0.2435 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 252ms/epoch - 50ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5839 - mse: 0.2413 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 253ms/epoch - 51ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.5620 - mse: 0.2411 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 260ms/epoch - 52ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5766 - mse: 0.2416 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 255ms/epoch - 51ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2441 - accuracy: 0.5620 - mse: 0.2441 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 264ms/epoch - 53ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5912 - mse: 0.2418 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 264ms/epoch - 53ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5547 - mse: 0.2423 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 273ms/epoch - 55ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5693 - mse: 0.2432 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-09 - 248ms/epoch - 50ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.5547 - mse: 0.2406 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-11 - 260ms/epoch - 52ms/step\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2492 - accuracy: 0.5556 - mse: 0.2492\n",
      "2/2 [==============================] - 2s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_43_layer_call_fn, lstm_cell_43_layer_call_and_return_conditional_losses, lstm_cell_44_layer_call_fn, lstm_cell_44_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5556\n",
      "Loss: 0.24916154146194458\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_46 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_47 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_48 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_49 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,314\n",
      "Trainable params: 55,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 16s - loss: 0.4115 - accuracy: 0.4926 - mse: 0.4115 - val_loss: 0.2713 - val_accuracy: 0.5625 - val_mse: 0.2713 - lr: 0.0010 - 16s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2672 - accuracy: 0.5588 - mse: 0.2672 - val_loss: 0.2607 - val_accuracy: 0.5625 - val_mse: 0.2607 - lr: 0.0010 - 241ms/epoch - 48ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2625 - accuracy: 0.5000 - mse: 0.2625 - val_loss: 0.2567 - val_accuracy: 0.5625 - val_mse: 0.2567 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2599 - accuracy: 0.5000 - mse: 0.2599 - val_loss: 0.2464 - val_accuracy: 0.5625 - val_mse: 0.2464 - lr: 0.0010 - 250ms/epoch - 50ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2533 - accuracy: 0.4926 - mse: 0.2533 - val_loss: 0.2511 - val_accuracy: 0.4375 - val_mse: 0.2511 - lr: 0.0010 - 246ms/epoch - 49ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2526 - accuracy: 0.4706 - mse: 0.2526 - val_loss: 0.2515 - val_accuracy: 0.4375 - val_mse: 0.2515 - lr: 0.0010 - 263ms/epoch - 53ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2504 - accuracy: 0.5147 - mse: 0.2504 - val_loss: 0.2472 - val_accuracy: 0.5625 - val_mse: 0.2472 - lr: 0.0010 - 248ms/epoch - 50ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2516 - accuracy: 0.5000 - mse: 0.2516 - val_loss: 0.2473 - val_accuracy: 0.5625 - val_mse: 0.2473 - lr: 0.0010 - 253ms/epoch - 51ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2506 - accuracy: 0.5000 - mse: 0.2506 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 0.0010 - 252ms/epoch - 50ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2513 - accuracy: 0.5000 - mse: 0.2513 - val_loss: 0.2470 - val_accuracy: 0.5625 - val_mse: 0.2470 - lr: 0.0010 - 269ms/epoch - 54ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.4779 - mse: 0.2496 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 0.0010 - 261ms/epoch - 52ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2499 - accuracy: 0.4853 - mse: 0.2499 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 0.0010 - 261ms/epoch - 52ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2499 - accuracy: 0.5515 - mse: 0.2499 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 254ms/epoch - 51ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2499 - accuracy: 0.5294 - mse: 0.2499 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 263ms/epoch - 53ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5294 - mse: 0.2491 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 1.0000e-05 - 250ms/epoch - 50ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5441 - mse: 0.2488 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 1.0000e-05 - 248ms/epoch - 50ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2506 - accuracy: 0.4926 - mse: 0.2506 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 1.0000e-05 - 251ms/epoch - 50ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5588 - mse: 0.2487 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 1.0000e-05 - 300ms/epoch - 60ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2512 - accuracy: 0.5221 - mse: 0.2512 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 1.0000e-05 - 258ms/epoch - 52ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2508 - accuracy: 0.5147 - mse: 0.2508 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 1.0000e-05 - 247ms/epoch - 49ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5515 - mse: 0.2488 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 1.0000e-05 - 241ms/epoch - 48ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5368 - mse: 0.2493 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-05 - 247ms/epoch - 49ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5368 - mse: 0.2488 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 246ms/epoch - 49ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5368 - mse: 0.2492 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 247ms/epoch - 49ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2502 - accuracy: 0.5074 - mse: 0.2502 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 250ms/epoch - 50ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2503 - accuracy: 0.5515 - mse: 0.2503 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 251ms/epoch - 50ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5515 - mse: 0.2491 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 252ms/epoch - 50ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5294 - mse: 0.2496 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 252ms/epoch - 50ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.5294 - mse: 0.2500 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5221 - mse: 0.2490 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5588 - mse: 0.2482 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 244ms/epoch - 49ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.5147 - mse: 0.2500 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-07 - 252ms/epoch - 50ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2504 - accuracy: 0.5221 - mse: 0.2504 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 234ms/epoch - 47ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2501 - accuracy: 0.4926 - mse: 0.2501 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 265ms/epoch - 53ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2495 - accuracy: 0.5221 - mse: 0.2495 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 256ms/epoch - 51ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2505 - accuracy: 0.5221 - mse: 0.2505 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 271ms/epoch - 54ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5441 - mse: 0.2487 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 253ms/epoch - 51ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2495 - accuracy: 0.5294 - mse: 0.2495 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 302ms/epoch - 60ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5221 - mse: 0.2496 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 253ms/epoch - 51ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2501 - accuracy: 0.5147 - mse: 0.2501 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 266ms/epoch - 53ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5588 - mse: 0.2491 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 248ms/epoch - 50ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2495 - accuracy: 0.5074 - mse: 0.2495 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-09 - 261ms/epoch - 52ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2495 - accuracy: 0.5147 - mse: 0.2495 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-11 - 275ms/epoch - 55ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5294 - mse: 0.2482 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-11 - 259ms/epoch - 52ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5074 - mse: 0.2496 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-11 - 255ms/epoch - 51ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5000 - mse: 0.2490 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-11 - 255ms/epoch - 51ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5662 - mse: 0.2481 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-11 - 255ms/epoch - 51ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5809 - mse: 0.2486 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-11 - 261ms/epoch - 52ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5515 - mse: 0.2491 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-11 - 251ms/epoch - 50ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2518 - accuracy: 0.5000 - mse: 0.2518 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-11 - 353ms/epoch - 71ms/step\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2464 - accuracy: 0.5833 - mse: 0.2464\n",
      "2/2 [==============================] - 2s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_47_layer_call_fn, lstm_cell_47_layer_call_and_return_conditional_losses, lstm_cell_48_layer_call_fn, lstm_cell_48_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833\n",
      "Loss: 0.24642859399318695\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_50 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_51 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_52 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_53 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,314\n",
      "Trainable params: 55,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 19s - loss: 0.4195 - accuracy: 0.5036 - mse: 0.4195 - val_loss: 0.2601 - val_accuracy: 0.6875 - val_mse: 0.2601 - lr: 0.0010 - 19s/epoch - 4s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2650 - accuracy: 0.5912 - mse: 0.2650 - val_loss: 0.2376 - val_accuracy: 0.6875 - val_mse: 0.2376 - lr: 0.0010 - 260ms/epoch - 52ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2536 - accuracy: 0.5912 - mse: 0.2536 - val_loss: 0.2290 - val_accuracy: 0.6875 - val_mse: 0.2290 - lr: 0.0010 - 260ms/epoch - 52ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2521 - accuracy: 0.5912 - mse: 0.2521 - val_loss: 0.2165 - val_accuracy: 0.6875 - val_mse: 0.2165 - lr: 0.0010 - 267ms/epoch - 53ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5912 - mse: 0.2438 - val_loss: 0.2316 - val_accuracy: 0.6875 - val_mse: 0.2316 - lr: 0.0010 - 365ms/epoch - 73ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5912 - mse: 0.2420 - val_loss: 0.2332 - val_accuracy: 0.6875 - val_mse: 0.2332 - lr: 0.0010 - 254ms/epoch - 51ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5912 - mse: 0.2425 - val_loss: 0.2221 - val_accuracy: 0.6875 - val_mse: 0.2221 - lr: 0.0010 - 259ms/epoch - 52ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2428 - accuracy: 0.5912 - mse: 0.2428 - val_loss: 0.2224 - val_accuracy: 0.6875 - val_mse: 0.2224 - lr: 0.0010 - 261ms/epoch - 52ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5912 - mse: 0.2423 - val_loss: 0.2245 - val_accuracy: 0.6875 - val_mse: 0.2245 - lr: 0.0010 - 258ms/epoch - 52ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2417 - accuracy: 0.5912 - mse: 0.2417 - val_loss: 0.2233 - val_accuracy: 0.6875 - val_mse: 0.2233 - lr: 0.0010 - 262ms/epoch - 52ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5912 - mse: 0.2421 - val_loss: 0.2237 - val_accuracy: 0.6875 - val_mse: 0.2237 - lr: 0.0010 - 268ms/epoch - 54ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5912 - mse: 0.2425 - val_loss: 0.2253 - val_accuracy: 0.6875 - val_mse: 0.2253 - lr: 0.0010 - 252ms/epoch - 50ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2410 - accuracy: 0.5912 - mse: 0.2410 - val_loss: 0.2253 - val_accuracy: 0.6875 - val_mse: 0.2253 - lr: 1.0000e-05 - 253ms/epoch - 51ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2252 - val_accuracy: 0.6875 - val_mse: 0.2252 - lr: 1.0000e-05 - 258ms/epoch - 52ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5912 - mse: 0.2418 - val_loss: 0.2252 - val_accuracy: 0.6875 - val_mse: 0.2252 - lr: 1.0000e-05 - 259ms/epoch - 52ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5912 - mse: 0.2414 - val_loss: 0.2251 - val_accuracy: 0.6875 - val_mse: 0.2251 - lr: 1.0000e-05 - 249ms/epoch - 50ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5912 - mse: 0.2418 - val_loss: 0.2250 - val_accuracy: 0.6875 - val_mse: 0.2250 - lr: 1.0000e-05 - 262ms/epoch - 52ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2249 - val_accuracy: 0.6875 - val_mse: 0.2249 - lr: 1.0000e-05 - 258ms/epoch - 52ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2404 - accuracy: 0.5912 - mse: 0.2404 - val_loss: 0.2249 - val_accuracy: 0.6875 - val_mse: 0.2249 - lr: 1.0000e-05 - 252ms/epoch - 50ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2248 - val_accuracy: 0.6875 - val_mse: 0.2248 - lr: 1.0000e-05 - 256ms/epoch - 51ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2247 - val_accuracy: 0.6875 - val_mse: 0.2247 - lr: 1.0000e-05 - 256ms/epoch - 51ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5912 - mse: 0.2416 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-05 - 277ms/epoch - 55ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.5912 - mse: 0.2411 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 253ms/epoch - 51ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5912 - mse: 0.2414 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 267ms/epoch - 53ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5912 - mse: 0.2412 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 251ms/epoch - 50ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 274ms/epoch - 55ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2410 - accuracy: 0.5912 - mse: 0.2410 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 252ms/epoch - 50ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2405 - accuracy: 0.5912 - mse: 0.2405 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 261ms/epoch - 52ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2422 - accuracy: 0.5912 - mse: 0.2422 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 255ms/epoch - 51ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5912 - mse: 0.2420 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 253ms/epoch - 51ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.5912 - mse: 0.2409 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 253ms/epoch - 51ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2410 - accuracy: 0.5912 - mse: 0.2410 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-07 - 258ms/epoch - 52ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5912 - mse: 0.2416 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 266ms/epoch - 53ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5912 - mse: 0.2416 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 253ms/epoch - 51ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2404 - accuracy: 0.5912 - mse: 0.2404 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 247ms/epoch - 49ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5912 - mse: 0.2420 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 251ms/epoch - 50ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2399 - accuracy: 0.5912 - mse: 0.2399 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 262ms/epoch - 52ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.5912 - mse: 0.2409 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 254ms/epoch - 51ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 264ms/epoch - 53ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5912 - mse: 0.2414 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 314ms/epoch - 63ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5912 - mse: 0.2416 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 255ms/epoch - 51ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.5912 - mse: 0.2409 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-09 - 257ms/epoch - 51ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-11 - 253ms/epoch - 51ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.5912 - mse: 0.2411 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-11 - 257ms/epoch - 51ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-11 - 258ms/epoch - 52ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2410 - accuracy: 0.5912 - mse: 0.2410 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-11 - 258ms/epoch - 52ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-11 - 286ms/epoch - 57ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.5912 - mse: 0.2406 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-11 - 260ms/epoch - 52ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2407 - accuracy: 0.5912 - mse: 0.2407 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-11 - 253ms/epoch - 51ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5912 - mse: 0.2421 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-11 - 254ms/epoch - 51ms/step\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2630 - accuracy: 0.4722 - mse: 0.2630\n",
      "2/2 [==============================] - 2s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_51_layer_call_fn, lstm_cell_51_layer_call_and_return_conditional_losses, lstm_cell_52_layer_call_fn, lstm_cell_52_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4722\n",
      "Loss: 0.26303279399871826\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_54 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_55 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_56 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_57 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,314\n",
      "Trainable params: 55,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 15s - loss: 0.4168 - accuracy: 0.4818 - mse: 0.4168 - val_loss: 0.2714 - val_accuracy: 0.6250 - val_mse: 0.2714 - lr: 0.0010 - 15s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2729 - accuracy: 0.5620 - mse: 0.2729 - val_loss: 0.2400 - val_accuracy: 0.6250 - val_mse: 0.2400 - lr: 0.0010 - 275ms/epoch - 55ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2545 - accuracy: 0.5620 - mse: 0.2545 - val_loss: 0.2464 - val_accuracy: 0.6250 - val_mse: 0.2464 - lr: 0.0010 - 290ms/epoch - 58ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2622 - accuracy: 0.5620 - mse: 0.2622 - val_loss: 0.2393 - val_accuracy: 0.6250 - val_mse: 0.2393 - lr: 0.0010 - 291ms/epoch - 58ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2601 - accuracy: 0.5620 - mse: 0.2601 - val_loss: 0.2350 - val_accuracy: 0.6250 - val_mse: 0.2350 - lr: 0.0010 - 279ms/epoch - 56ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2511 - accuracy: 0.5620 - mse: 0.2511 - val_loss: 0.2357 - val_accuracy: 0.6250 - val_mse: 0.2357 - lr: 0.0010 - 259ms/epoch - 52ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5620 - mse: 0.2466 - val_loss: 0.2367 - val_accuracy: 0.6250 - val_mse: 0.2367 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5620 - mse: 0.2486 - val_loss: 0.2353 - val_accuracy: 0.6250 - val_mse: 0.2353 - lr: 0.0010 - 229ms/epoch - 46ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 1s - loss: 0.2493 - accuracy: 0.5620 - mse: 0.2493 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 0.0010 - 630ms/epoch - 126ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2499 - accuracy: 0.5620 - mse: 0.2499 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 0.0010 - 274ms/epoch - 55ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2501 - accuracy: 0.5620 - mse: 0.2501 - val_loss: 0.2347 - val_accuracy: 0.6250 - val_mse: 0.2347 - lr: 0.0010 - 383ms/epoch - 77ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2494 - accuracy: 0.5620 - mse: 0.2494 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 0.0010 - 274ms/epoch - 55ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5620 - mse: 0.2492 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 1.0000e-05 - 308ms/epoch - 62ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5620 - mse: 0.2478 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 1.0000e-05 - 258ms/epoch - 52ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5620 - mse: 0.2483 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 1.0000e-05 - 276ms/epoch - 55ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5620 - mse: 0.2489 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 1.0000e-05 - 257ms/epoch - 51ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5620 - mse: 0.2480 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 1.0000e-05 - 259ms/epoch - 52ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5620 - mse: 0.2482 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 1.0000e-05 - 285ms/epoch - 57ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5620 - mse: 0.2486 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 259ms/epoch - 52ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5620 - mse: 0.2487 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 261ms/epoch - 52ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5620 - mse: 0.2487 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 262ms/epoch - 52ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5620 - mse: 0.2485 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 322ms/epoch - 64ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5620 - mse: 0.2484 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 310ms/epoch - 62ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5620 - mse: 0.2490 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 257ms/epoch - 51ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 267ms/epoch - 53ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5620 - mse: 0.2480 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 260ms/epoch - 52ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5620 - mse: 0.2491 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 257ms/epoch - 51ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5620 - mse: 0.2492 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 261ms/epoch - 52ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5620 - mse: 0.2493 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 258ms/epoch - 52ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5620 - mse: 0.2487 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 255ms/epoch - 51ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5620 - mse: 0.2490 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 260ms/epoch - 52ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5620 - mse: 0.2485 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 256ms/epoch - 51ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5620 - mse: 0.2496 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 252ms/epoch - 50ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5620 - mse: 0.2486 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 256ms/epoch - 51ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5620 - mse: 0.2479 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5620 - mse: 0.2491 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 260ms/epoch - 52ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 253ms/epoch - 51ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5620 - mse: 0.2489 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 257ms/epoch - 51ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 257ms/epoch - 51ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5620 - mse: 0.2491 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5620 - mse: 0.2482 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 256ms/epoch - 51ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5620 - mse: 0.2487 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5620 - mse: 0.2498 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 255ms/epoch - 51ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5620 - mse: 0.2485 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 255ms/epoch - 51ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5620 - mse: 0.2490 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 254ms/epoch - 51ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5620 - mse: 0.2485 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 263ms/epoch - 53ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5620 - mse: 0.2491 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 253ms/epoch - 51ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 259ms/epoch - 52ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5620 - mse: 0.2484 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 256ms/epoch - 51ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5620 - mse: 0.2476 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 261ms/epoch - 52ms/step\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2184 - accuracy: 0.6944 - mse: 0.2184\n",
      "2/2 [==============================] - 2s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_55_layer_call_fn, lstm_cell_55_layer_call_and_return_conditional_losses, lstm_cell_56_layer_call_fn, lstm_cell_56_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6944\n",
      "Loss: 0.2184489369392395\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_58 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_59 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_60 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_61 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,314\n",
      "Trainable params: 55,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 19s - loss: 0.4091 - accuracy: 0.4891 - mse: 0.4091 - val_loss: 0.2706 - val_accuracy: 0.5625 - val_mse: 0.2706 - lr: 0.0010 - 19s/epoch - 4s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2657 - accuracy: 0.5474 - mse: 0.2657 - val_loss: 0.2612 - val_accuracy: 0.5625 - val_mse: 0.2612 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2599 - accuracy: 0.5547 - mse: 0.2599 - val_loss: 0.2569 - val_accuracy: 0.5625 - val_mse: 0.2569 - lr: 0.0010 - 315ms/epoch - 63ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2537 - accuracy: 0.5547 - mse: 0.2537 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 0.0010 - 242ms/epoch - 48ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5620 - mse: 0.2479 - val_loss: 0.2503 - val_accuracy: 0.5625 - val_mse: 0.2503 - lr: 0.0010 - 325ms/epoch - 65ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5547 - mse: 0.2481 - val_loss: 0.2466 - val_accuracy: 0.5625 - val_mse: 0.2466 - lr: 0.0010 - 258ms/epoch - 52ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5547 - mse: 0.2480 - val_loss: 0.2470 - val_accuracy: 0.5625 - val_mse: 0.2470 - lr: 0.0010 - 256ms/epoch - 51ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5547 - mse: 0.2479 - val_loss: 0.2466 - val_accuracy: 0.5625 - val_mse: 0.2466 - lr: 0.0010 - 270ms/epoch - 54ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2464 - val_accuracy: 0.5625 - val_mse: 0.2464 - lr: 0.0010 - 240ms/epoch - 48ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5547 - mse: 0.2464 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 0.0010 - 245ms/epoch - 49ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5547 - mse: 0.2463 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 0.0010 - 255ms/epoch - 51ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5547 - mse: 0.2476 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 0.0010 - 249ms/epoch - 50ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5547 - mse: 0.2477 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 0.0010 - 272ms/epoch - 54ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 0.0010 - 254ms/epoch - 51ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5547 - mse: 0.2464 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 255ms/epoch - 51ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 281ms/epoch - 56ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5547 - mse: 0.2440 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 260ms/epoch - 52ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5547 - mse: 0.2458 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 260ms/epoch - 52ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5547 - mse: 0.2480 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 259ms/epoch - 52ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5547 - mse: 0.2462 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 266ms/epoch - 53ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5547 - mse: 0.2482 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 256ms/epoch - 51ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5547 - mse: 0.2479 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 254ms/epoch - 51ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 389ms/epoch - 78ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5547 - mse: 0.2459 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-05 - 267ms/epoch - 53ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 254ms/epoch - 51ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 265ms/epoch - 53ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5547 - mse: 0.2482 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 260ms/epoch - 52ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 259ms/epoch - 52ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2451 - accuracy: 0.5547 - mse: 0.2451 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 252ms/epoch - 50ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 257ms/epoch - 51ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 259ms/epoch - 52ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5547 - mse: 0.2461 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5547 - mse: 0.2438 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 258ms/epoch - 52ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-07 - 255ms/epoch - 51ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5547 - mse: 0.2459 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 256ms/epoch - 51ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5547 - mse: 0.2459 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 264ms/epoch - 53ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5547 - mse: 0.2464 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 254ms/epoch - 51ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2460 - accuracy: 0.5547 - mse: 0.2460 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 266ms/epoch - 53ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 261ms/epoch - 52ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 253ms/epoch - 51ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5547 - mse: 0.2477 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5547 - mse: 0.2486 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-11 - 334ms/epoch - 67ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5547 - mse: 0.2462 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-11 - 266ms/epoch - 53ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5547 - mse: 0.2444 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-11 - 261ms/epoch - 52ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-11 - 254ms/epoch - 51ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5547 - mse: 0.2459 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 1.0000e-11 - 261ms/epoch - 52ms/step\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2542 - accuracy: 0.5000 - mse: 0.2542\n",
      "2/2 [==============================] - 2s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_59_layer_call_fn, lstm_cell_59_layer_call_and_return_conditional_losses, lstm_cell_60_layer_call_fn, lstm_cell_60_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Loss: 0.2541767656803131\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_62 (LSTM)              (None, 19, 32)            13824     \n",
      "                                                                 \n",
      " lstm_63 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_64 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_65 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,314\n",
      "Trainable params: 55,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 18s - loss: 0.4185 - accuracy: 0.4380 - mse: 0.4185 - val_loss: 0.2717 - val_accuracy: 0.6250 - val_mse: 0.2717 - lr: 0.0010 - 18s/epoch - 4s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2668 - accuracy: 0.5547 - mse: 0.2668 - val_loss: 0.2503 - val_accuracy: 0.6250 - val_mse: 0.2503 - lr: 0.0010 - 251ms/epoch - 50ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2617 - accuracy: 0.5547 - mse: 0.2617 - val_loss: 0.2509 - val_accuracy: 0.6250 - val_mse: 0.2509 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2549 - accuracy: 0.5547 - mse: 0.2549 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 0.0010 - 299ms/epoch - 60ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2506 - accuracy: 0.5547 - mse: 0.2506 - val_loss: 0.2408 - val_accuracy: 0.6250 - val_mse: 0.2408 - lr: 0.0010 - 266ms/epoch - 53ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2514 - accuracy: 0.5474 - mse: 0.2514 - val_loss: 0.2486 - val_accuracy: 0.6250 - val_mse: 0.2486 - lr: 0.0010 - 246ms/epoch - 49ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5474 - mse: 0.2491 - val_loss: 0.2405 - val_accuracy: 0.6250 - val_mse: 0.2405 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2368 - val_accuracy: 0.6250 - val_mse: 0.2368 - lr: 0.0010 - 275ms/epoch - 55ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2384 - val_accuracy: 0.6250 - val_mse: 0.2384 - lr: 0.0010 - 268ms/epoch - 54ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5547 - mse: 0.2484 - val_loss: 0.2400 - val_accuracy: 0.6250 - val_mse: 0.2400 - lr: 0.0010 - 259ms/epoch - 52ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5547 - mse: 0.2477 - val_loss: 0.2392 - val_accuracy: 0.6250 - val_mse: 0.2392 - lr: 0.0010 - 324ms/epoch - 65ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5547 - mse: 0.2481 - val_loss: 0.2388 - val_accuracy: 0.6250 - val_mse: 0.2388 - lr: 0.0010 - 266ms/epoch - 53ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5547 - mse: 0.2462 - val_loss: 0.2388 - val_accuracy: 0.6250 - val_mse: 0.2388 - lr: 1.0000e-05 - 273ms/epoch - 55ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2388 - val_accuracy: 0.6250 - val_mse: 0.2388 - lr: 1.0000e-05 - 252ms/epoch - 50ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2388 - val_accuracy: 0.6250 - val_mse: 0.2388 - lr: 1.0000e-05 - 271ms/epoch - 54ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5547 - mse: 0.2463 - val_loss: 0.2389 - val_accuracy: 0.6250 - val_mse: 0.2389 - lr: 1.0000e-05 - 314ms/epoch - 63ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5547 - mse: 0.2467 - val_loss: 0.2389 - val_accuracy: 0.6250 - val_mse: 0.2389 - lr: 1.0000e-05 - 312ms/epoch - 62ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2389 - val_accuracy: 0.6250 - val_mse: 0.2389 - lr: 1.0000e-05 - 252ms/epoch - 50ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5547 - mse: 0.2464 - val_loss: 0.2390 - val_accuracy: 0.6250 - val_mse: 0.2390 - lr: 1.0000e-05 - 262ms/epoch - 52ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2390 - val_accuracy: 0.6250 - val_mse: 0.2390 - lr: 1.0000e-05 - 251ms/epoch - 50ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2390 - val_accuracy: 0.6250 - val_mse: 0.2390 - lr: 1.0000e-05 - 252ms/epoch - 50ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5547 - mse: 0.2465 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-05 - 259ms/epoch - 52ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5547 - mse: 0.2465 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 256ms/epoch - 51ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5547 - mse: 0.2466 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 255ms/epoch - 51ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 268ms/epoch - 54ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5547 - mse: 0.2462 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 257ms/epoch - 51ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 260ms/epoch - 52ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 259ms/epoch - 52ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 260ms/epoch - 52ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 253ms/epoch - 51ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 253ms/epoch - 51ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5547 - mse: 0.2462 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-07 - 251ms/epoch - 50ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5547 - mse: 0.2458 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5547 - mse: 0.2466 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 265ms/epoch - 53ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5547 - mse: 0.2467 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 265ms/epoch - 53ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5547 - mse: 0.2467 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 260ms/epoch - 52ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5547 - mse: 0.2464 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 255ms/epoch - 51ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 254ms/epoch - 51ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5547 - mse: 0.2477 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 274ms/epoch - 55ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5547 - mse: 0.2476 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5547 - mse: 0.2463 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 258ms/epoch - 52ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5547 - mse: 0.2477 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-09 - 264ms/epoch - 53ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-11 - 275ms/epoch - 55ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-11 - 256ms/epoch - 51ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-11 - 265ms/epoch - 53ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5547 - mse: 0.2463 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-11 - 265ms/epoch - 53ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5547 - mse: 0.2477 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-11 - 281ms/epoch - 56ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-11 - 279ms/epoch - 56ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-11 - 351ms/epoch - 70ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 1.0000e-11 - 276ms/epoch - 55ms/step\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2378 - accuracy: 0.6389 - mse: 0.2378\n",
      "2/2 [==============================] - 2s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_63_layer_call_fn, lstm_cell_63_layer_call_and_return_conditional_losses, lstm_cell_64_layer_call_fn, lstm_cell_64_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6389\n",
      "Loss: 0.2378232181072235\n"
     ]
    }
   ],
   "source": [
    "def train_model_2_3( xTrain, yTrain, xValid , yValid):\n",
    "    random.seed(26)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM( 32 ,input_shape = (19,75), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.3, return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.2, return_sequences=True))\n",
    "    model.add(LSTM(16))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "    model.build()   \n",
    "    model.summary()\n",
    "    model.compile( optimizer = \"adam\" , loss = 'mean_squared_error' , metrics = ['accuracy', 'mse'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau( monitor = 'accuracy', factor = 0.01, patience=10, cooldown=0)\n",
    "    \n",
    "    callbacks = [ reduce_lr ]\n",
    "    train_history = model.fit( xTrain, yTrain , epochs = 50, shuffle=False, callbacks=callbacks, verbose = 2, validation_split = 0.1)\n",
    "\n",
    "    score = model.evaluate( xValid , yValid )\n",
    "    pred = model.predict(xValid)\n",
    "    model.save(\"LSTM_1\")\n",
    "    \n",
    "    print( \"Accuracy: {:0.4}\".format( score[1] ))\n",
    "    print( \"Loss:\", score[0] )\n",
    "    return score, pred, train_history\n",
    "\n",
    "results_2012, pred_2012, history_2012 = train_model_2_3(x_train_2012, y_train_2012_OHE, x_valid_2012, y_valid_2012_OHE) \n",
    "results_2013, pred_2013, history_2013 = train_model_2_3(x_train_2013, y_train_2013_OHE, x_valid_2013, y_valid_2013_OHE) \n",
    "results_2014, pred_2014, history_2014 = train_model_2_3(x_train_2014, y_train_2014_OHE, x_valid_2014, y_valid_2014_OHE) \n",
    "results_2015, pred_2015, history_2015 = train_model_2_3(x_train_2015, y_train_2015_OHE, x_valid_2015, y_valid_2015_OHE) \n",
    "results_2016, pred_2016, history_2016 = train_model_2_3(x_train_2016, y_train_2016_OHE, x_valid_2016, y_valid_2016_OHE) \n",
    "results_2017, pred_2017, history_2017 = train_model_2_3(x_train_2017, y_train_2017_OHE, x_valid_2017, y_valid_2017_OHE) \n",
    "results_2018, pred_2018, history_2018 = train_model_2_3(x_train_2018, y_train_2018_OHE, x_valid_2018, y_valid_2018_OHE) \n",
    "results_2019, pred_2019, history_2019 = train_model_2_3(x_train_2019, y_train_2019_OHE, x_valid_2019, y_valid_2019_OHE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5590277723968029"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data = [results_2012[:2],results_2013[:2],results_2014[:2],results_2015[:2],results_2016[:2],\n",
    "                               results_2017[:2],results_2018[:2],results_2019[:2]],\n",
    "                            index = ['2012', '2013', '2014','2015','2016','2017','2018','2019'],\n",
    "                            columns = ['loss', 'accuracy'])\n",
    "sum(results['accuracy'])/8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afd8bbf76cc8f66cb6213c8ab916f8a134e63b6f70cbd0f147b7ecd8cc749dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
