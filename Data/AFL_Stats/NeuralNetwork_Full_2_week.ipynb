{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,roc_auc_score,confusion_matrix,accuracy_score,f1_score,roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from IPython.display import display\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:3: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2012 = pd.read_csv(games_folder_path + '2012.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:4: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2013 = pd.read_csv(games_folder_path + '2013.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:5: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2014 = pd.read_csv(games_folder_path + '2014.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:6: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2015 = pd.read_csv(games_folder_path + '2015.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:7: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2016 = pd.read_csv(games_folder_path + '2016.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:8: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2017 = pd.read_csv(games_folder_path + '2017.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:9: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2018 = pd.read_csv(games_folder_path + '2018.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:10: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2019 = pd.read_csv(games_folder_path + '2019.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:11: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2020 = pd.read_csv(games_folder_path + '2020.csv', index_col=False, parse_dates=['date'])\n",
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_17608\\3458396436.py:12: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2021 = pd.read_csv(games_folder_path + '2021.csv', index_col=False, parse_dates=['date'])\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "games_folder_path = \"C:/Users/Craig/Documents/Thesis/Thomas_Gallagher_Thesis/Data/AFL_Stats_sorted/Year/Games/\"\n",
    "games_2012 = pd.read_csv(games_folder_path + '2012.csv', index_col=False, parse_dates=['date'])\n",
    "games_2013 = pd.read_csv(games_folder_path + '2013.csv', index_col=False, parse_dates=['date'])\n",
    "games_2014 = pd.read_csv(games_folder_path + '2014.csv', index_col=False, parse_dates=['date'])\n",
    "games_2015 = pd.read_csv(games_folder_path + '2015.csv', index_col=False, parse_dates=['date'])\n",
    "games_2016 = pd.read_csv(games_folder_path + '2016.csv', index_col=False, parse_dates=['date'])\n",
    "games_2017 = pd.read_csv(games_folder_path + '2017.csv', index_col=False, parse_dates=['date'])\n",
    "games_2018 = pd.read_csv(games_folder_path + '2018.csv', index_col=False, parse_dates=['date'])\n",
    "games_2019 = pd.read_csv(games_folder_path + '2019.csv', index_col=False, parse_dates=['date'])\n",
    "games_2020 = pd.read_csv(games_folder_path + '2020.csv', index_col=False, parse_dates=['date'])\n",
    "games_2021 = pd.read_csv(games_folder_path + '2021.csv', index_col=False, parse_dates=['date'])\n",
    "\n",
    "\n",
    "all_games = pd.read_csv(games_folder_path + 'games_sorted.csv', index_col=False, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Teams\n",
    "encoding = LabelEncoder()\n",
    "encoding.fit(all_games[\"homeTeam\"].values)\n",
    "\n",
    "\n",
    "def OHE_Teams(games):\n",
    "    home_teams = encoding.transform(games[\"homeTeam\"].values)\n",
    "    away_teams = encoding.transform(games[\"awayTeam\"].values)\n",
    "\n",
    "    all_teams = np.vstack([home_teams, away_teams]).T\n",
    " \n",
    "    oneHot = OneHotEncoder()\n",
    "    X_teams = oneHot.fit_transform(all_teams).todense()\n",
    "    X_teams = pd.DataFrame(X_teams)\n",
    "    games = pd.concat([games, pd.DataFrame(X_teams)],axis=1)\n",
    "    return games\n",
    "\n",
    "games_2012 = OHE_Teams(games_2012)\n",
    "games_2013 = OHE_Teams(games_2013)\n",
    "games_2014 = OHE_Teams(games_2014)\n",
    "games_2015 = OHE_Teams(games_2015)\n",
    "games_2016 = OHE_Teams(games_2016)\n",
    "games_2017 = OHE_Teams(games_2017)\n",
    "games_2018 = OHE_Teams(games_2018)\n",
    "games_2019 = OHE_Teams(games_2019)\n",
    "games_2020 = OHE_Teams(games_2020)\n",
    "games_2021 = OHE_Teams(games_2021)\n",
    "\n",
    "all_games = OHE_Teams(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Venues\n",
    "encoding = LabelEncoder()\n",
    "encoding.fit(all_games[\"venue\"].values)\n",
    "all_venues = all_games[\"venue\"].values\n",
    "\n",
    "all_venues = all_venues.reshape(-1,1)\n",
    "\n",
    "def OHE_Venues(games):\n",
    "    venues = games['venue'].values\n",
    "    # all_venues = all_venues.reshape(-1,1)\n",
    "    venues = venues.reshape(-1,1)\n",
    "    oneHot = OneHotEncoder()\n",
    "\n",
    "    oneHot.fit(all_venues)\n",
    "    X_venues = oneHot.transform(venues).toarray()\n",
    "    X_venues = pd.DataFrame(X_venues, columns=oneHot.categories_[0])\n",
    "    games = pd.concat([games, X_venues], axis=1)\n",
    "    return games\n",
    "\n",
    "games_2012 = OHE_Venues(games_2012)\n",
    "games_2013 = OHE_Venues(games_2013)\n",
    "games_2014 = OHE_Venues(games_2014)\n",
    "games_2015 = OHE_Venues(games_2015)\n",
    "games_2016 = OHE_Venues(games_2016)\n",
    "games_2017 = OHE_Venues(games_2017)\n",
    "games_2018 = OHE_Venues(games_2018)\n",
    "games_2019 = OHE_Venues(games_2019)\n",
    "games_2020 = OHE_Venues(games_2020)\n",
    "games_2021 = OHE_Venues(games_2021)\n",
    "\n",
    "all_games = OHE_Venues(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time(row):\n",
    "    time = row['startTime']\n",
    "    time = time.split(':')\n",
    "    time = ''.join(time[:2])\n",
    "    row['startTime'] = time\n",
    "    return row\n",
    "\n",
    "games_2012 = games_2012.apply(split_time, axis=1)\n",
    "games_2013 = games_2013.apply(split_time, axis=1)\n",
    "games_2014 = games_2014.apply(split_time, axis=1)\n",
    "games_2015 = games_2015.apply(split_time, axis=1)\n",
    "games_2016 = games_2016.apply(split_time, axis=1)\n",
    "games_2017 = games_2017.apply(split_time, axis=1)\n",
    "games_2018 = games_2018.apply(split_time, axis=1)\n",
    "games_2019 = games_2019.apply(split_time, axis=1)\n",
    "games_2020 = games_2020.apply(split_time, axis=1)\n",
    "games_2021 = games_2021.apply(split_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_2012 = games_2012['homeWin']\n",
    "y_true_2013 = games_2013['homeWin']\n",
    "y_true_2014 = games_2014['homeWin']\n",
    "y_true_2015 = games_2015['homeWin']\n",
    "y_true_2016 = games_2016['homeWin']\n",
    "y_true_2017 = games_2017['homeWin']\n",
    "y_true_2018 = games_2018['homeWin']\n",
    "y_true_2019 = games_2019['homeWin']\n",
    "y_true_2020 = games_2020['homeWin']\n",
    "y_true_2021 = games_2021['homeWin']\n",
    "y_true = all_games['homeWin']\n",
    "\n",
    "drop_values = ['gameId', 'venue', 'homeWin', 'homeTeam', 'awayTeam', 'year','date', 'homeTeamScore', 'awayTeamScore', 'round']\n",
    "\n",
    "def drop_columns(game_list):\n",
    "    game_list = game_list.drop(drop_values,axis=1)\n",
    "    game_list.columns = game_list.columns.astype(str)\n",
    "    return game_list\n",
    "\n",
    "games_2012 = drop_columns(games_2012)\n",
    "games_2013 = drop_columns(games_2013)\n",
    "games_2014 = drop_columns(games_2014)\n",
    "games_2015 = drop_columns(games_2015)\n",
    "games_2016 = drop_columns(games_2016)\n",
    "games_2017 = drop_columns(games_2017)\n",
    "games_2018 = drop_columns(games_2018)\n",
    "games_2019 = drop_columns(games_2019)\n",
    "games_2020 = drop_columns(games_2020)\n",
    "games_2021 = drop_columns(games_2021)\n",
    "\n",
    "all_games = drop_columns(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "games_2012 = scaler.fit_transform(games_2012)\n",
    "games_2013 = scaler.fit_transform(games_2013)\n",
    "games_2014 = scaler.fit_transform(games_2014)\n",
    "games_2015 = scaler.fit_transform(games_2015)\n",
    "games_2016 = scaler.fit_transform(games_2016)\n",
    "games_2017 = scaler.fit_transform(games_2017)\n",
    "games_2018 = scaler.fit_transform(games_2018)\n",
    "games_2019 = scaler.fit_transform(games_2019)\n",
    "games_2020 = scaler.fit_transform(games_2020)\n",
    "games_2021 = scaler.fit_transform(games_2021)\n",
    "\n",
    "# all_games = scaler.fit_transform(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2012 = y_true_2012[18:171]\n",
    "y_valid_2012 = y_true_2012[171:]\n",
    "\n",
    "y_train_2013 = y_true_2013[18:171]\n",
    "y_valid_2013 = y_true_2013[171:]\n",
    "\n",
    "y_train_2014 = y_true_2014[18:171]\n",
    "y_valid_2014 = y_true_2014[171:]\n",
    "\n",
    "y_train_2015 = y_true_2015[18:170]\n",
    "y_valid_2015 = y_true_2015[170:]\n",
    "\n",
    "y_train_2016 = y_true_2016[18:171]\n",
    "y_valid_2016 = y_true_2016[171:]\n",
    "\n",
    "y_train_2017 = y_true_2017[18:171]\n",
    "y_valid_2017 = y_true_2017[171:]\n",
    "\n",
    "y_train_2018 = y_true_2018[18:171]\n",
    "y_valid_2018 = y_true_2018[171:]\n",
    "\n",
    "y_train_2019 = y_true_2019[18:171]\n",
    "y_valid_2019 = y_true_2019[171:]\n",
    "\n",
    "y_train_2020 = y_true_2020[18:127]\n",
    "y_valid_2020 = y_true_2020[127:]\n",
    "\n",
    "y_train_2021 = y_true_2021[18:171]\n",
    "y_valid_2021 = y_true_2021[171:]\n",
    "\n",
    "y_train = y_true[:1447]\n",
    "y_valid = y_true[1447:1655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE Y values\n",
    "oneHot = OneHotEncoder()\n",
    "def OHE_y_values(y_val):\n",
    "    y = np.vstack([y_val]).T\n",
    "    \n",
    "    # for i in range(len(y)):\n",
    "    #     if y[i] == 1:\n",
    "    #         y[i] = 0\n",
    "\n",
    "    y_OHE = oneHot.fit_transform(y).toarray()\n",
    "\n",
    "    return y_OHE\n",
    "\n",
    "\n",
    "y_train_2012_OHE = OHE_y_values(y_train_2012)\n",
    "y_valid_2012_OHE = OHE_y_values(y_valid_2012)\n",
    "\n",
    "y_train_2013_OHE = OHE_y_values(y_train_2013)\n",
    "y_valid_2013_OHE = OHE_y_values(y_valid_2013)\n",
    "\n",
    "y_train_2014_OHE = OHE_y_values(y_train_2014)\n",
    "y_valid_2014_OHE = OHE_y_values(y_valid_2014)\n",
    "\n",
    "y_train_2015_OHE = OHE_y_values(y_train_2015)\n",
    "y_valid_2015_OHE = OHE_y_values(y_valid_2015)\n",
    "\n",
    "y_train_2016_OHE = OHE_y_values(y_train_2016)\n",
    "y_valid_2016_OHE = OHE_y_values(y_valid_2016)\n",
    "\n",
    "y_train_2017_OHE = OHE_y_values(y_train_2017)\n",
    "y_valid_2017_OHE = OHE_y_values(y_valid_2017)\n",
    "\n",
    "y_train_2018_OHE = OHE_y_values(y_train_2018)\n",
    "y_valid_2018_OHE = OHE_y_values(y_valid_2018)\n",
    "\n",
    "y_train_2019_OHE = OHE_y_values(y_train_2019)\n",
    "y_valid_2019_OHE = OHE_y_values(y_valid_2019)\n",
    "\n",
    "y_train_2020_OHE = OHE_y_values(y_train_2020)\n",
    "y_valid_2020_OHE = OHE_y_values(y_valid_2020)\n",
    "\n",
    "y_train_2021_OHE = OHE_y_values(y_train_2021)\n",
    "y_valid_2021_OHE = OHE_y_values(y_valid_2021)\n",
    "\n",
    "y_train_OHE = OHE_y_values(y_train)\n",
    "y_valid_OHE = OHE_y_values(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_window(games):\n",
    "    y = 0 #\n",
    "    p = 0 # round 0\n",
    "    # d_full = np.zeros(shape=(1980,75))\n",
    "    d_full = np.zeros(shape=(3591,92)) # (207 - 18) * 18 + (207 - 18)\n",
    "    for x in range(0,d_full.shape[0],19): # For games in each round corresponds to d_full, when a round is ended it jumps over the added games\n",
    "        y = 18 # link to previous rounds\n",
    "        if x % 171 == 0: # Games in each round * added games\n",
    "            p += 1 # move to next round when 90 index is reached\n",
    "        for i in range(18): # fills out the first 18 posistions in the window with previous games\n",
    "            d_full[x+i] = games[p+i] # at pos x add corresponding previous game\n",
    "        d_full[x+y] = games[x//19 + y] # add game in question to final position\n",
    "    \n",
    "    d_Train = d_full[:2907]\n",
    "    d_valid = d_full[2907:]\n",
    "    d_Train = np.reshape(d_Train, (153, 19,92))\n",
    "    d_valid = np.reshape(d_valid, (36, 19, 92))\n",
    "    return d_Train, d_valid\n",
    "\n",
    "x_train_2012, x_valid_2012 = set_window(games_2012)\n",
    "x_train_2013, x_valid_2013 = set_window(games_2013)\n",
    "x_train_2014, x_valid_2014 = set_window(games_2014)\n",
    "# x_train_2015, x_valid_2015 = set_window(games_2015)\n",
    "x_train_2016, x_valid_2016 = set_window(games_2016)\n",
    "x_train_2017, x_valid_2017 = set_window(games_2017)\n",
    "x_train_2018, x_valid_2018 = set_window(games_2018)\n",
    "x_train_2019, x_valid_2019 = set_window(games_2019)\n",
    "# x_train_2020, x_valid_2020 = set_window(games_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_window_2015(games):\n",
    "    y = 0\n",
    "    p = 0\n",
    "    d_full = np.zeros(shape=(3572,92))\n",
    "    for x in range(0,d_full.shape[0],19): # Goes through index for each round\n",
    "        y = 18 # link to previous round\n",
    "        if x % 171 == 0:\n",
    "            p += 1 # move to next round when 90 index is reached\n",
    "        for i in range(18): # fills out the first nine posistions in the window with previous games\n",
    "                d_full[x+i] = games[p+i] # at pos x add corresponding previous game\n",
    "            \n",
    "        d_full[x+y] = games[x//19 + y] # add game in question to final position\n",
    "        \n",
    "    d_Train = d_full[:2888]\n",
    "    d_valid = d_full[2888:]\n",
    "    d_Train = np.reshape(d_Train, (152, 19,92))\n",
    "    d_valid = np.reshape(d_valid, (36, 19, 92))\n",
    "    return d_Train, d_valid\n",
    "\n",
    "x_train_2015, x_valid_2015 = set_window_2015(games_2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_5( xTrain, yTrain, xValid , yValid):\n",
    "    random.seed(26)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM( 64 ,input_shape = (19,92), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "    model.build()   \n",
    "    model.summary()\n",
    "    model.compile( optimizer = \"rmsprop\" , loss = 'mean_squared_error' , metrics = ['accuracy', 'mse'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau( monitor = 'accuracy', factor = 0.01, patience=10, cooldown=0)\n",
    "    \n",
    "    callbacks = [ reduce_lr ]\n",
    "    model.fit( xTrain, yTrain , epochs = 50, shuffle=False, callbacks=callbacks, verbose = 2)\n",
    "\n",
    "    # train_history = model.fit( x_train_2012 , y_train_2012 , epochs = 10, validation_split = 0.1 , verbose = 1 )\n",
    "    score = model.evaluate( xValid , yValid )\n",
    "    pred = model.predict(xValid)\n",
    "    model.save(\"LSTM_5\")\n",
    "    # print( f\"Train Accuracy: {train_history.history}\" )\n",
    "    \n",
    "    print( \"Accuracy: {:0.4}\".format( score[1] ))\n",
    "    print( \"Loss:\", score[0] )\n",
    "    return score, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 64)                40192     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,322\n",
      "Trainable params: 40,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3108 - accuracy: 0.4575 - mse: 0.3108 - lr: 0.0010 - 3s/epoch - 658ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2624 - accuracy: 0.4706 - mse: 0.2624 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2548 - accuracy: 0.5229 - mse: 0.2548 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2530 - accuracy: 0.4771 - mse: 0.2530 - lr: 0.0010 - 94ms/epoch - 19ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5425 - mse: 0.2461 - lr: 0.0010 - 93ms/epoch - 19ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5359 - mse: 0.2477 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2407 - accuracy: 0.5882 - mse: 0.2407 - lr: 0.0010 - 89ms/epoch - 18ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2357 - accuracy: 0.5882 - mse: 0.2357 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2250 - accuracy: 0.6340 - mse: 0.2250 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2229 - accuracy: 0.6601 - mse: 0.2229 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2331 - accuracy: 0.6340 - mse: 0.2331 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2113 - accuracy: 0.6993 - mse: 0.2113 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2139 - accuracy: 0.6667 - mse: 0.2139 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2199 - accuracy: 0.6732 - mse: 0.2199 - lr: 0.0010 - 94ms/epoch - 19ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2057 - accuracy: 0.7255 - mse: 0.2057 - lr: 0.0010 - 88ms/epoch - 18ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1999 - accuracy: 0.7124 - mse: 0.1999 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1965 - accuracy: 0.7386 - mse: 0.1965 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2090 - accuracy: 0.6601 - mse: 0.2090 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1997 - accuracy: 0.7320 - mse: 0.1997 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1875 - accuracy: 0.8039 - mse: 0.1875 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1863 - accuracy: 0.7647 - mse: 0.1863 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1857 - accuracy: 0.7582 - mse: 0.1857 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1719 - accuracy: 0.7974 - mse: 0.1719 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1819 - accuracy: 0.7712 - mse: 0.1819 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1911 - accuracy: 0.7386 - mse: 0.1911 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1749 - accuracy: 0.7582 - mse: 0.1749 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1696 - accuracy: 0.7582 - mse: 0.1696 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1666 - accuracy: 0.7778 - mse: 0.1666 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1667 - accuracy: 0.7974 - mse: 0.1667 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1737 - accuracy: 0.7778 - mse: 0.1737 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1537 - accuracy: 0.8105 - mse: 0.1537 - lr: 1.0000e-05 - 79ms/epoch - 16ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1511 - accuracy: 0.8301 - mse: 0.1511 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1569 - accuracy: 0.8366 - mse: 0.1569 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1587 - accuracy: 0.8366 - mse: 0.1587 - lr: 1.0000e-05 - 85ms/epoch - 17ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1593 - accuracy: 0.7778 - mse: 0.1593 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1630 - accuracy: 0.7712 - mse: 0.1630 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1557 - accuracy: 0.7908 - mse: 0.1557 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1607 - accuracy: 0.7712 - mse: 0.1607 - lr: 1.0000e-05 - 85ms/epoch - 17ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1662 - accuracy: 0.7778 - mse: 0.1662 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1577 - accuracy: 0.8039 - mse: 0.1577 - lr: 1.0000e-05 - 85ms/epoch - 17ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1675 - accuracy: 0.7582 - mse: 0.1675 - lr: 1.0000e-05 - 80ms/epoch - 16ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1587 - accuracy: 0.7974 - mse: 0.1587 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1767 - accuracy: 0.7255 - mse: 0.1767 - lr: 1.0000e-05 - 85ms/epoch - 17ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1685 - accuracy: 0.7712 - mse: 0.1685 - lr: 1.0000e-07 - 82ms/epoch - 16ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1504 - accuracy: 0.7712 - mse: 0.1504 - lr: 1.0000e-07 - 81ms/epoch - 16ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1580 - accuracy: 0.8170 - mse: 0.1580 - lr: 1.0000e-07 - 82ms/epoch - 16ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1644 - accuracy: 0.7843 - mse: 0.1644 - lr: 1.0000e-07 - 83ms/epoch - 17ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1492 - accuracy: 0.8170 - mse: 0.1492 - lr: 1.0000e-07 - 80ms/epoch - 16ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1663 - accuracy: 0.8039 - mse: 0.1663 - lr: 1.0000e-07 - 85ms/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1549 - accuracy: 0.7843 - mse: 0.1549 - lr: 1.0000e-07 - 83ms/epoch - 17ms/step\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2209 - accuracy: 0.6111 - mse: 0.2209\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6111\n",
      "Loss: 0.22089028358459473\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 64)                40192     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,322\n",
      "Trainable params: 40,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.2865 - accuracy: 0.5425 - mse: 0.2865 - lr: 0.0010 - 3s/epoch - 619ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2506 - accuracy: 0.5294 - mse: 0.2506 - lr: 0.0010 - 100ms/epoch - 20ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5752 - mse: 0.2414 - lr: 0.0010 - 101ms/epoch - 20ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2322 - accuracy: 0.5621 - mse: 0.2322 - lr: 0.0010 - 88ms/epoch - 18ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2398 - accuracy: 0.5882 - mse: 0.2398 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2293 - accuracy: 0.6144 - mse: 0.2293 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2268 - accuracy: 0.6209 - mse: 0.2268 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2165 - accuracy: 0.7124 - mse: 0.2165 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2118 - accuracy: 0.6863 - mse: 0.2118 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2070 - accuracy: 0.6601 - mse: 0.2070 - lr: 0.0010 - 78ms/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2120 - accuracy: 0.6797 - mse: 0.2120 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.1987 - accuracy: 0.7124 - mse: 0.1987 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.1986 - accuracy: 0.6928 - mse: 0.1986 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.1909 - accuracy: 0.7516 - mse: 0.1909 - lr: 0.0010 - 92ms/epoch - 18ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.1967 - accuracy: 0.7190 - mse: 0.1967 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1911 - accuracy: 0.7255 - mse: 0.1911 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1934 - accuracy: 0.6732 - mse: 0.1934 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1946 - accuracy: 0.7320 - mse: 0.1946 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1784 - accuracy: 0.7582 - mse: 0.1784 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1836 - accuracy: 0.6928 - mse: 0.1836 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1809 - accuracy: 0.7451 - mse: 0.1809 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1647 - accuracy: 0.7712 - mse: 0.1647 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1677 - accuracy: 0.7843 - mse: 0.1677 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1727 - accuracy: 0.7320 - mse: 0.1727 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1648 - accuracy: 0.7908 - mse: 0.1648 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1569 - accuracy: 0.8366 - mse: 0.1569 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1678 - accuracy: 0.7712 - mse: 0.1678 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1531 - accuracy: 0.8301 - mse: 0.1531 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1548 - accuracy: 0.8301 - mse: 0.1548 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1650 - accuracy: 0.7908 - mse: 0.1650 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1542 - accuracy: 0.8039 - mse: 0.1542 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1546 - accuracy: 0.7843 - mse: 0.1546 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1587 - accuracy: 0.7386 - mse: 0.1587 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1581 - accuracy: 0.8105 - mse: 0.1581 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1517 - accuracy: 0.8105 - mse: 0.1517 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1474 - accuracy: 0.8235 - mse: 0.1474 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1507 - accuracy: 0.8301 - mse: 0.1507 - lr: 1.0000e-05 - 80ms/epoch - 16ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1418 - accuracy: 0.8497 - mse: 0.1418 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1412 - accuracy: 0.8235 - mse: 0.1412 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1536 - accuracy: 0.8170 - mse: 0.1536 - lr: 1.0000e-05 - 79ms/epoch - 16ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1464 - accuracy: 0.7974 - mse: 0.1464 - lr: 1.0000e-05 - 80ms/epoch - 16ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1464 - accuracy: 0.7778 - mse: 0.1464 - lr: 1.0000e-05 - 84ms/epoch - 17ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1457 - accuracy: 0.8039 - mse: 0.1457 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1571 - accuracy: 0.8301 - mse: 0.1571 - lr: 1.0000e-05 - 80ms/epoch - 16ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1421 - accuracy: 0.8366 - mse: 0.1421 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1418 - accuracy: 0.8105 - mse: 0.1418 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1375 - accuracy: 0.8170 - mse: 0.1375 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1457 - accuracy: 0.8105 - mse: 0.1457 - lr: 1.0000e-05 - 84ms/epoch - 17ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1403 - accuracy: 0.8366 - mse: 0.1403 - lr: 1.0000e-07 - 83ms/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1412 - accuracy: 0.8497 - mse: 0.1412 - lr: 1.0000e-07 - 79ms/epoch - 16ms/step\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2042 - accuracy: 0.7222 - mse: 0.2042\n",
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7222\n",
      "Loss: 0.20423926413059235\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 64)                40192     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,322\n",
      "Trainable params: 40,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.2812 - accuracy: 0.5817 - mse: 0.2812 - lr: 0.0010 - 3s/epoch - 623ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2391 - accuracy: 0.6078 - mse: 0.2391 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2366 - accuracy: 0.6078 - mse: 0.2366 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2334 - accuracy: 0.6601 - mse: 0.2334 - lr: 0.0010 - 91ms/epoch - 18ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2291 - accuracy: 0.6536 - mse: 0.2291 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2229 - accuracy: 0.6078 - mse: 0.2229 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2191 - accuracy: 0.6797 - mse: 0.2191 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2100 - accuracy: 0.6993 - mse: 0.2100 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2124 - accuracy: 0.6993 - mse: 0.2124 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2061 - accuracy: 0.7059 - mse: 0.2061 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2061 - accuracy: 0.6928 - mse: 0.2061 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.1940 - accuracy: 0.7647 - mse: 0.1940 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.1951 - accuracy: 0.7516 - mse: 0.1951 - lr: 0.0010 - 93ms/epoch - 19ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.1895 - accuracy: 0.7255 - mse: 0.1895 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.1827 - accuracy: 0.7712 - mse: 0.1827 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1831 - accuracy: 0.7647 - mse: 0.1831 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1978 - accuracy: 0.7582 - mse: 0.1978 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1727 - accuracy: 0.7712 - mse: 0.1727 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1756 - accuracy: 0.7778 - mse: 0.1756 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1720 - accuracy: 0.7778 - mse: 0.1720 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1846 - accuracy: 0.7451 - mse: 0.1846 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1702 - accuracy: 0.7974 - mse: 0.1702 - lr: 0.0010 - 134ms/epoch - 27ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1616 - accuracy: 0.7843 - mse: 0.1616 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1622 - accuracy: 0.7974 - mse: 0.1622 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1689 - accuracy: 0.7582 - mse: 0.1689 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1680 - accuracy: 0.7516 - mse: 0.1680 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1573 - accuracy: 0.7778 - mse: 0.1573 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1739 - accuracy: 0.7190 - mse: 0.1739 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1547 - accuracy: 0.7908 - mse: 0.1547 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1526 - accuracy: 0.8039 - mse: 0.1526 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1686 - accuracy: 0.7843 - mse: 0.1686 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1622 - accuracy: 0.7516 - mse: 0.1622 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1526 - accuracy: 0.8105 - mse: 0.1526 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1428 - accuracy: 0.8497 - mse: 0.1428 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1530 - accuracy: 0.7843 - mse: 0.1530 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1664 - accuracy: 0.7582 - mse: 0.1664 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1545 - accuracy: 0.7778 - mse: 0.1545 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1531 - accuracy: 0.7712 - mse: 0.1531 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1551 - accuracy: 0.8039 - mse: 0.1551 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1435 - accuracy: 0.8105 - mse: 0.1435 - lr: 0.0010 - 95ms/epoch - 19ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1421 - accuracy: 0.8105 - mse: 0.1421 - lr: 0.0010 - 88ms/epoch - 18ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1537 - accuracy: 0.7843 - mse: 0.1537 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1514 - accuracy: 0.7778 - mse: 0.1514 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1323 - accuracy: 0.8431 - mse: 0.1323 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1520 - accuracy: 0.8366 - mse: 0.1520 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1456 - accuracy: 0.8039 - mse: 0.1456 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1419 - accuracy: 0.8431 - mse: 0.1419 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1466 - accuracy: 0.8105 - mse: 0.1466 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1394 - accuracy: 0.8301 - mse: 0.1394 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1469 - accuracy: 0.7843 - mse: 0.1469 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2176 - accuracy: 0.6944 - mse: 0.2176\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6944\n",
      "Loss: 0.2176419496536255\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 64)                40192     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,322\n",
      "Trainable params: 40,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3233 - accuracy: 0.4671 - mse: 0.3233 - lr: 0.0010 - 3s/epoch - 616ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2610 - accuracy: 0.4934 - mse: 0.2610 - lr: 0.0010 - 100ms/epoch - 20ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2521 - accuracy: 0.5658 - mse: 0.2521 - lr: 0.0010 - 102ms/epoch - 20ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5855 - mse: 0.2470 - lr: 0.0010 - 88ms/epoch - 18ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2517 - accuracy: 0.5526 - mse: 0.2517 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2373 - accuracy: 0.6184 - mse: 0.2373 - lr: 0.0010 - 88ms/epoch - 18ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2327 - accuracy: 0.6776 - mse: 0.2327 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2215 - accuracy: 0.7105 - mse: 0.2215 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2260 - accuracy: 0.6908 - mse: 0.2260 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2288 - accuracy: 0.6382 - mse: 0.2288 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2165 - accuracy: 0.7039 - mse: 0.2165 - lr: 0.0010 - 89ms/epoch - 18ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2103 - accuracy: 0.7105 - mse: 0.2103 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2090 - accuracy: 0.7105 - mse: 0.2090 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2121 - accuracy: 0.6974 - mse: 0.2121 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2033 - accuracy: 0.7105 - mse: 0.2033 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1993 - accuracy: 0.7171 - mse: 0.1993 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2040 - accuracy: 0.6974 - mse: 0.2040 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1913 - accuracy: 0.7632 - mse: 0.1913 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1950 - accuracy: 0.7237 - mse: 0.1950 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1896 - accuracy: 0.7632 - mse: 0.1896 - lr: 0.0010 - 92ms/epoch - 18ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1890 - accuracy: 0.7895 - mse: 0.1890 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1812 - accuracy: 0.7368 - mse: 0.1812 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1786 - accuracy: 0.7829 - mse: 0.1786 - lr: 0.0010 - 138ms/epoch - 28ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1825 - accuracy: 0.7697 - mse: 0.1825 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1792 - accuracy: 0.7171 - mse: 0.1792 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1764 - accuracy: 0.7961 - mse: 0.1764 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1730 - accuracy: 0.8289 - mse: 0.1730 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1599 - accuracy: 0.8092 - mse: 0.1599 - lr: 0.0010 - 177ms/epoch - 35ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1637 - accuracy: 0.7632 - mse: 0.1637 - lr: 0.0010 - 112ms/epoch - 22ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1723 - accuracy: 0.7829 - mse: 0.1723 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1715 - accuracy: 0.7237 - mse: 0.1715 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1606 - accuracy: 0.7566 - mse: 0.1606 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1627 - accuracy: 0.7763 - mse: 0.1627 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1580 - accuracy: 0.7763 - mse: 0.1580 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1575 - accuracy: 0.7763 - mse: 0.1575 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1740 - accuracy: 0.7434 - mse: 0.1740 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1602 - accuracy: 0.7697 - mse: 0.1602 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1560 - accuracy: 0.7632 - mse: 0.1560 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1442 - accuracy: 0.7961 - mse: 0.1442 - lr: 1.0000e-05 - 88ms/epoch - 18ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1472 - accuracy: 0.8026 - mse: 0.1472 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1468 - accuracy: 0.8289 - mse: 0.1468 - lr: 1.0000e-05 - 84ms/epoch - 17ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1535 - accuracy: 0.7895 - mse: 0.1535 - lr: 1.0000e-05 - 85ms/epoch - 17ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1464 - accuracy: 0.8026 - mse: 0.1464 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1473 - accuracy: 0.8158 - mse: 0.1473 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1508 - accuracy: 0.7697 - mse: 0.1508 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1453 - accuracy: 0.8355 - mse: 0.1453 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1489 - accuracy: 0.7895 - mse: 0.1489 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1478 - accuracy: 0.8224 - mse: 0.1478 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1379 - accuracy: 0.8487 - mse: 0.1379 - lr: 1.0000e-05 - 80ms/epoch - 16ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1470 - accuracy: 0.8355 - mse: 0.1470 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2097 - accuracy: 0.5833 - mse: 0.2097\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833\n",
      "Loss: 0.20972923934459686\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 64)                40192     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,322\n",
      "Trainable params: 40,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.2796 - accuracy: 0.6209 - mse: 0.2796 - lr: 0.0010 - 3s/epoch - 630ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2326 - accuracy: 0.6144 - mse: 0.2326 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2365 - accuracy: 0.6340 - mse: 0.2365 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2261 - accuracy: 0.6471 - mse: 0.2261 - lr: 0.0010 - 96ms/epoch - 19ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2214 - accuracy: 0.6209 - mse: 0.2214 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2243 - accuracy: 0.6536 - mse: 0.2243 - lr: 0.0010 - 88ms/epoch - 18ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2123 - accuracy: 0.6601 - mse: 0.2123 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2065 - accuracy: 0.6863 - mse: 0.2065 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2018 - accuracy: 0.7059 - mse: 0.2018 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.1985 - accuracy: 0.7059 - mse: 0.1985 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2023 - accuracy: 0.7059 - mse: 0.2023 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.1967 - accuracy: 0.7124 - mse: 0.1967 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.1931 - accuracy: 0.7320 - mse: 0.1931 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.1798 - accuracy: 0.7451 - mse: 0.1798 - lr: 0.0010 - 120ms/epoch - 24ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.1778 - accuracy: 0.7320 - mse: 0.1778 - lr: 0.0010 - 93ms/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1693 - accuracy: 0.7712 - mse: 0.1693 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1820 - accuracy: 0.7582 - mse: 0.1820 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1662 - accuracy: 0.7516 - mse: 0.1662 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1670 - accuracy: 0.7778 - mse: 0.1670 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1631 - accuracy: 0.7778 - mse: 0.1631 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1639 - accuracy: 0.7974 - mse: 0.1639 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1679 - accuracy: 0.7582 - mse: 0.1679 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1591 - accuracy: 0.7712 - mse: 0.1591 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1614 - accuracy: 0.7712 - mse: 0.1614 - lr: 0.0010 - 140ms/epoch - 28ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1611 - accuracy: 0.7974 - mse: 0.1611 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1478 - accuracy: 0.7843 - mse: 0.1478 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1506 - accuracy: 0.8431 - mse: 0.1506 - lr: 0.0010 - 78ms/epoch - 16ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1492 - accuracy: 0.7974 - mse: 0.1492 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1473 - accuracy: 0.7843 - mse: 0.1473 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1553 - accuracy: 0.8235 - mse: 0.1553 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1462 - accuracy: 0.7974 - mse: 0.1462 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1355 - accuracy: 0.8235 - mse: 0.1355 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1366 - accuracy: 0.8301 - mse: 0.1366 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1511 - accuracy: 0.7908 - mse: 0.1511 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1419 - accuracy: 0.8105 - mse: 0.1419 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1464 - accuracy: 0.7908 - mse: 0.1464 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1322 - accuracy: 0.8235 - mse: 0.1322 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1432 - accuracy: 0.8366 - mse: 0.1432 - lr: 1.0000e-05 - 85ms/epoch - 17ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1317 - accuracy: 0.8562 - mse: 0.1317 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1332 - accuracy: 0.8497 - mse: 0.1332 - lr: 1.0000e-05 - 80ms/epoch - 16ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1415 - accuracy: 0.8301 - mse: 0.1415 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1412 - accuracy: 0.8235 - mse: 0.1412 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1343 - accuracy: 0.8497 - mse: 0.1343 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1456 - accuracy: 0.8039 - mse: 0.1456 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1367 - accuracy: 0.8497 - mse: 0.1367 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1386 - accuracy: 0.8301 - mse: 0.1386 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1400 - accuracy: 0.8170 - mse: 0.1400 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1423 - accuracy: 0.8170 - mse: 0.1423 - lr: 1.0000e-05 - 84ms/epoch - 17ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1390 - accuracy: 0.8562 - mse: 0.1390 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1260 - accuracy: 0.8627 - mse: 0.1260 - lr: 1.0000e-07 - 82ms/epoch - 16ms/step\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2486 - accuracy: 0.5556 - mse: 0.2486\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5556\n",
      "Loss: 0.2486078441143036\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 64)                40192     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,322\n",
      "Trainable params: 40,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.3007 - accuracy: 0.4967 - mse: 0.3007 - lr: 0.0010 - 3s/epoch - 643ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2540 - accuracy: 0.5425 - mse: 0.2540 - lr: 0.0010 - 101ms/epoch - 20ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2523 - accuracy: 0.5490 - mse: 0.2523 - lr: 0.0010 - 97ms/epoch - 19ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.5425 - mse: 0.2500 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5294 - mse: 0.2480 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2460 - accuracy: 0.5556 - mse: 0.2460 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5556 - mse: 0.2466 - lr: 0.0010 - 88ms/epoch - 18ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2417 - accuracy: 0.5752 - mse: 0.2417 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5556 - mse: 0.2473 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2229 - accuracy: 0.6275 - mse: 0.2229 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2323 - accuracy: 0.6144 - mse: 0.2323 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2300 - accuracy: 0.6144 - mse: 0.2300 - lr: 0.0010 - 89ms/epoch - 18ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2294 - accuracy: 0.5817 - mse: 0.2294 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2250 - accuracy: 0.6471 - mse: 0.2250 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2151 - accuracy: 0.6732 - mse: 0.2151 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2188 - accuracy: 0.6928 - mse: 0.2188 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2126 - accuracy: 0.6471 - mse: 0.2126 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2152 - accuracy: 0.6667 - mse: 0.2152 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2083 - accuracy: 0.6863 - mse: 0.2083 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2126 - accuracy: 0.6993 - mse: 0.2126 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2091 - accuracy: 0.6797 - mse: 0.2091 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2014 - accuracy: 0.6993 - mse: 0.2014 - lr: 0.0010 - 130ms/epoch - 26ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2048 - accuracy: 0.7124 - mse: 0.2048 - lr: 0.0010 - 90ms/epoch - 18ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2138 - accuracy: 0.6797 - mse: 0.2138 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1932 - accuracy: 0.6863 - mse: 0.1932 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1997 - accuracy: 0.6993 - mse: 0.1997 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2006 - accuracy: 0.6993 - mse: 0.2006 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1958 - accuracy: 0.7320 - mse: 0.1958 - lr: 0.0010 - 78ms/epoch - 16ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1953 - accuracy: 0.7451 - mse: 0.1953 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2014 - accuracy: 0.6667 - mse: 0.2014 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1830 - accuracy: 0.7451 - mse: 0.1830 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1935 - accuracy: 0.6863 - mse: 0.1935 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1895 - accuracy: 0.7255 - mse: 0.1895 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1867 - accuracy: 0.7582 - mse: 0.1867 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1941 - accuracy: 0.6797 - mse: 0.1941 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1849 - accuracy: 0.7255 - mse: 0.1849 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1789 - accuracy: 0.7647 - mse: 0.1789 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1867 - accuracy: 0.7059 - mse: 0.1867 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1700 - accuracy: 0.7647 - mse: 0.1700 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1801 - accuracy: 0.7516 - mse: 0.1801 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1728 - accuracy: 0.7582 - mse: 0.1728 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1882 - accuracy: 0.7190 - mse: 0.1882 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1921 - accuracy: 0.7386 - mse: 0.1921 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1772 - accuracy: 0.7516 - mse: 0.1772 - lr: 0.0010 - 78ms/epoch - 16ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1795 - accuracy: 0.7190 - mse: 0.1795 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1722 - accuracy: 0.7255 - mse: 0.1722 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1772 - accuracy: 0.7386 - mse: 0.1772 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1664 - accuracy: 0.7451 - mse: 0.1664 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1781 - accuracy: 0.7320 - mse: 0.1781 - lr: 1.0000e-05 - 85ms/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1751 - accuracy: 0.7386 - mse: 0.1751 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2102 - accuracy: 0.7500 - mse: 0.2102\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Loss: 0.21020549535751343\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 64)                40192     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,322\n",
      "Trainable params: 40,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.2895 - accuracy: 0.5294 - mse: 0.2895 - lr: 0.0010 - 3s/epoch - 618ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5948 - mse: 0.2421 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5621 - mse: 0.2440 - lr: 0.0010 - 78ms/epoch - 16ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2310 - accuracy: 0.6209 - mse: 0.2310 - lr: 0.0010 - 87ms/epoch - 17ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2363 - accuracy: 0.6601 - mse: 0.2363 - lr: 0.0010 - 77ms/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2278 - accuracy: 0.6536 - mse: 0.2278 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2258 - accuracy: 0.6732 - mse: 0.2258 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2232 - accuracy: 0.6601 - mse: 0.2232 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2183 - accuracy: 0.6797 - mse: 0.2183 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2061 - accuracy: 0.7582 - mse: 0.2061 - lr: 0.0010 - 78ms/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2162 - accuracy: 0.6536 - mse: 0.2162 - lr: 0.0010 - 77ms/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2176 - accuracy: 0.6471 - mse: 0.2176 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2026 - accuracy: 0.7190 - mse: 0.2026 - lr: 0.0010 - 78ms/epoch - 16ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2071 - accuracy: 0.6471 - mse: 0.2071 - lr: 0.0010 - 77ms/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2013 - accuracy: 0.6667 - mse: 0.2013 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.1923 - accuracy: 0.7386 - mse: 0.1923 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.1905 - accuracy: 0.7190 - mse: 0.1905 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.1948 - accuracy: 0.7059 - mse: 0.1948 - lr: 0.0010 - 79ms/epoch - 16ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.1852 - accuracy: 0.6928 - mse: 0.1852 - lr: 0.0010 - 78ms/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.1856 - accuracy: 0.7582 - mse: 0.1856 - lr: 0.0010 - 76ms/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.1766 - accuracy: 0.7712 - mse: 0.1766 - lr: 1.0000e-05 - 77ms/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.1891 - accuracy: 0.7190 - mse: 0.1891 - lr: 1.0000e-05 - 78ms/epoch - 16ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1825 - accuracy: 0.7647 - mse: 0.1825 - lr: 1.0000e-05 - 75ms/epoch - 15ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1831 - accuracy: 0.7582 - mse: 0.1831 - lr: 1.0000e-05 - 130ms/epoch - 26ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1817 - accuracy: 0.7451 - mse: 0.1817 - lr: 1.0000e-05 - 79ms/epoch - 16ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1697 - accuracy: 0.7974 - mse: 0.1697 - lr: 1.0000e-05 - 75ms/epoch - 15ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1888 - accuracy: 0.7647 - mse: 0.1888 - lr: 1.0000e-05 - 76ms/epoch - 15ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1735 - accuracy: 0.7843 - mse: 0.1735 - lr: 1.0000e-05 - 78ms/epoch - 16ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1798 - accuracy: 0.7908 - mse: 0.1798 - lr: 1.0000e-05 - 84ms/epoch - 17ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1808 - accuracy: 0.7843 - mse: 0.1808 - lr: 1.0000e-05 - 79ms/epoch - 16ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1826 - accuracy: 0.7320 - mse: 0.1826 - lr: 1.0000e-05 - 83ms/epoch - 17ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1791 - accuracy: 0.7582 - mse: 0.1791 - lr: 1.0000e-05 - 79ms/epoch - 16ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1881 - accuracy: 0.7255 - mse: 0.1881 - lr: 1.0000e-05 - 80ms/epoch - 16ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1750 - accuracy: 0.7908 - mse: 0.1750 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1834 - accuracy: 0.7386 - mse: 0.1834 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1851 - accuracy: 0.7582 - mse: 0.1851 - lr: 1.0000e-05 - 80ms/epoch - 16ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1839 - accuracy: 0.7255 - mse: 0.1839 - lr: 1.0000e-07 - 83ms/epoch - 17ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1837 - accuracy: 0.7320 - mse: 0.1837 - lr: 1.0000e-07 - 80ms/epoch - 16ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1843 - accuracy: 0.7320 - mse: 0.1843 - lr: 1.0000e-07 - 83ms/epoch - 17ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1814 - accuracy: 0.7712 - mse: 0.1814 - lr: 1.0000e-07 - 81ms/epoch - 16ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1721 - accuracy: 0.7712 - mse: 0.1721 - lr: 1.0000e-07 - 138ms/epoch - 28ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1873 - accuracy: 0.7386 - mse: 0.1873 - lr: 1.0000e-07 - 111ms/epoch - 22ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1858 - accuracy: 0.7320 - mse: 0.1858 - lr: 1.0000e-07 - 98ms/epoch - 20ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1770 - accuracy: 0.7712 - mse: 0.1770 - lr: 1.0000e-07 - 84ms/epoch - 17ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1850 - accuracy: 0.7712 - mse: 0.1850 - lr: 1.0000e-07 - 83ms/epoch - 17ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1816 - accuracy: 0.8039 - mse: 0.1816 - lr: 1.0000e-07 - 83ms/epoch - 17ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1864 - accuracy: 0.7451 - mse: 0.1864 - lr: 1.0000e-07 - 79ms/epoch - 16ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1824 - accuracy: 0.7582 - mse: 0.1824 - lr: 1.0000e-07 - 83ms/epoch - 17ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1693 - accuracy: 0.7974 - mse: 0.1693 - lr: 1.0000e-07 - 79ms/epoch - 16ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1754 - accuracy: 0.7516 - mse: 0.1754 - lr: 1.0000e-07 - 80ms/epoch - 16ms/step\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1959 - accuracy: 0.6667 - mse: 0.1959\n",
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6667\n",
      "Loss: 0.19593846797943115\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 64)                40192     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,322\n",
      "Trainable params: 40,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 3s - loss: 0.2994 - accuracy: 0.5294 - mse: 0.2994 - lr: 0.0010 - 3s/epoch - 618ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2550 - accuracy: 0.5294 - mse: 0.2550 - lr: 0.0010 - 104ms/epoch - 21ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2529 - accuracy: 0.5490 - mse: 0.2529 - lr: 0.0010 - 102ms/epoch - 20ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5882 - mse: 0.2469 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5817 - mse: 0.2446 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.6013 - mse: 0.2440 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2384 - accuracy: 0.6275 - mse: 0.2384 - lr: 0.0010 - 86ms/epoch - 17ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2346 - accuracy: 0.6144 - mse: 0.2346 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2304 - accuracy: 0.6209 - mse: 0.2304 - lr: 0.0010 - 85ms/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2249 - accuracy: 0.6405 - mse: 0.2249 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2286 - accuracy: 0.6405 - mse: 0.2286 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2195 - accuracy: 0.6275 - mse: 0.2195 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2210 - accuracy: 0.6536 - mse: 0.2210 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2178 - accuracy: 0.6863 - mse: 0.2178 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2152 - accuracy: 0.6928 - mse: 0.2152 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2152 - accuracy: 0.6536 - mse: 0.2152 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2115 - accuracy: 0.6536 - mse: 0.2115 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2115 - accuracy: 0.7059 - mse: 0.2115 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2076 - accuracy: 0.6928 - mse: 0.2076 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2033 - accuracy: 0.7059 - mse: 0.2033 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2025 - accuracy: 0.7059 - mse: 0.2025 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2070 - accuracy: 0.6667 - mse: 0.2070 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.1981 - accuracy: 0.7059 - mse: 0.1981 - lr: 0.0010 - 80ms/epoch - 16ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.1999 - accuracy: 0.6863 - mse: 0.1999 - lr: 0.0010 - 135ms/epoch - 27ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.1853 - accuracy: 0.7516 - mse: 0.1853 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.1950 - accuracy: 0.7059 - mse: 0.1950 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.1912 - accuracy: 0.7255 - mse: 0.1912 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.1866 - accuracy: 0.7451 - mse: 0.1866 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.1900 - accuracy: 0.6993 - mse: 0.1900 - lr: 0.0010 - 81ms/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.1928 - accuracy: 0.6732 - mse: 0.1928 - lr: 0.0010 - 132ms/epoch - 26ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.1842 - accuracy: 0.7320 - mse: 0.1842 - lr: 0.0010 - 113ms/epoch - 23ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.1950 - accuracy: 0.7059 - mse: 0.1950 - lr: 0.0010 - 93ms/epoch - 19ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.1885 - accuracy: 0.7255 - mse: 0.1885 - lr: 0.0010 - 84ms/epoch - 17ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.1839 - accuracy: 0.7255 - mse: 0.1839 - lr: 0.0010 - 83ms/epoch - 17ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.1843 - accuracy: 0.7451 - mse: 0.1843 - lr: 0.0010 - 82ms/epoch - 16ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.1857 - accuracy: 0.7255 - mse: 0.1857 - lr: 1.0000e-05 - 84ms/epoch - 17ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.1826 - accuracy: 0.7516 - mse: 0.1826 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.1862 - accuracy: 0.7255 - mse: 0.1862 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.1840 - accuracy: 0.7320 - mse: 0.1840 - lr: 1.0000e-05 - 84ms/epoch - 17ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.1923 - accuracy: 0.7320 - mse: 0.1923 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.1790 - accuracy: 0.6993 - mse: 0.1790 - lr: 1.0000e-05 - 85ms/epoch - 17ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.1819 - accuracy: 0.7190 - mse: 0.1819 - lr: 1.0000e-05 - 79ms/epoch - 16ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.1721 - accuracy: 0.7320 - mse: 0.1721 - lr: 1.0000e-05 - 82ms/epoch - 16ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.1809 - accuracy: 0.7451 - mse: 0.1809 - lr: 1.0000e-05 - 81ms/epoch - 16ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.1952 - accuracy: 0.6667 - mse: 0.1952 - lr: 1.0000e-05 - 84ms/epoch - 17ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.1731 - accuracy: 0.7386 - mse: 0.1731 - lr: 1.0000e-07 - 81ms/epoch - 16ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.1892 - accuracy: 0.7190 - mse: 0.1892 - lr: 1.0000e-07 - 81ms/epoch - 16ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.1866 - accuracy: 0.6993 - mse: 0.1866 - lr: 1.0000e-07 - 81ms/epoch - 16ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.1765 - accuracy: 0.7516 - mse: 0.1765 - lr: 1.0000e-07 - 84ms/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.1923 - accuracy: 0.6863 - mse: 0.1923 - lr: 1.0000e-07 - 79ms/epoch - 16ms/step\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2335 - accuracy: 0.7222 - mse: 0.2335\n",
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7222\n",
      "Loss: 0.23345300555229187\n"
     ]
    }
   ],
   "source": [
    "results_2012, pred_2012 = train_model_5(x_train_2012, y_train_2012_OHE, x_valid_2012, y_valid_2012_OHE) \n",
    "results_2013, pred_2013 = train_model_5(x_train_2013, y_train_2013_OHE, x_valid_2013, y_valid_2013_OHE) \n",
    "results_2014, pred_2014 = train_model_5(x_train_2014, y_train_2014_OHE, x_valid_2014, y_valid_2014_OHE) \n",
    "results_2015, pred_2015 = train_model_5(x_train_2015, y_train_2015_OHE, x_valid_2015, y_valid_2015_OHE) \n",
    "results_2016, pred_2016 = train_model_5(x_train_2016, y_train_2016_OHE, x_valid_2016, y_valid_2016_OHE) \n",
    "results_2017, pred_2017 = train_model_5(x_train_2017, y_train_2017_OHE, x_valid_2017, y_valid_2017_OHE) \n",
    "results_2018, pred_2018 = train_model_5(x_train_2018, y_train_2018_OHE, x_valid_2018, y_valid_2018_OHE) \n",
    "results_2019, pred_2019 = train_model_5(x_train_2019, y_train_2019_OHE, x_valid_2019, y_valid_2019_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.663194440305233"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data = [results_2012[:2],results_2013[:2],results_2014[:2],results_2015[:2],results_2016[:2],\n",
    "                               results_2017[:2],results_2018[:2],results_2019[:2]],\n",
    "                            index = ['2012', '2013', '2014','2015','2016','2017','2018','2019'],\n",
    "                            columns = ['loss', 'accuracy'])\n",
    "sum(results['accuracy'])/8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 1.0, '2018'), Text(0.5, 1.0, '2019'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 17 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_conf_matrix(prediction, true):\n",
    "    s = 0\n",
    "    pl = []\n",
    "    for pred in prediction:\n",
    "        if pred[0] > pred[1]:\n",
    "            pl.append(0)\n",
    "        else:\n",
    "            pl.append(1)\n",
    "\n",
    "    for i in range(len(pl)):\n",
    "        if pl[i] == true.values[i]:\n",
    "            s+=1\n",
    "\n",
    "    c_train = confusion_matrix(true, pl)\n",
    "    disp = ConfusionMatrixDisplay(c_train)\n",
    "    return disp\n",
    "\n",
    "cf_2012 = build_conf_matrix(pred_2012, y_valid_2012)\n",
    "cf_2013 = build_conf_matrix(pred_2013, y_valid_2013)\n",
    "cf_2014 = build_conf_matrix(pred_2014, y_valid_2014)\n",
    "cf_2015 = build_conf_matrix(pred_2015, y_valid_2015)\n",
    "cf_2016 = build_conf_matrix(pred_2016, y_valid_2016)\n",
    "cf_2017 = build_conf_matrix(pred_2017, y_valid_2017)\n",
    "cf_2018 = build_conf_matrix(pred_2018, y_valid_2018)\n",
    "cf_2019 = build_conf_matrix(pred_2019, y_valid_2019)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,3)\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(12)\n",
    "fig.suptitle(\"Confusion Matrices: LSTM Model 5 Training/Validation Set 66.3%\")\n",
    "cf_2012.plot(ax=ax[0][0]), cf_2013.plot(ax=ax[0][1]), cf_2014.plot(ax=ax[0][2])\n",
    "cf_2015.plot(ax=ax[1][0]), cf_2016.plot(ax=ax[1][1]), cf_2017.plot(ax=ax[1][2])\n",
    "cf_2018.plot(ax=ax[2][0]), cf_2019.plot(ax=ax[2][1])\n",
    "\n",
    "ax[0][0].set_title(2012), ax[0][1].set_title(2013), ax[0][2].set_title(2014)\n",
    "ax[1][0].set_title(2015), ax[1][1].set_title(2016), ax[1][2].set_title(2017)\n",
    "ax[2][0].set_title(2018), ax[2][1].set_title(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,978\n",
      "Trainable params: 42,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 7s - loss: 0.4183 - accuracy: 0.5255 - mse: 0.4183 - val_loss: 0.2471 - val_accuracy: 0.7500 - val_mse: 0.2471 - lr: 0.0010 - 7s/epoch - 1s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2811 - accuracy: 0.4818 - mse: 0.2811 - val_loss: 0.3129 - val_accuracy: 0.2500 - val_mse: 0.3129 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2726 - accuracy: 0.4964 - mse: 0.2726 - val_loss: 0.2992 - val_accuracy: 0.2500 - val_mse: 0.2992 - lr: 0.0010 - 149ms/epoch - 30ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2633 - accuracy: 0.4672 - mse: 0.2633 - val_loss: 0.2627 - val_accuracy: 0.2500 - val_mse: 0.2627 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2544 - accuracy: 0.5620 - mse: 0.2544 - val_loss: 0.2262 - val_accuracy: 0.7500 - val_mse: 0.2262 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2511 - accuracy: 0.5182 - mse: 0.2511 - val_loss: 0.2233 - val_accuracy: 0.7500 - val_mse: 0.2233 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2508 - accuracy: 0.5255 - mse: 0.2508 - val_loss: 0.2389 - val_accuracy: 0.7500 - val_mse: 0.2389 - lr: 0.0010 - 175ms/epoch - 35ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.5255 - mse: 0.2500 - val_loss: 0.2571 - val_accuracy: 0.2500 - val_mse: 0.2571 - lr: 0.0010 - 166ms/epoch - 33ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2526 - accuracy: 0.5036 - mse: 0.2526 - val_loss: 0.2633 - val_accuracy: 0.2500 - val_mse: 0.2633 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5766 - mse: 0.2475 - val_loss: 0.2557 - val_accuracy: 0.2500 - val_mse: 0.2557 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.6277 - mse: 0.2458 - val_loss: 0.2490 - val_accuracy: 0.6875 - val_mse: 0.2490 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5474 - mse: 0.2485 - val_loss: 0.2472 - val_accuracy: 0.6250 - val_mse: 0.2472 - lr: 0.0010 - 150ms/epoch - 30ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2501 - accuracy: 0.5474 - mse: 0.2501 - val_loss: 0.2507 - val_accuracy: 0.4375 - val_mse: 0.2507 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2567 - val_accuracy: 0.2500 - val_mse: 0.2567 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5036 - mse: 0.2496 - val_loss: 0.2598 - val_accuracy: 0.2500 - val_mse: 0.2598 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5839 - mse: 0.2465 - val_loss: 0.2600 - val_accuracy: 0.2500 - val_mse: 0.2600 - lr: 0.0010 - 148ms/epoch - 30ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2424 - accuracy: 0.6277 - mse: 0.2424 - val_loss: 0.2613 - val_accuracy: 0.2500 - val_mse: 0.2613 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2457 - accuracy: 0.5912 - mse: 0.2457 - val_loss: 0.2636 - val_accuracy: 0.2500 - val_mse: 0.2636 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2443 - accuracy: 0.5693 - mse: 0.2443 - val_loss: 0.2651 - val_accuracy: 0.2500 - val_mse: 0.2651 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.5766 - mse: 0.2442 - val_loss: 0.2624 - val_accuracy: 0.2500 - val_mse: 0.2624 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.6131 - mse: 0.2415 - val_loss: 0.2702 - val_accuracy: 0.2500 - val_mse: 0.2702 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5912 - mse: 0.2423 - val_loss: 0.2704 - val_accuracy: 0.2500 - val_mse: 0.2704 - lr: 1.0000e-05 - 150ms/epoch - 30ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5839 - mse: 0.2472 - val_loss: 0.2706 - val_accuracy: 0.2500 - val_mse: 0.2706 - lr: 1.0000e-05 - 147ms/epoch - 29ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5912 - mse: 0.2465 - val_loss: 0.2708 - val_accuracy: 0.2500 - val_mse: 0.2708 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5693 - mse: 0.2421 - val_loss: 0.2710 - val_accuracy: 0.2500 - val_mse: 0.2710 - lr: 1.0000e-05 - 149ms/epoch - 30ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2428 - accuracy: 0.5328 - mse: 0.2428 - val_loss: 0.2712 - val_accuracy: 0.2500 - val_mse: 0.2712 - lr: 1.0000e-05 - 152ms/epoch - 30ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.6277 - mse: 0.2401 - val_loss: 0.2714 - val_accuracy: 0.2500 - val_mse: 0.2714 - lr: 1.0000e-05 - 153ms/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2424 - accuracy: 0.6058 - mse: 0.2424 - val_loss: 0.2716 - val_accuracy: 0.2500 - val_mse: 0.2716 - lr: 1.0000e-05 - 149ms/epoch - 30ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2433 - accuracy: 0.5620 - mse: 0.2433 - val_loss: 0.2718 - val_accuracy: 0.2500 - val_mse: 0.2718 - lr: 1.0000e-05 - 149ms/epoch - 30ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5839 - mse: 0.2423 - val_loss: 0.2720 - val_accuracy: 0.2500 - val_mse: 0.2720 - lr: 1.0000e-05 - 153ms/epoch - 31ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.6058 - mse: 0.2426 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-05 - 150ms/epoch - 30ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5985 - mse: 0.2444 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 151ms/epoch - 30ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 151ms/epoch - 30ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.6058 - mse: 0.2461 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 155ms/epoch - 31ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5766 - mse: 0.2454 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 145ms/epoch - 29ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.5985 - mse: 0.2442 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 149ms/epoch - 30ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5912 - mse: 0.2426 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 149ms/epoch - 30ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.5766 - mse: 0.2447 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 151ms/epoch - 30ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5474 - mse: 0.2484 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 152ms/epoch - 30ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2417 - accuracy: 0.6204 - mse: 0.2417 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 149ms/epoch - 30ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5766 - mse: 0.2416 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-07 - 155ms/epoch - 31ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.6204 - mse: 0.2406 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-09 - 155ms/epoch - 31ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2450 - accuracy: 0.5912 - mse: 0.2450 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-09 - 154ms/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.6058 - mse: 0.2468 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-09 - 153ms/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5693 - mse: 0.2425 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-09 - 152ms/epoch - 30ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.6350 - mse: 0.2411 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-09 - 155ms/epoch - 31ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2435 - accuracy: 0.5839 - mse: 0.2435 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-09 - 151ms/epoch - 30ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5766 - mse: 0.2459 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-09 - 147ms/epoch - 29ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5474 - mse: 0.2467 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-09 - 182ms/epoch - 36ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2424 - accuracy: 0.5620 - mse: 0.2424 - val_loss: 0.2722 - val_accuracy: 0.2500 - val_mse: 0.2722 - lr: 1.0000e-09 - 211ms/epoch - 42ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2549 - accuracy: 0.4444 - mse: 0.2549\n",
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4444\n",
      "Loss: 0.2548602819442749\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,978\n",
      "Trainable params: 42,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 7s - loss: 0.4122 - accuracy: 0.5693 - mse: 0.4122 - val_loss: 0.2811 - val_accuracy: 0.5000 - val_mse: 0.2811 - lr: 0.0010 - 7s/epoch - 1s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2768 - accuracy: 0.5693 - mse: 0.2768 - val_loss: 0.3105 - val_accuracy: 0.5000 - val_mse: 0.3105 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2668 - accuracy: 0.5693 - mse: 0.2668 - val_loss: 0.2815 - val_accuracy: 0.5000 - val_mse: 0.2815 - lr: 0.0010 - 192ms/epoch - 38ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2520 - accuracy: 0.5693 - mse: 0.2520 - val_loss: 0.2751 - val_accuracy: 0.5000 - val_mse: 0.2751 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2560 - accuracy: 0.5693 - mse: 0.2560 - val_loss: 0.2665 - val_accuracy: 0.5000 - val_mse: 0.2665 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2504 - accuracy: 0.5693 - mse: 0.2504 - val_loss: 0.2672 - val_accuracy: 0.5000 - val_mse: 0.2672 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5693 - mse: 0.2472 - val_loss: 0.2737 - val_accuracy: 0.5000 - val_mse: 0.2737 - lr: 0.0010 - 194ms/epoch - 39ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5693 - mse: 0.2431 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5693 - mse: 0.2485 - val_loss: 0.2745 - val_accuracy: 0.5000 - val_mse: 0.2745 - lr: 0.0010 - 148ms/epoch - 30ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5693 - mse: 0.2490 - val_loss: 0.2737 - val_accuracy: 0.5000 - val_mse: 0.2737 - lr: 0.0010 - 148ms/epoch - 30ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5620 - mse: 0.2438 - val_loss: 0.2755 - val_accuracy: 0.5000 - val_mse: 0.2755 - lr: 0.0010 - 215ms/epoch - 43ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.5766 - mse: 0.2401 - val_loss: 0.2755 - val_accuracy: 0.5000 - val_mse: 0.2755 - lr: 1.0000e-05 - 147ms/epoch - 29ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2393 - accuracy: 0.5839 - mse: 0.2393 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-05 - 149ms/epoch - 30ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5693 - mse: 0.2438 - val_loss: 0.2755 - val_accuracy: 0.5000 - val_mse: 0.2755 - lr: 1.0000e-05 - 154ms/epoch - 31ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5693 - mse: 0.2438 - val_loss: 0.2755 - val_accuracy: 0.5000 - val_mse: 0.2755 - lr: 1.0000e-05 - 144ms/epoch - 29ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2402 - accuracy: 0.5693 - mse: 0.2402 - val_loss: 0.2755 - val_accuracy: 0.5000 - val_mse: 0.2755 - lr: 1.0000e-05 - 146ms/epoch - 29ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5620 - mse: 0.2423 - val_loss: 0.2755 - val_accuracy: 0.5000 - val_mse: 0.2755 - lr: 1.0000e-05 - 143ms/epoch - 29ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5693 - mse: 0.2420 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5693 - mse: 0.2430 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-05 - 149ms/epoch - 30ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5693 - mse: 0.2471 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-05 - 146ms/epoch - 29ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5693 - mse: 0.2490 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-05 - 145ms/epoch - 29ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2433 - accuracy: 0.5547 - mse: 0.2433 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-05 - 147ms/epoch - 29ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2494 - accuracy: 0.5693 - mse: 0.2494 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-05 - 146ms/epoch - 29ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5839 - mse: 0.2459 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 149ms/epoch - 30ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2403 - accuracy: 0.5620 - mse: 0.2403 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 146ms/epoch - 29ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5693 - mse: 0.2471 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 150ms/epoch - 30ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2428 - accuracy: 0.5766 - mse: 0.2428 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 150ms/epoch - 30ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5766 - mse: 0.2414 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 145ms/epoch - 29ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5620 - mse: 0.2426 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 150ms/epoch - 30ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2437 - accuracy: 0.5620 - mse: 0.2437 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 144ms/epoch - 29ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5693 - mse: 0.2486 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 144ms/epoch - 29ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5693 - mse: 0.2418 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 146ms/epoch - 29ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5693 - mse: 0.2426 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-07 - 146ms/epoch - 29ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2376 - accuracy: 0.5766 - mse: 0.2376 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 149ms/epoch - 30ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2422 - accuracy: 0.5693 - mse: 0.2422 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 146ms/epoch - 29ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5693 - mse: 0.2465 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 153ms/epoch - 31ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5766 - mse: 0.2432 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 157ms/epoch - 31ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5620 - mse: 0.2444 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 154ms/epoch - 31ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5693 - mse: 0.2448 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 147ms/epoch - 29ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5766 - mse: 0.2414 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 157ms/epoch - 31ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2417 - accuracy: 0.5839 - mse: 0.2417 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 160ms/epoch - 32ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2419 - accuracy: 0.5693 - mse: 0.2419 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 158ms/epoch - 32ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2401 - accuracy: 0.5693 - mse: 0.2401 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-09 - 161ms/epoch - 32ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2419 - accuracy: 0.5766 - mse: 0.2419 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-11 - 153ms/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5693 - mse: 0.2415 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-11 - 158ms/epoch - 32ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2436 - accuracy: 0.5620 - mse: 0.2436 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-11 - 163ms/epoch - 33ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.5839 - mse: 0.2442 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-11 - 168ms/epoch - 34ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5693 - mse: 0.2448 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-11 - 189ms/epoch - 38ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5547 - mse: 0.2420 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-11 - 147ms/epoch - 29ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5839 - mse: 0.2470 - val_loss: 0.2756 - val_accuracy: 0.5000 - val_mse: 0.2756 - lr: 1.0000e-11 - 147ms/epoch - 29ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2460 - accuracy: 0.5833 - mse: 0.2460\n",
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833\n",
      "Loss: 0.24595314264297485\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,978\n",
      "Trainable params: 42,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 8s - loss: 0.3933 - accuracy: 0.5693 - mse: 0.3933 - val_loss: 0.2756 - val_accuracy: 0.5625 - val_mse: 0.2756 - lr: 0.0010 - 8s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2858 - accuracy: 0.5693 - mse: 0.2858 - val_loss: 0.2876 - val_accuracy: 0.5625 - val_mse: 0.2876 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2595 - accuracy: 0.5693 - mse: 0.2595 - val_loss: 0.2460 - val_accuracy: 0.5625 - val_mse: 0.2460 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5693 - mse: 0.2498 - val_loss: 0.2520 - val_accuracy: 0.5625 - val_mse: 0.2520 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2539 - accuracy: 0.5693 - mse: 0.2539 - val_loss: 0.2478 - val_accuracy: 0.5625 - val_mse: 0.2478 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5766 - mse: 0.2416 - val_loss: 0.2485 - val_accuracy: 0.5625 - val_mse: 0.2485 - lr: 0.0010 - 149ms/epoch - 30ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5766 - mse: 0.2425 - val_loss: 0.2497 - val_accuracy: 0.5625 - val_mse: 0.2497 - lr: 0.0010 - 150ms/epoch - 30ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2405 - accuracy: 0.5912 - mse: 0.2405 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2402 - accuracy: 0.6277 - mse: 0.2402 - val_loss: 0.2456 - val_accuracy: 0.5625 - val_mse: 0.2456 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2396 - accuracy: 0.5547 - mse: 0.2396 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 0.0010 - 225ms/epoch - 45ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2362 - accuracy: 0.5912 - mse: 0.2362 - val_loss: 0.2478 - val_accuracy: 0.5625 - val_mse: 0.2478 - lr: 0.0010 - 165ms/epoch - 33ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2397 - accuracy: 0.5474 - mse: 0.2397 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 0.0010 - 166ms/epoch - 33ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2390 - accuracy: 0.6204 - mse: 0.2390 - val_loss: 0.2446 - val_accuracy: 0.5625 - val_mse: 0.2446 - lr: 0.0010 - 164ms/epoch - 33ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2318 - accuracy: 0.5766 - mse: 0.2318 - val_loss: 0.2464 - val_accuracy: 0.5625 - val_mse: 0.2464 - lr: 0.0010 - 171ms/epoch - 34ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2375 - accuracy: 0.5912 - mse: 0.2375 - val_loss: 0.2488 - val_accuracy: 0.5625 - val_mse: 0.2488 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2303 - accuracy: 0.6569 - mse: 0.2303 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 0.0010 - 180ms/epoch - 36ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2294 - accuracy: 0.6131 - mse: 0.2294 - val_loss: 0.2483 - val_accuracy: 0.5625 - val_mse: 0.2483 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2289 - accuracy: 0.6058 - mse: 0.2289 - val_loss: 0.2562 - val_accuracy: 0.5625 - val_mse: 0.2562 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2340 - accuracy: 0.5547 - mse: 0.2340 - val_loss: 0.2509 - val_accuracy: 0.5625 - val_mse: 0.2509 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2321 - accuracy: 0.5839 - mse: 0.2321 - val_loss: 0.2450 - val_accuracy: 0.5625 - val_mse: 0.2450 - lr: 0.0010 - 203ms/epoch - 41ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2306 - accuracy: 0.6058 - mse: 0.2306 - val_loss: 0.2506 - val_accuracy: 0.5625 - val_mse: 0.2506 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2290 - accuracy: 0.6204 - mse: 0.2290 - val_loss: 0.2492 - val_accuracy: 0.5625 - val_mse: 0.2492 - lr: 0.0010 - 169ms/epoch - 34ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2230 - accuracy: 0.6861 - mse: 0.2230 - val_loss: 0.2440 - val_accuracy: 0.5625 - val_mse: 0.2440 - lr: 0.0010 - 148ms/epoch - 30ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2199 - accuracy: 0.6715 - mse: 0.2199 - val_loss: 0.2452 - val_accuracy: 0.5625 - val_mse: 0.2452 - lr: 0.0010 - 151ms/epoch - 30ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2286 - accuracy: 0.5985 - mse: 0.2286 - val_loss: 0.2436 - val_accuracy: 0.5625 - val_mse: 0.2436 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2290 - accuracy: 0.6204 - mse: 0.2290 - val_loss: 0.2394 - val_accuracy: 0.5625 - val_mse: 0.2394 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2179 - accuracy: 0.6350 - mse: 0.2179 - val_loss: 0.2422 - val_accuracy: 0.5625 - val_mse: 0.2422 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2210 - accuracy: 0.6277 - mse: 0.2210 - val_loss: 0.2379 - val_accuracy: 0.5625 - val_mse: 0.2379 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2249 - accuracy: 0.6277 - mse: 0.2249 - val_loss: 0.2376 - val_accuracy: 0.5625 - val_mse: 0.2376 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2319 - accuracy: 0.6058 - mse: 0.2319 - val_loss: 0.2399 - val_accuracy: 0.5625 - val_mse: 0.2399 - lr: 0.0010 - 227ms/epoch - 45ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2194 - accuracy: 0.6496 - mse: 0.2194 - val_loss: 0.2300 - val_accuracy: 0.6250 - val_mse: 0.2300 - lr: 0.0010 - 185ms/epoch - 37ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2155 - accuracy: 0.6642 - mse: 0.2155 - val_loss: 0.2447 - val_accuracy: 0.5625 - val_mse: 0.2447 - lr: 0.0010 - 168ms/epoch - 34ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2150 - accuracy: 0.6277 - mse: 0.2150 - val_loss: 0.2315 - val_accuracy: 0.6250 - val_mse: 0.2315 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2162 - accuracy: 0.7153 - mse: 0.2162 - val_loss: 0.2315 - val_accuracy: 0.6250 - val_mse: 0.2315 - lr: 1.0000e-05 - 159ms/epoch - 32ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2090 - accuracy: 0.6350 - mse: 0.2090 - val_loss: 0.2316 - val_accuracy: 0.6250 - val_mse: 0.2316 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2052 - accuracy: 0.6934 - mse: 0.2052 - val_loss: 0.2318 - val_accuracy: 0.6250 - val_mse: 0.2318 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2031 - accuracy: 0.6569 - mse: 0.2031 - val_loss: 0.2320 - val_accuracy: 0.6250 - val_mse: 0.2320 - lr: 1.0000e-05 - 165ms/epoch - 33ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2118 - accuracy: 0.6569 - mse: 0.2118 - val_loss: 0.2322 - val_accuracy: 0.6250 - val_mse: 0.2322 - lr: 1.0000e-05 - 176ms/epoch - 35ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2142 - accuracy: 0.6496 - mse: 0.2142 - val_loss: 0.2323 - val_accuracy: 0.6250 - val_mse: 0.2323 - lr: 1.0000e-05 - 164ms/epoch - 33ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2048 - accuracy: 0.7226 - mse: 0.2048 - val_loss: 0.2325 - val_accuracy: 0.6250 - val_mse: 0.2325 - lr: 1.0000e-05 - 163ms/epoch - 33ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2077 - accuracy: 0.6715 - mse: 0.2077 - val_loss: 0.2328 - val_accuracy: 0.6250 - val_mse: 0.2328 - lr: 1.0000e-05 - 169ms/epoch - 34ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2047 - accuracy: 0.6934 - mse: 0.2047 - val_loss: 0.2331 - val_accuracy: 0.6250 - val_mse: 0.2331 - lr: 1.0000e-05 - 167ms/epoch - 33ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2091 - accuracy: 0.6715 - mse: 0.2091 - val_loss: 0.2334 - val_accuracy: 0.6250 - val_mse: 0.2334 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2063 - accuracy: 0.6861 - mse: 0.2063 - val_loss: 0.2338 - val_accuracy: 0.6250 - val_mse: 0.2338 - lr: 1.0000e-05 - 178ms/epoch - 36ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2063 - accuracy: 0.6934 - mse: 0.2063 - val_loss: 0.2341 - val_accuracy: 0.6250 - val_mse: 0.2341 - lr: 1.0000e-05 - 167ms/epoch - 33ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2183 - accuracy: 0.6715 - mse: 0.2183 - val_loss: 0.2344 - val_accuracy: 0.6250 - val_mse: 0.2344 - lr: 1.0000e-05 - 167ms/epoch - 33ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2041 - accuracy: 0.7372 - mse: 0.2041 - val_loss: 0.2347 - val_accuracy: 0.6250 - val_mse: 0.2347 - lr: 1.0000e-05 - 172ms/epoch - 34ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2124 - accuracy: 0.6496 - mse: 0.2124 - val_loss: 0.2350 - val_accuracy: 0.5625 - val_mse: 0.2350 - lr: 1.0000e-05 - 172ms/epoch - 34ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2003 - accuracy: 0.6861 - mse: 0.2003 - val_loss: 0.2351 - val_accuracy: 0.5625 - val_mse: 0.2351 - lr: 1.0000e-05 - 225ms/epoch - 45ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2143 - accuracy: 0.7153 - mse: 0.2143 - val_loss: 0.2353 - val_accuracy: 0.5625 - val_mse: 0.2353 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2259 - accuracy: 0.6111 - mse: 0.2259\n",
      "2/2 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6111\n",
      "Loss: 0.2259024977684021\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,978\n",
      "Trainable params: 42,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 8s - loss: 0.4176 - accuracy: 0.5000 - mse: 0.4176 - val_loss: 0.2683 - val_accuracy: 0.5625 - val_mse: 0.2683 - lr: 0.0010 - 8s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2816 - accuracy: 0.5588 - mse: 0.2816 - val_loss: 0.2959 - val_accuracy: 0.4375 - val_mse: 0.2959 - lr: 0.0010 - 144ms/epoch - 29ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2694 - accuracy: 0.5074 - mse: 0.2694 - val_loss: 0.2514 - val_accuracy: 0.4375 - val_mse: 0.2514 - lr: 0.0010 - 147ms/epoch - 29ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2507 - accuracy: 0.5074 - mse: 0.2507 - val_loss: 0.2497 - val_accuracy: 0.5625 - val_mse: 0.2497 - lr: 0.0010 - 146ms/epoch - 29ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2570 - accuracy: 0.5368 - mse: 0.2570 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 146ms/epoch - 29ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2520 - accuracy: 0.4926 - mse: 0.2520 - val_loss: 0.2455 - val_accuracy: 0.5625 - val_mse: 0.2455 - lr: 0.0010 - 213ms/epoch - 43ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2505 - accuracy: 0.5147 - mse: 0.2505 - val_loss: 0.2493 - val_accuracy: 0.5625 - val_mse: 0.2493 - lr: 0.0010 - 162ms/epoch - 32ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5956 - mse: 0.2478 - val_loss: 0.2482 - val_accuracy: 0.5625 - val_mse: 0.2482 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5588 - mse: 0.2469 - val_loss: 0.2449 - val_accuracy: 0.5625 - val_mse: 0.2449 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2497 - accuracy: 0.5662 - mse: 0.2497 - val_loss: 0.2438 - val_accuracy: 0.5625 - val_mse: 0.2438 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5662 - mse: 0.2486 - val_loss: 0.2439 - val_accuracy: 0.5625 - val_mse: 0.2439 - lr: 0.0010 - 164ms/epoch - 33ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5000 - mse: 0.2475 - val_loss: 0.2439 - val_accuracy: 0.5625 - val_mse: 0.2439 - lr: 0.0010 - 189ms/epoch - 38ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5368 - mse: 0.2498 - val_loss: 0.2439 - val_accuracy: 0.5625 - val_mse: 0.2439 - lr: 0.0010 - 174ms/epoch - 35ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2451 - accuracy: 0.5588 - mse: 0.2451 - val_loss: 0.2434 - val_accuracy: 0.5625 - val_mse: 0.2434 - lr: 0.0010 - 199ms/epoch - 40ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2436 - accuracy: 0.6029 - mse: 0.2436 - val_loss: 0.2429 - val_accuracy: 0.5625 - val_mse: 0.2429 - lr: 0.0010 - 266ms/epoch - 53ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5956 - mse: 0.2414 - val_loss: 0.2425 - val_accuracy: 0.5625 - val_mse: 0.2425 - lr: 0.0010 - 162ms/epoch - 32ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2429 - accuracy: 0.5956 - mse: 0.2429 - val_loss: 0.2421 - val_accuracy: 0.5625 - val_mse: 0.2421 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5368 - mse: 0.2455 - val_loss: 0.2421 - val_accuracy: 0.5625 - val_mse: 0.2421 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5515 - mse: 0.2472 - val_loss: 0.2419 - val_accuracy: 0.5625 - val_mse: 0.2419 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5809 - mse: 0.2418 - val_loss: 0.2411 - val_accuracy: 0.5625 - val_mse: 0.2411 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.6029 - mse: 0.2454 - val_loss: 0.2406 - val_accuracy: 0.5625 - val_mse: 0.2406 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5294 - mse: 0.2485 - val_loss: 0.2403 - val_accuracy: 0.5625 - val_mse: 0.2403 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2534 - accuracy: 0.5294 - mse: 0.2534 - val_loss: 0.2406 - val_accuracy: 0.5625 - val_mse: 0.2406 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5735 - mse: 0.2438 - val_loss: 0.2402 - val_accuracy: 0.5625 - val_mse: 0.2402 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.6029 - mse: 0.2406 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5515 - mse: 0.2446 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5515 - mse: 0.2472 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 152ms/epoch - 30ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5588 - mse: 0.2461 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5368 - mse: 0.2478 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 224ms/epoch - 45ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2374 - accuracy: 0.6176 - mse: 0.2374 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 165ms/epoch - 33ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2385 - accuracy: 0.5956 - mse: 0.2385 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 164ms/epoch - 33ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2449 - accuracy: 0.5662 - mse: 0.2449 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 163ms/epoch - 33ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2395 - accuracy: 0.5735 - mse: 0.2395 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 159ms/epoch - 32ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5735 - mse: 0.2412 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 164ms/epoch - 33ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2445 - accuracy: 0.5956 - mse: 0.2445 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2389 - accuracy: 0.6103 - mse: 0.2389 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2360 - accuracy: 0.5809 - mse: 0.2360 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 157ms/epoch - 31ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5735 - mse: 0.2452 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2358 - accuracy: 0.5882 - mse: 0.2358 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2382 - accuracy: 0.5515 - mse: 0.2382 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-05 - 157ms/epoch - 31ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2380 - accuracy: 0.6250 - mse: 0.2380 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 153ms/epoch - 31ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2305 - accuracy: 0.6544 - mse: 0.2305 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 154ms/epoch - 31ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2359 - accuracy: 0.6176 - mse: 0.2359 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 154ms/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2329 - accuracy: 0.6324 - mse: 0.2329 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 157ms/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2378 - accuracy: 0.5809 - mse: 0.2378 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 181ms/epoch - 36ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5294 - mse: 0.2416 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 175ms/epoch - 35ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2298 - accuracy: 0.6618 - mse: 0.2298 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 261ms/epoch - 52ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2372 - accuracy: 0.5735 - mse: 0.2372 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 175ms/epoch - 35ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2393 - accuracy: 0.6176 - mse: 0.2393 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 246ms/epoch - 49ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2354 - accuracy: 0.6618 - mse: 0.2354 - val_loss: 0.2386 - val_accuracy: 0.5625 - val_mse: 0.2386 - lr: 1.0000e-07 - 169ms/epoch - 34ms/step\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2454 - accuracy: 0.5833 - mse: 0.2454\n",
      "2/2 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833\n",
      "Loss: 0.24539653956890106\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,978\n",
      "Trainable params: 42,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 8s - loss: 0.4243 - accuracy: 0.5985 - mse: 0.4243 - val_loss: 0.2414 - val_accuracy: 0.6875 - val_mse: 0.2414 - lr: 0.0010 - 8s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2741 - accuracy: 0.5912 - mse: 0.2741 - val_loss: 0.2736 - val_accuracy: 0.6875 - val_mse: 0.2736 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2683 - accuracy: 0.5912 - mse: 0.2683 - val_loss: 0.2195 - val_accuracy: 0.6875 - val_mse: 0.2195 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5912 - mse: 0.2453 - val_loss: 0.2217 - val_accuracy: 0.6875 - val_mse: 0.2217 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5912 - mse: 0.2492 - val_loss: 0.2276 - val_accuracy: 0.6875 - val_mse: 0.2276 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2450 - accuracy: 0.5912 - mse: 0.2450 - val_loss: 0.2244 - val_accuracy: 0.6875 - val_mse: 0.2244 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5912 - mse: 0.2444 - val_loss: 0.2235 - val_accuracy: 0.6875 - val_mse: 0.2235 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2457 - accuracy: 0.5912 - mse: 0.2457 - val_loss: 0.2216 - val_accuracy: 0.6875 - val_mse: 0.2216 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5912 - mse: 0.2421 - val_loss: 0.2191 - val_accuracy: 0.6875 - val_mse: 0.2191 - lr: 0.0010 - 152ms/epoch - 30ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2407 - accuracy: 0.5912 - mse: 0.2407 - val_loss: 0.2206 - val_accuracy: 0.6875 - val_mse: 0.2206 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5912 - mse: 0.2414 - val_loss: 0.2219 - val_accuracy: 0.6875 - val_mse: 0.2219 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2402 - accuracy: 0.5912 - mse: 0.2402 - val_loss: 0.2219 - val_accuracy: 0.6875 - val_mse: 0.2219 - lr: 1.0000e-05 - 208ms/epoch - 42ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5912 - mse: 0.2425 - val_loss: 0.2218 - val_accuracy: 0.6875 - val_mse: 0.2218 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2400 - accuracy: 0.5912 - mse: 0.2400 - val_loss: 0.2218 - val_accuracy: 0.6875 - val_mse: 0.2218 - lr: 1.0000e-05 - 150ms/epoch - 30ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5912 - mse: 0.2418 - val_loss: 0.2217 - val_accuracy: 0.6875 - val_mse: 0.2217 - lr: 1.0000e-05 - 146ms/epoch - 29ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2408 - accuracy: 0.5912 - mse: 0.2408 - val_loss: 0.2216 - val_accuracy: 0.6875 - val_mse: 0.2216 - lr: 1.0000e-05 - 150ms/epoch - 30ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2435 - accuracy: 0.5912 - mse: 0.2435 - val_loss: 0.2216 - val_accuracy: 0.6875 - val_mse: 0.2216 - lr: 1.0000e-05 - 150ms/epoch - 30ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5912 - mse: 0.2427 - val_loss: 0.2215 - val_accuracy: 0.6875 - val_mse: 0.2215 - lr: 1.0000e-05 - 147ms/epoch - 29ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2388 - accuracy: 0.5912 - mse: 0.2388 - val_loss: 0.2214 - val_accuracy: 0.6875 - val_mse: 0.2214 - lr: 1.0000e-05 - 149ms/epoch - 30ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2403 - accuracy: 0.5912 - mse: 0.2403 - val_loss: 0.2214 - val_accuracy: 0.6875 - val_mse: 0.2214 - lr: 1.0000e-05 - 150ms/epoch - 30ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2403 - accuracy: 0.5912 - mse: 0.2403 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-05 - 150ms/epoch - 30ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 147ms/epoch - 29ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.5912 - mse: 0.2442 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 145ms/epoch - 29ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5912 - mse: 0.2423 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 148ms/epoch - 30ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2398 - accuracy: 0.5912 - mse: 0.2398 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 147ms/epoch - 29ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5912 - mse: 0.2416 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 145ms/epoch - 29ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2408 - accuracy: 0.5912 - mse: 0.2408 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 148ms/epoch - 30ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2450 - accuracy: 0.5912 - mse: 0.2450 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 146ms/epoch - 29ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5912 - mse: 0.2431 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 171ms/epoch - 34ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2422 - accuracy: 0.5912 - mse: 0.2422 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 146ms/epoch - 29ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5912 - mse: 0.2432 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-07 - 205ms/epoch - 41ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.5912 - mse: 0.2447 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 172ms/epoch - 34ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2449 - accuracy: 0.5912 - mse: 0.2449 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 169ms/epoch - 34ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5912 - mse: 0.2423 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 151ms/epoch - 30ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2394 - accuracy: 0.5912 - mse: 0.2394 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 160ms/epoch - 32ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5912 - mse: 0.2412 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 146ms/epoch - 29ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2436 - accuracy: 0.5912 - mse: 0.2436 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 210ms/epoch - 42ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2424 - accuracy: 0.5912 - mse: 0.2424 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 147ms/epoch - 29ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5912 - mse: 0.2452 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 150ms/epoch - 30ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5912 - mse: 0.2430 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 149ms/epoch - 30ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2445 - accuracy: 0.5912 - mse: 0.2445 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-09 - 152ms/epoch - 30ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5912 - mse: 0.2431 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-11 - 150ms/epoch - 30ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.5912 - mse: 0.2411 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-11 - 157ms/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2422 - accuracy: 0.5912 - mse: 0.2422 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-11 - 147ms/epoch - 29ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5912 - mse: 0.2455 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-11 - 149ms/epoch - 30ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2428 - accuracy: 0.5912 - mse: 0.2428 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-11 - 154ms/epoch - 31ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2389 - accuracy: 0.5912 - mse: 0.2389 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-11 - 156ms/epoch - 31ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2388 - accuracy: 0.5912 - mse: 0.2388 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-11 - 152ms/epoch - 30ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-11 - 146ms/epoch - 29ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5912 - mse: 0.2446 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 1.0000e-11 - 145ms/epoch - 29ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2678 - accuracy: 0.4722 - mse: 0.2678\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B5CEDC5DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B5CEDC5DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4722\n",
      "Loss: 0.26782897114753723\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,978\n",
      "Trainable params: 42,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 10s - loss: 0.4135 - accuracy: 0.5620 - mse: 0.4135 - val_loss: 0.2577 - val_accuracy: 0.6250 - val_mse: 0.2577 - lr: 0.0010 - 10s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2798 - accuracy: 0.5620 - mse: 0.2798 - val_loss: 0.2814 - val_accuracy: 0.6250 - val_mse: 0.2814 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2720 - accuracy: 0.5620 - mse: 0.2720 - val_loss: 0.2379 - val_accuracy: 0.6250 - val_mse: 0.2379 - lr: 0.0010 - 219ms/epoch - 44ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2513 - accuracy: 0.5620 - mse: 0.2513 - val_loss: 0.2402 - val_accuracy: 0.6250 - val_mse: 0.2402 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2568 - accuracy: 0.5620 - mse: 0.2568 - val_loss: 0.2389 - val_accuracy: 0.6250 - val_mse: 0.2389 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2510 - accuracy: 0.5620 - mse: 0.2510 - val_loss: 0.2353 - val_accuracy: 0.6250 - val_mse: 0.2353 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5620 - mse: 0.2487 - val_loss: 0.2375 - val_accuracy: 0.6250 - val_mse: 0.2375 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5620 - mse: 0.2480 - val_loss: 0.2369 - val_accuracy: 0.6250 - val_mse: 0.2369 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5620 - mse: 0.2474 - val_loss: 0.2353 - val_accuracy: 0.6250 - val_mse: 0.2353 - lr: 0.0010 - 157ms/epoch - 31ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5620 - mse: 0.2463 - val_loss: 0.2355 - val_accuracy: 0.6250 - val_mse: 0.2355 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5620 - mse: 0.2461 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5620 - mse: 0.2469 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 152ms/epoch - 30ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5620 - mse: 0.2491 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5620 - mse: 0.2468 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5620 - mse: 0.2498 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 152ms/epoch - 30ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5620 - mse: 0.2474 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 161ms/epoch - 32ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2460 - accuracy: 0.5620 - mse: 0.2460 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 153ms/epoch - 31ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5620 - mse: 0.2459 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5620 - mse: 0.2491 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 153ms/epoch - 31ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2505 - accuracy: 0.5620 - mse: 0.2505 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5620 - mse: 0.2470 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5620 - mse: 0.2474 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5620 - mse: 0.2466 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 157ms/epoch - 31ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5620 - mse: 0.2467 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5620 - mse: 0.2444 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 154ms/epoch - 31ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5620 - mse: 0.2463 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 157ms/epoch - 31ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2504 - accuracy: 0.5620 - mse: 0.2504 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 158ms/epoch - 32ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5620 - mse: 0.2440 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 153ms/epoch - 31ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5620 - mse: 0.2489 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 162ms/epoch - 32ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5620 - mse: 0.2453 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 154ms/epoch - 31ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5620 - mse: 0.2483 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-07 - 156ms/epoch - 31ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5620 - mse: 0.2456 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 158ms/epoch - 32ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5620 - mse: 0.2493 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 159ms/epoch - 32ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2502 - accuracy: 0.5620 - mse: 0.2502 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 155ms/epoch - 31ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2451 - accuracy: 0.5620 - mse: 0.2451 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 159ms/epoch - 32ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2506 - accuracy: 0.5620 - mse: 0.2506 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 157ms/epoch - 31ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5620 - mse: 0.2486 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 166ms/epoch - 33ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5620 - mse: 0.2444 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 153ms/epoch - 31ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2433 - accuracy: 0.5620 - mse: 0.2433 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 165ms/epoch - 33ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5620 - mse: 0.2479 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 157ms/epoch - 31ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5620 - mse: 0.2490 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-09 - 218ms/epoch - 44ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5620 - mse: 0.2463 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-11 - 160ms/epoch - 32ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5620 - mse: 0.2471 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-11 - 164ms/epoch - 33ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5620 - mse: 0.2475 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-11 - 162ms/epoch - 32ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5620 - mse: 0.2444 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-11 - 163ms/epoch - 33ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2435 - accuracy: 0.5620 - mse: 0.2435 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-11 - 161ms/epoch - 32ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2503 - accuracy: 0.5620 - mse: 0.2503 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-11 - 161ms/epoch - 32ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5620 - mse: 0.2473 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-11 - 158ms/epoch - 32ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5620 - mse: 0.2431 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-11 - 160ms/epoch - 32ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5620 - mse: 0.2479 - val_loss: 0.2356 - val_accuracy: 0.6250 - val_mse: 0.2356 - lr: 1.0000e-11 - 155ms/epoch - 31ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2151 - accuracy: 0.6944 - mse: 0.2151\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B5E1AD18B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B5E1AD18B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6944\n",
      "Loss: 0.21510370075702667\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,978\n",
      "Trainable params: 42,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 11s - loss: 0.4177 - accuracy: 0.5547 - mse: 0.4177 - val_loss: 0.2771 - val_accuracy: 0.5625 - val_mse: 0.2771 - lr: 0.0010 - 11s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2835 - accuracy: 0.5474 - mse: 0.2835 - val_loss: 0.2959 - val_accuracy: 0.5625 - val_mse: 0.2959 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2679 - accuracy: 0.5620 - mse: 0.2679 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 0.0010 - 154ms/epoch - 31ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2509 - accuracy: 0.5474 - mse: 0.2509 - val_loss: 0.2527 - val_accuracy: 0.5625 - val_mse: 0.2527 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2578 - accuracy: 0.5547 - mse: 0.2578 - val_loss: 0.2503 - val_accuracy: 0.5625 - val_mse: 0.2503 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2506 - accuracy: 0.5547 - mse: 0.2506 - val_loss: 0.2476 - val_accuracy: 0.5625 - val_mse: 0.2476 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2489 - val_accuracy: 0.5625 - val_mse: 0.2489 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5547 - mse: 0.2493 - val_loss: 0.2471 - val_accuracy: 0.5625 - val_mse: 0.2471 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5474 - mse: 0.2474 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5620 - mse: 0.2476 - val_loss: 0.2463 - val_accuracy: 0.5625 - val_mse: 0.2463 - lr: 0.0010 - 159ms/epoch - 32ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5547 - mse: 0.2490 - val_loss: 0.2465 - val_accuracy: 0.5625 - val_mse: 0.2465 - lr: 0.0010 - 153ms/epoch - 31ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2507 - accuracy: 0.5474 - mse: 0.2507 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 0.0010 - 155ms/epoch - 31ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5547 - mse: 0.2463 - val_loss: 0.2459 - val_accuracy: 0.5625 - val_mse: 0.2459 - lr: 0.0010 - 162ms/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5328 - mse: 0.2475 - val_loss: 0.2459 - val_accuracy: 0.5625 - val_mse: 0.2459 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5328 - mse: 0.2478 - val_loss: 0.2459 - val_accuracy: 0.5625 - val_mse: 0.2459 - lr: 1.0000e-05 - 162ms/epoch - 32ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5620 - mse: 0.2480 - val_loss: 0.2459 - val_accuracy: 0.5625 - val_mse: 0.2459 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5693 - mse: 0.2465 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 154ms/epoch - 31ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5547 - mse: 0.2467 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5693 - mse: 0.2454 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5474 - mse: 0.2491 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5693 - mse: 0.2471 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5401 - mse: 0.2469 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 153ms/epoch - 31ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5620 - mse: 0.2470 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 155ms/epoch - 31ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5401 - mse: 0.2474 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 159ms/epoch - 32ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.5474 - mse: 0.2500 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 162ms/epoch - 32ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2428 - accuracy: 0.5766 - mse: 0.2428 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 154ms/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2435 - accuracy: 0.5839 - mse: 0.2435 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 166ms/epoch - 33ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2429 - accuracy: 0.5620 - mse: 0.2429 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 161ms/epoch - 32ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5547 - mse: 0.2454 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 157ms/epoch - 31ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5474 - mse: 0.2459 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 154ms/epoch - 31ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5693 - mse: 0.2462 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5401 - mse: 0.2475 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5620 - mse: 0.2478 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 159ms/epoch - 32ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 159ms/epoch - 32ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5620 - mse: 0.2448 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 161ms/epoch - 32ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5693 - mse: 0.2481 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 154ms/epoch - 31ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5547 - mse: 0.2458 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 157ms/epoch - 31ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5547 - mse: 0.2465 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 163ms/epoch - 33ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5547 - mse: 0.2462 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 157ms/epoch - 31ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5474 - mse: 0.2488 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 220ms/epoch - 44ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5620 - mse: 0.2463 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 164ms/epoch - 33ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 162ms/epoch - 32ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5620 - mse: 0.2455 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 161ms/epoch - 32ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 179ms/epoch - 36ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5620 - mse: 0.2471 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 165ms/epoch - 33ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5766 - mse: 0.2474 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-07 - 165ms/epoch - 33ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2506 - accuracy: 0.5547 - mse: 0.2506 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-09 - 157ms/epoch - 31ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5693 - mse: 0.2485 - val_loss: 0.2458 - val_accuracy: 0.5625 - val_mse: 0.2458 - lr: 1.0000e-09 - 160ms/epoch - 32ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2542 - accuracy: 0.5000 - mse: 0.2542\n",
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Loss: 0.25419947504997253\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,978\n",
      "Trainable params: 42,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 9s - loss: 0.3997 - accuracy: 0.5547 - mse: 0.3997 - val_loss: 0.2747 - val_accuracy: 0.6250 - val_mse: 0.2747 - lr: 0.0010 - 9s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2844 - accuracy: 0.5401 - mse: 0.2844 - val_loss: 0.2964 - val_accuracy: 0.6250 - val_mse: 0.2964 - lr: 0.0010 - 163ms/epoch - 33ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2675 - accuracy: 0.4818 - mse: 0.2675 - val_loss: 0.2477 - val_accuracy: 0.6250 - val_mse: 0.2477 - lr: 0.0010 - 162ms/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2515 - accuracy: 0.5620 - mse: 0.2515 - val_loss: 0.2398 - val_accuracy: 0.6250 - val_mse: 0.2398 - lr: 0.0010 - 156ms/epoch - 31ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2582 - accuracy: 0.5547 - mse: 0.2582 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 0.0010 - 177ms/epoch - 35ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2524 - accuracy: 0.5547 - mse: 0.2524 - val_loss: 0.2372 - val_accuracy: 0.6250 - val_mse: 0.2372 - lr: 0.0010 - 178ms/epoch - 36ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5547 - mse: 0.2498 - val_loss: 0.2421 - val_accuracy: 0.6250 - val_mse: 0.2421 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2501 - accuracy: 0.5547 - mse: 0.2501 - val_loss: 0.2428 - val_accuracy: 0.6250 - val_mse: 0.2428 - lr: 0.0010 - 161ms/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5474 - mse: 0.2472 - val_loss: 0.2412 - val_accuracy: 0.6250 - val_mse: 0.2412 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5620 - mse: 0.2479 - val_loss: 0.2386 - val_accuracy: 0.6250 - val_mse: 0.2386 - lr: 0.0010 - 160ms/epoch - 32ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2375 - val_accuracy: 0.6250 - val_mse: 0.2375 - lr: 0.0010 - 164ms/epoch - 33ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5547 - mse: 0.2463 - val_loss: 0.2381 - val_accuracy: 0.6250 - val_mse: 0.2381 - lr: 0.0010 - 165ms/epoch - 33ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2391 - val_accuracy: 0.6250 - val_mse: 0.2391 - lr: 0.0010 - 158ms/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.5547 - mse: 0.2447 - val_loss: 0.2396 - val_accuracy: 0.6250 - val_mse: 0.2396 - lr: 0.0010 - 162ms/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5547 - mse: 0.2463 - val_loss: 0.2396 - val_accuracy: 0.6250 - val_mse: 0.2396 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5474 - mse: 0.2470 - val_loss: 0.2396 - val_accuracy: 0.6250 - val_mse: 0.2396 - lr: 1.0000e-05 - 165ms/epoch - 33ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5547 - mse: 0.2446 - val_loss: 0.2396 - val_accuracy: 0.6250 - val_mse: 0.2396 - lr: 1.0000e-05 - 165ms/epoch - 33ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2457 - accuracy: 0.5547 - mse: 0.2457 - val_loss: 0.2396 - val_accuracy: 0.6250 - val_mse: 0.2396 - lr: 1.0000e-05 - 161ms/epoch - 32ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5547 - mse: 0.2458 - val_loss: 0.2396 - val_accuracy: 0.6250 - val_mse: 0.2396 - lr: 1.0000e-05 - 156ms/epoch - 31ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5620 - mse: 0.2477 - val_loss: 0.2396 - val_accuracy: 0.6250 - val_mse: 0.2396 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2460 - accuracy: 0.5547 - mse: 0.2460 - val_loss: 0.2396 - val_accuracy: 0.6250 - val_mse: 0.2396 - lr: 1.0000e-05 - 160ms/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5474 - mse: 0.2465 - val_loss: 0.2396 - val_accuracy: 0.6250 - val_mse: 0.2396 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5547 - mse: 0.2452 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-05 - 164ms/epoch - 33ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5474 - mse: 0.2453 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-05 - 158ms/epoch - 32ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5474 - mse: 0.2488 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 236ms/epoch - 47ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5547 - mse: 0.2465 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 166ms/epoch - 33ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2443 - accuracy: 0.5474 - mse: 0.2443 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 158ms/epoch - 32ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5547 - mse: 0.2466 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 162ms/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 164ms/epoch - 33ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2428 - accuracy: 0.5620 - mse: 0.2428 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 160ms/epoch - 32ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.5547 - mse: 0.2442 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 158ms/epoch - 32ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.5547 - mse: 0.2447 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 159ms/epoch - 32ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 158ms/epoch - 32ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2437 - accuracy: 0.5620 - mse: 0.2437 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-07 - 171ms/epoch - 34ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2445 - accuracy: 0.5620 - mse: 0.2445 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 169ms/epoch - 34ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5547 - mse: 0.2452 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 177ms/epoch - 35ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5547 - mse: 0.2464 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 171ms/epoch - 34ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 177ms/epoch - 35ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2437 - accuracy: 0.5547 - mse: 0.2437 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 163ms/epoch - 33ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2439 - accuracy: 0.5474 - mse: 0.2439 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 160ms/epoch - 32ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5547 - mse: 0.2459 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 184ms/epoch - 37ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5620 - mse: 0.2458 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 160ms/epoch - 32ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5474 - mse: 0.2453 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 159ms/epoch - 32ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-09 - 161ms/epoch - 32ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5547 - mse: 0.2464 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-11 - 159ms/epoch - 32ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.5547 - mse: 0.2442 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-11 - 162ms/epoch - 32ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5620 - mse: 0.2458 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-11 - 164ms/epoch - 33ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5547 - mse: 0.2455 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-11 - 163ms/epoch - 33ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2443 - accuracy: 0.5474 - mse: 0.2443 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-11 - 157ms/epoch - 31ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2450 - accuracy: 0.5620 - mse: 0.2450 - val_loss: 0.2395 - val_accuracy: 0.6250 - val_mse: 0.2395 - lr: 1.0000e-11 - 160ms/epoch - 32ms/step\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2377 - accuracy: 0.6389 - mse: 0.2377\n",
      "2/2 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6389\n",
      "Loss: 0.23769420385360718\n"
     ]
    }
   ],
   "source": [
    "def train_model_5_2( xTrain, yTrain, xValid , yValid):\n",
    "    random.seed(26)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM( 32 ,input_shape = (19,92), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.3))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "    model.build()   \n",
    "    model.summary()\n",
    "    model.compile( optimizer = \"adam\" , loss = 'mean_squared_error' , metrics = ['accuracy', 'mse'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau( monitor = 'accuracy', factor = 0.01, patience=10, cooldown=0)\n",
    "    \n",
    "    callbacks = [ reduce_lr ]\n",
    "    train_history = model.fit( xTrain, yTrain , epochs = 50, shuffle=False, callbacks=callbacks, verbose = 2, validation_split = 0.1)\n",
    "\n",
    "    score = model.evaluate( xValid , yValid )\n",
    "    pred = model.predict(xValid)\n",
    "    model.save(\"LSTM_1\")\n",
    "    \n",
    "    print( \"Accuracy: {:0.4}\".format( score[1] ))\n",
    "    print( \"Loss:\", score[0] )\n",
    "    return score, pred, train_history\n",
    "\n",
    "results_2012, pred_2012, history_2012 = train_model_5_2(x_train_2012, y_train_2012_OHE, x_valid_2012, y_valid_2012_OHE) \n",
    "results_2013, pred_2013, history_2013 = train_model_5_2(x_train_2013, y_train_2013_OHE, x_valid_2013, y_valid_2013_OHE) \n",
    "results_2014, pred_2014, history_2014 = train_model_5_2(x_train_2014, y_train_2014_OHE, x_valid_2014, y_valid_2014_OHE) \n",
    "results_2015, pred_2015, history_2015 = train_model_5_2(x_train_2015, y_train_2015_OHE, x_valid_2015, y_valid_2015_OHE) \n",
    "results_2016, pred_2016, history_2016 = train_model_5_2(x_train_2016, y_train_2016_OHE, x_valid_2016, y_valid_2016_OHE) \n",
    "results_2017, pred_2017, history_2017 = train_model_5_2(x_train_2017, y_train_2017_OHE, x_valid_2017, y_valid_2017_OHE) \n",
    "results_2018, pred_2018, history_2018 = train_model_5_2(x_train_2018, y_train_2018_OHE, x_valid_2018, y_valid_2018_OHE) \n",
    "results_2019, pred_2019, history_2019 = train_model_5_2(x_train_2019, y_train_2019_OHE, x_valid_2019, y_valid_2019_OHE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,490\n",
      "Trainable params: 57,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 15s - loss: 0.4225 - accuracy: 0.4307 - mse: 0.4225 - val_loss: 0.2806 - val_accuracy: 0.7500 - val_mse: 0.2806 - lr: 0.0010 - 15s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2699 - accuracy: 0.4672 - mse: 0.2699 - val_loss: 0.2587 - val_accuracy: 0.2500 - val_mse: 0.2587 - lr: 0.0010 - 265ms/epoch - 53ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2606 - accuracy: 0.4526 - mse: 0.2606 - val_loss: 0.2602 - val_accuracy: 0.7500 - val_mse: 0.2602 - lr: 0.0010 - 294ms/epoch - 59ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2572 - accuracy: 0.5182 - mse: 0.2572 - val_loss: 0.2347 - val_accuracy: 0.7500 - val_mse: 0.2347 - lr: 0.0010 - 246ms/epoch - 49ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2504 - accuracy: 0.5255 - mse: 0.2504 - val_loss: 0.2495 - val_accuracy: 0.7500 - val_mse: 0.2495 - lr: 0.0010 - 253ms/epoch - 51ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2524 - accuracy: 0.4672 - mse: 0.2524 - val_loss: 0.2634 - val_accuracy: 0.2500 - val_mse: 0.2634 - lr: 0.0010 - 233ms/epoch - 47ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2521 - accuracy: 0.4453 - mse: 0.2521 - val_loss: 0.2513 - val_accuracy: 0.2500 - val_mse: 0.2513 - lr: 0.0010 - 227ms/epoch - 45ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2518 - accuracy: 0.4964 - mse: 0.2518 - val_loss: 0.2438 - val_accuracy: 0.7500 - val_mse: 0.2438 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2497 - accuracy: 0.5255 - mse: 0.2497 - val_loss: 0.2467 - val_accuracy: 0.7500 - val_mse: 0.2467 - lr: 0.0010 - 230ms/epoch - 46ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5182 - mse: 0.2498 - val_loss: 0.2526 - val_accuracy: 0.2500 - val_mse: 0.2526 - lr: 0.0010 - 234ms/epoch - 47ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.4745 - mse: 0.2500 - val_loss: 0.2553 - val_accuracy: 0.2500 - val_mse: 0.2553 - lr: 0.0010 - 242ms/epoch - 48ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2507 - accuracy: 0.4599 - mse: 0.2507 - val_loss: 0.2534 - val_accuracy: 0.2500 - val_mse: 0.2534 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5036 - mse: 0.2487 - val_loss: 0.2564 - val_accuracy: 0.2500 - val_mse: 0.2564 - lr: 0.0010 - 256ms/epoch - 51ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2499 - accuracy: 0.5036 - mse: 0.2499 - val_loss: 0.2615 - val_accuracy: 0.2500 - val_mse: 0.2615 - lr: 0.0010 - 265ms/epoch - 53ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5255 - mse: 0.2477 - val_loss: 0.2614 - val_accuracy: 0.2500 - val_mse: 0.2614 - lr: 0.0010 - 255ms/epoch - 51ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5328 - mse: 0.2452 - val_loss: 0.2615 - val_accuracy: 0.2500 - val_mse: 0.2615 - lr: 1.0000e-05 - 262ms/epoch - 52ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5839 - mse: 0.2463 - val_loss: 0.2618 - val_accuracy: 0.2500 - val_mse: 0.2618 - lr: 1.0000e-05 - 260ms/epoch - 52ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2621 - val_accuracy: 0.2500 - val_mse: 0.2621 - lr: 1.0000e-05 - 348ms/epoch - 70ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5985 - mse: 0.2458 - val_loss: 0.2623 - val_accuracy: 0.2500 - val_mse: 0.2623 - lr: 1.0000e-05 - 271ms/epoch - 54ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5474 - mse: 0.2465 - val_loss: 0.2626 - val_accuracy: 0.2500 - val_mse: 0.2626 - lr: 1.0000e-05 - 269ms/epoch - 54ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5912 - mse: 0.2468 - val_loss: 0.2629 - val_accuracy: 0.2500 - val_mse: 0.2629 - lr: 1.0000e-05 - 278ms/epoch - 56ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.6058 - mse: 0.2461 - val_loss: 0.2632 - val_accuracy: 0.2500 - val_mse: 0.2632 - lr: 1.0000e-05 - 270ms/epoch - 54ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2445 - accuracy: 0.5985 - mse: 0.2445 - val_loss: 0.2635 - val_accuracy: 0.2500 - val_mse: 0.2635 - lr: 1.0000e-05 - 249ms/epoch - 50ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5693 - mse: 0.2467 - val_loss: 0.2637 - val_accuracy: 0.2500 - val_mse: 0.2637 - lr: 1.0000e-05 - 260ms/epoch - 52ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5547 - mse: 0.2480 - val_loss: 0.2639 - val_accuracy: 0.2500 - val_mse: 0.2639 - lr: 1.0000e-05 - 238ms/epoch - 48ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5912 - mse: 0.2477 - val_loss: 0.2641 - val_accuracy: 0.2500 - val_mse: 0.2641 - lr: 1.0000e-05 - 243ms/epoch - 49ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.6058 - mse: 0.2455 - val_loss: 0.2644 - val_accuracy: 0.2500 - val_mse: 0.2644 - lr: 1.0000e-05 - 244ms/epoch - 49ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.6131 - mse: 0.2477 - val_loss: 0.2646 - val_accuracy: 0.2500 - val_mse: 0.2646 - lr: 1.0000e-05 - 276ms/epoch - 55ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.6058 - mse: 0.2454 - val_loss: 0.2648 - val_accuracy: 0.2500 - val_mse: 0.2648 - lr: 1.0000e-05 - 260ms/epoch - 52ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.6131 - mse: 0.2453 - val_loss: 0.2649 - val_accuracy: 0.2500 - val_mse: 0.2649 - lr: 1.0000e-05 - 345ms/epoch - 69ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.5985 - mse: 0.2447 - val_loss: 0.2650 - val_accuracy: 0.2500 - val_mse: 0.2650 - lr: 1.0000e-05 - 268ms/epoch - 54ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5255 - mse: 0.2496 - val_loss: 0.2652 - val_accuracy: 0.2500 - val_mse: 0.2652 - lr: 1.0000e-05 - 297ms/epoch - 59ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5401 - mse: 0.2485 - val_loss: 0.2654 - val_accuracy: 0.2500 - val_mse: 0.2654 - lr: 1.0000e-05 - 303ms/epoch - 61ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.6058 - mse: 0.2464 - val_loss: 0.2655 - val_accuracy: 0.2500 - val_mse: 0.2655 - lr: 1.0000e-05 - 256ms/epoch - 51ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5839 - mse: 0.2448 - val_loss: 0.2656 - val_accuracy: 0.2500 - val_mse: 0.2656 - lr: 1.0000e-05 - 258ms/epoch - 52ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5693 - mse: 0.2440 - val_loss: 0.2657 - val_accuracy: 0.2500 - val_mse: 0.2657 - lr: 1.0000e-05 - 262ms/epoch - 52ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2462 - accuracy: 0.5401 - mse: 0.2462 - val_loss: 0.2659 - val_accuracy: 0.2500 - val_mse: 0.2659 - lr: 1.0000e-05 - 261ms/epoch - 52ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.6131 - mse: 0.2452 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-05 - 259ms/epoch - 52ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5912 - mse: 0.2459 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 310ms/epoch - 62ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2460 - accuracy: 0.5766 - mse: 0.2460 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 329ms/epoch - 66ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5547 - mse: 0.2485 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 277ms/epoch - 55ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5547 - mse: 0.2489 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 247ms/epoch - 49ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5839 - mse: 0.2465 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 241ms/epoch - 48ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2500 - accuracy: 0.5474 - mse: 0.2500 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 246ms/epoch - 49ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5766 - mse: 0.2464 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 254ms/epoch - 51ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5328 - mse: 0.2485 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 242ms/epoch - 48ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5766 - mse: 0.2456 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 241ms/epoch - 48ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5474 - mse: 0.2475 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-07 - 283ms/epoch - 57ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5766 - mse: 0.2469 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-09 - 245ms/epoch - 49ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5912 - mse: 0.2474 - val_loss: 0.2660 - val_accuracy: 0.2500 - val_mse: 0.2660 - lr: 1.0000e-09 - 242ms/epoch - 48ms/step\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2523 - accuracy: 0.4444 - mse: 0.2523\n",
      "2/2 [==============================] - 2s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4444\n",
      "Loss: 0.25230279564857483\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,490\n",
      "Trainable params: 57,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 29s - loss: 0.4212 - accuracy: 0.4745 - mse: 0.4212 - val_loss: 0.2966 - val_accuracy: 0.5000 - val_mse: 0.2966 - lr: 0.0010 - 29s/epoch - 6s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2688 - accuracy: 0.5693 - mse: 0.2688 - val_loss: 0.2694 - val_accuracy: 0.5000 - val_mse: 0.2694 - lr: 0.0010 - 245ms/epoch - 49ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2553 - accuracy: 0.5693 - mse: 0.2553 - val_loss: 0.2786 - val_accuracy: 0.5000 - val_mse: 0.2786 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2571 - accuracy: 0.5693 - mse: 0.2571 - val_loss: 0.2837 - val_accuracy: 0.5000 - val_mse: 0.2837 - lr: 0.0010 - 257ms/epoch - 51ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2555 - accuracy: 0.5693 - mse: 0.2555 - val_loss: 0.2763 - val_accuracy: 0.5000 - val_mse: 0.2763 - lr: 0.0010 - 240ms/epoch - 48ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2511 - accuracy: 0.5693 - mse: 0.2511 - val_loss: 0.2617 - val_accuracy: 0.5000 - val_mse: 0.2617 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5693 - mse: 0.2465 - val_loss: 0.2635 - val_accuracy: 0.5000 - val_mse: 0.2635 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5693 - mse: 0.2444 - val_loss: 0.2738 - val_accuracy: 0.5000 - val_mse: 0.2738 - lr: 0.0010 - 235ms/epoch - 47ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5693 - mse: 0.2479 - val_loss: 0.2728 - val_accuracy: 0.5000 - val_mse: 0.2728 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5693 - mse: 0.2472 - val_loss: 0.2719 - val_accuracy: 0.5000 - val_mse: 0.2719 - lr: 0.0010 - 260ms/epoch - 52ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2439 - accuracy: 0.5693 - mse: 0.2439 - val_loss: 0.2830 - val_accuracy: 0.5000 - val_mse: 0.2830 - lr: 0.0010 - 238ms/epoch - 48ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5620 - mse: 0.2461 - val_loss: 0.2849 - val_accuracy: 0.5000 - val_mse: 0.2849 - lr: 0.0010 - 235ms/epoch - 47ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2452 - accuracy: 0.5693 - mse: 0.2452 - val_loss: 0.2849 - val_accuracy: 0.5000 - val_mse: 0.2849 - lr: 1.0000e-05 - 240ms/epoch - 48ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5985 - mse: 0.2454 - val_loss: 0.2851 - val_accuracy: 0.5000 - val_mse: 0.2851 - lr: 1.0000e-05 - 240ms/epoch - 48ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5620 - mse: 0.2466 - val_loss: 0.2853 - val_accuracy: 0.5000 - val_mse: 0.2853 - lr: 1.0000e-05 - 234ms/epoch - 47ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2458 - accuracy: 0.5474 - mse: 0.2458 - val_loss: 0.2856 - val_accuracy: 0.5000 - val_mse: 0.2856 - lr: 1.0000e-05 - 246ms/epoch - 49ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2449 - accuracy: 0.6131 - mse: 0.2449 - val_loss: 0.2858 - val_accuracy: 0.5000 - val_mse: 0.2858 - lr: 1.0000e-05 - 234ms/epoch - 47ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2456 - accuracy: 0.5474 - mse: 0.2456 - val_loss: 0.2861 - val_accuracy: 0.5000 - val_mse: 0.2861 - lr: 1.0000e-05 - 241ms/epoch - 48ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2445 - accuracy: 0.5766 - mse: 0.2445 - val_loss: 0.2864 - val_accuracy: 0.5000 - val_mse: 0.2864 - lr: 1.0000e-05 - 236ms/epoch - 47ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2450 - accuracy: 0.5912 - mse: 0.2450 - val_loss: 0.2867 - val_accuracy: 0.5000 - val_mse: 0.2867 - lr: 1.0000e-05 - 238ms/epoch - 48ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5620 - mse: 0.2448 - val_loss: 0.2869 - val_accuracy: 0.5000 - val_mse: 0.2869 - lr: 1.0000e-05 - 240ms/epoch - 48ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5839 - mse: 0.2473 - val_loss: 0.2870 - val_accuracy: 0.5000 - val_mse: 0.2870 - lr: 1.0000e-05 - 240ms/epoch - 48ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5620 - mse: 0.2446 - val_loss: 0.2872 - val_accuracy: 0.5000 - val_mse: 0.2872 - lr: 1.0000e-05 - 237ms/epoch - 47ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5401 - mse: 0.2485 - val_loss: 0.2872 - val_accuracy: 0.5000 - val_mse: 0.2872 - lr: 1.0000e-05 - 235ms/epoch - 47ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2445 - accuracy: 0.5547 - mse: 0.2445 - val_loss: 0.2872 - val_accuracy: 0.5000 - val_mse: 0.2872 - lr: 1.0000e-05 - 233ms/epoch - 47ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.5839 - mse: 0.2442 - val_loss: 0.2872 - val_accuracy: 0.5000 - val_mse: 0.2872 - lr: 1.0000e-05 - 234ms/epoch - 47ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5839 - mse: 0.2446 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-05 - 245ms/epoch - 49ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5912 - mse: 0.2420 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 255ms/epoch - 51ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5839 - mse: 0.2465 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 248ms/epoch - 50ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5401 - mse: 0.2464 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.5693 - mse: 0.2406 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 250ms/epoch - 50ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5985 - mse: 0.2430 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.6131 - mse: 0.2444 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 238ms/epoch - 48ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5620 - mse: 0.2492 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 242ms/epoch - 48ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5912 - mse: 0.2440 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 236ms/epoch - 47ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2437 - accuracy: 0.5547 - mse: 0.2437 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 231ms/epoch - 46ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-07 - 297ms/epoch - 59ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2451 - accuracy: 0.5620 - mse: 0.2451 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 238ms/epoch - 48ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5766 - mse: 0.2481 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 241ms/epoch - 48ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2410 - accuracy: 0.5766 - mse: 0.2410 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 235ms/epoch - 47ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5766 - mse: 0.2483 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 235ms/epoch - 47ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2433 - accuracy: 0.5912 - mse: 0.2433 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 240ms/epoch - 48ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5912 - mse: 0.2453 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 271ms/epoch - 54ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5912 - mse: 0.2472 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 262ms/epoch - 52ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5620 - mse: 0.2481 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 236ms/epoch - 47ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5620 - mse: 0.2446 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 267ms/epoch - 53ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5401 - mse: 0.2463 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-09 - 239ms/epoch - 48ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2436 - accuracy: 0.5912 - mse: 0.2436 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-11 - 236ms/epoch - 47ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5839 - mse: 0.2470 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-11 - 240ms/epoch - 48ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2874 - val_accuracy: 0.5000 - val_mse: 0.2874 - lr: 1.0000e-11 - 239ms/epoch - 48ms/step\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2516 - accuracy: 0.5833 - mse: 0.2516\n",
      "2/2 [==============================] - 3s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_23_layer_call_fn, lstm_cell_23_layer_call_and_return_conditional_losses, lstm_cell_24_layer_call_fn, lstm_cell_24_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833\n",
      "Loss: 0.2515908181667328\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_26 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,490\n",
      "Trainable params: 57,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 13s - loss: 0.4216 - accuracy: 0.4526 - mse: 0.4216 - val_loss: 0.2788 - val_accuracy: 0.5625 - val_mse: 0.2788 - lr: 0.0010 - 13s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2620 - accuracy: 0.5693 - mse: 0.2620 - val_loss: 0.2525 - val_accuracy: 0.5625 - val_mse: 0.2525 - lr: 0.0010 - 253ms/epoch - 51ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2555 - accuracy: 0.5693 - mse: 0.2555 - val_loss: 0.2571 - val_accuracy: 0.5625 - val_mse: 0.2571 - lr: 0.0010 - 255ms/epoch - 51ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2520 - accuracy: 0.5693 - mse: 0.2520 - val_loss: 0.2490 - val_accuracy: 0.5625 - val_mse: 0.2490 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5693 - mse: 0.2483 - val_loss: 0.2473 - val_accuracy: 0.5625 - val_mse: 0.2473 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5693 - mse: 0.2487 - val_loss: 0.2469 - val_accuracy: 0.5625 - val_mse: 0.2469 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5693 - mse: 0.2454 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2455 - accuracy: 0.5693 - mse: 0.2455 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5693 - mse: 0.2453 - val_loss: 0.2465 - val_accuracy: 0.5625 - val_mse: 0.2465 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5693 - mse: 0.2440 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 244ms/epoch - 49ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2445 - accuracy: 0.5693 - mse: 0.2445 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5693 - mse: 0.2440 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 0.0010 - 235ms/epoch - 47ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5693 - mse: 0.2420 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 239ms/epoch - 48ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2429 - accuracy: 0.5693 - mse: 0.2429 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 240ms/epoch - 48ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5693 - mse: 0.2430 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 241ms/epoch - 48ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5693 - mse: 0.2420 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 240ms/epoch - 48ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2422 - accuracy: 0.5693 - mse: 0.2422 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 238ms/epoch - 48ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5693 - mse: 0.2431 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 237ms/epoch - 47ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2437 - accuracy: 0.5693 - mse: 0.2437 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 239ms/epoch - 48ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2443 - accuracy: 0.5693 - mse: 0.2443 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 237ms/epoch - 47ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5693 - mse: 0.2425 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 238ms/epoch - 48ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2441 - accuracy: 0.5693 - mse: 0.2441 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 240ms/epoch - 48ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5693 - mse: 0.2431 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 242ms/epoch - 48ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5693 - mse: 0.2412 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 240ms/epoch - 48ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5693 - mse: 0.2427 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 248ms/epoch - 50ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2431 - accuracy: 0.5693 - mse: 0.2431 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 237ms/epoch - 47ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2435 - accuracy: 0.5693 - mse: 0.2435 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 240ms/epoch - 48ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2439 - accuracy: 0.5693 - mse: 0.2439 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 240ms/epoch - 48ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5693 - mse: 0.2421 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 252ms/epoch - 50ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5693 - mse: 0.2454 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 238ms/epoch - 48ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5693 - mse: 0.2421 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 236ms/epoch - 47ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2432 - accuracy: 0.5693 - mse: 0.2432 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-07 - 239ms/epoch - 48ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5693 - mse: 0.2430 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 237ms/epoch - 47ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2438 - accuracy: 0.5693 - mse: 0.2438 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 240ms/epoch - 48ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5693 - mse: 0.2440 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 294ms/epoch - 59ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5693 - mse: 0.2425 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 237ms/epoch - 47ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2439 - accuracy: 0.5693 - mse: 0.2439 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 266ms/epoch - 53ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2446 - accuracy: 0.5693 - mse: 0.2446 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 241ms/epoch - 48ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2419 - accuracy: 0.5693 - mse: 0.2419 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 238ms/epoch - 48ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5693 - mse: 0.2425 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 236ms/epoch - 47ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2437 - accuracy: 0.5693 - mse: 0.2437 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 234ms/epoch - 47ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2404 - accuracy: 0.5693 - mse: 0.2404 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-09 - 235ms/epoch - 47ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2430 - accuracy: 0.5693 - mse: 0.2430 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-11 - 237ms/epoch - 47ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2429 - accuracy: 0.5693 - mse: 0.2429 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-11 - 242ms/epoch - 48ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2448 - accuracy: 0.5693 - mse: 0.2448 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-11 - 237ms/epoch - 47ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2429 - accuracy: 0.5693 - mse: 0.2429 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-11 - 235ms/epoch - 47ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2450 - accuracy: 0.5693 - mse: 0.2450 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-11 - 242ms/epoch - 48ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2440 - accuracy: 0.5693 - mse: 0.2440 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-11 - 236ms/epoch - 47ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.5693 - mse: 0.2447 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-11 - 239ms/epoch - 48ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2421 - accuracy: 0.5693 - mse: 0.2421 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-11 - 240ms/epoch - 48ms/step\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2479 - accuracy: 0.5556 - mse: 0.2479\n",
      "2/2 [==============================] - 2s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_27_layer_call_fn, lstm_cell_27_layer_call_and_return_conditional_losses, lstm_cell_28_layer_call_fn, lstm_cell_28_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5556\n",
      "Loss: 0.2479153722524643\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,490\n",
      "Trainable params: 57,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 13s - loss: 0.4260 - accuracy: 0.4265 - mse: 0.4260 - val_loss: 0.2789 - val_accuracy: 0.5625 - val_mse: 0.2789 - lr: 0.0010 - 13s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2656 - accuracy: 0.5147 - mse: 0.2656 - val_loss: 0.2565 - val_accuracy: 0.5625 - val_mse: 0.2565 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2614 - accuracy: 0.5000 - mse: 0.2614 - val_loss: 0.2584 - val_accuracy: 0.5625 - val_mse: 0.2584 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2571 - accuracy: 0.5000 - mse: 0.2571 - val_loss: 0.2464 - val_accuracy: 0.5625 - val_mse: 0.2464 - lr: 0.0010 - 238ms/epoch - 48ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2524 - accuracy: 0.4853 - mse: 0.2524 - val_loss: 0.2525 - val_accuracy: 0.4375 - val_mse: 0.2525 - lr: 0.0010 - 252ms/epoch - 50ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2525 - accuracy: 0.5000 - mse: 0.2525 - val_loss: 0.2488 - val_accuracy: 0.5625 - val_mse: 0.2488 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2510 - accuracy: 0.5221 - mse: 0.2510 - val_loss: 0.2470 - val_accuracy: 0.5625 - val_mse: 0.2470 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2522 - accuracy: 0.4779 - mse: 0.2522 - val_loss: 0.2485 - val_accuracy: 0.5625 - val_mse: 0.2485 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2519 - accuracy: 0.4853 - mse: 0.2519 - val_loss: 0.2473 - val_accuracy: 0.5625 - val_mse: 0.2473 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2510 - accuracy: 0.5074 - mse: 0.2510 - val_loss: 0.2470 - val_accuracy: 0.5625 - val_mse: 0.2470 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2499 - accuracy: 0.5221 - mse: 0.2499 - val_loss: 0.2472 - val_accuracy: 0.5625 - val_mse: 0.2472 - lr: 0.0010 - 245ms/epoch - 49ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2504 - accuracy: 0.5000 - mse: 0.2504 - val_loss: 0.2472 - val_accuracy: 0.5625 - val_mse: 0.2472 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5441 - mse: 0.2490 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 244ms/epoch - 49ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5441 - mse: 0.2487 - val_loss: 0.2464 - val_accuracy: 0.5625 - val_mse: 0.2464 - lr: 0.0010 - 238ms/epoch - 48ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5662 - mse: 0.2493 - val_loss: 0.2465 - val_accuracy: 0.5625 - val_mse: 0.2465 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2515 - accuracy: 0.5000 - mse: 0.2515 - val_loss: 0.2465 - val_accuracy: 0.5625 - val_mse: 0.2465 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2508 - accuracy: 0.5221 - mse: 0.2508 - val_loss: 0.2466 - val_accuracy: 0.5625 - val_mse: 0.2466 - lr: 0.0010 - 236ms/epoch - 47ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2495 - accuracy: 0.5368 - mse: 0.2495 - val_loss: 0.2465 - val_accuracy: 0.5625 - val_mse: 0.2465 - lr: 0.0010 - 238ms/epoch - 48ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5074 - mse: 0.2489 - val_loss: 0.2472 - val_accuracy: 0.5625 - val_mse: 0.2472 - lr: 0.0010 - 281ms/epoch - 56ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5441 - mse: 0.2474 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5294 - mse: 0.2488 - val_loss: 0.2480 - val_accuracy: 0.5625 - val_mse: 0.2480 - lr: 0.0010 - 235ms/epoch - 47ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5588 - mse: 0.2477 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5809 - mse: 0.2473 - val_loss: 0.2487 - val_accuracy: 0.5625 - val_mse: 0.2487 - lr: 0.0010 - 237ms/epoch - 47ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2503 - accuracy: 0.5368 - mse: 0.2503 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 0.0010 - 241ms/epoch - 48ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2494 - accuracy: 0.4853 - mse: 0.2494 - val_loss: 0.2464 - val_accuracy: 0.5625 - val_mse: 0.2464 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5147 - mse: 0.2487 - val_loss: 0.2464 - val_accuracy: 0.5625 - val_mse: 0.2464 - lr: 0.0010 - 268ms/epoch - 54ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2450 - accuracy: 0.5662 - mse: 0.2450 - val_loss: 0.2464 - val_accuracy: 0.5625 - val_mse: 0.2464 - lr: 0.0010 - 235ms/epoch - 47ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5074 - mse: 0.2483 - val_loss: 0.2465 - val_accuracy: 0.5625 - val_mse: 0.2465 - lr: 0.0010 - 242ms/epoch - 48ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5368 - mse: 0.2498 - val_loss: 0.2472 - val_accuracy: 0.5625 - val_mse: 0.2472 - lr: 0.0010 - 268ms/epoch - 54ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5368 - mse: 0.2486 - val_loss: 0.2471 - val_accuracy: 0.5625 - val_mse: 0.2471 - lr: 0.0010 - 240ms/epoch - 48ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5368 - mse: 0.2490 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 229ms/epoch - 46ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5221 - mse: 0.2454 - val_loss: 0.2484 - val_accuracy: 0.5625 - val_mse: 0.2484 - lr: 0.0010 - 238ms/epoch - 48ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2508 - accuracy: 0.5221 - mse: 0.2508 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 0.0010 - 300ms/epoch - 60ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5147 - mse: 0.2480 - val_loss: 0.2467 - val_accuracy: 0.5625 - val_mse: 0.2467 - lr: 1.0000e-05 - 234ms/epoch - 47ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2444 - accuracy: 0.5441 - mse: 0.2444 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 241ms/epoch - 48ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2429 - accuracy: 0.5588 - mse: 0.2429 - val_loss: 0.2468 - val_accuracy: 0.5625 - val_mse: 0.2468 - lr: 1.0000e-05 - 237ms/epoch - 47ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5588 - mse: 0.2475 - val_loss: 0.2469 - val_accuracy: 0.5625 - val_mse: 0.2469 - lr: 1.0000e-05 - 237ms/epoch - 47ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5515 - mse: 0.2469 - val_loss: 0.2469 - val_accuracy: 0.5625 - val_mse: 0.2469 - lr: 1.0000e-05 - 239ms/epoch - 48ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2449 - accuracy: 0.5956 - mse: 0.2449 - val_loss: 0.2470 - val_accuracy: 0.5625 - val_mse: 0.2470 - lr: 1.0000e-05 - 239ms/epoch - 48ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2434 - accuracy: 0.5515 - mse: 0.2434 - val_loss: 0.2471 - val_accuracy: 0.5625 - val_mse: 0.2471 - lr: 1.0000e-05 - 241ms/epoch - 48ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5074 - mse: 0.2493 - val_loss: 0.2471 - val_accuracy: 0.5625 - val_mse: 0.2471 - lr: 1.0000e-05 - 238ms/epoch - 48ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2435 - accuracy: 0.5735 - mse: 0.2435 - val_loss: 0.2472 - val_accuracy: 0.5625 - val_mse: 0.2472 - lr: 1.0000e-05 - 245ms/epoch - 49ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2453 - accuracy: 0.5515 - mse: 0.2453 - val_loss: 0.2472 - val_accuracy: 0.5625 - val_mse: 0.2472 - lr: 1.0000e-05 - 297ms/epoch - 59ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2520 - accuracy: 0.4779 - mse: 0.2520 - val_loss: 0.2473 - val_accuracy: 0.5625 - val_mse: 0.2473 - lr: 1.0000e-05 - 312ms/epoch - 62ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2502 - accuracy: 0.5221 - mse: 0.2502 - val_loss: 0.2473 - val_accuracy: 0.5625 - val_mse: 0.2473 - lr: 1.0000e-05 - 306ms/epoch - 61ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5515 - mse: 0.2479 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-05 - 302ms/epoch - 60ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2449 - accuracy: 0.6176 - mse: 0.2449 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-05 - 317ms/epoch - 63ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5368 - mse: 0.2488 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-05 - 403ms/epoch - 81ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5441 - mse: 0.2454 - val_loss: 0.2474 - val_accuracy: 0.5625 - val_mse: 0.2474 - lr: 1.0000e-05 - 326ms/epoch - 65ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2459 - accuracy: 0.5221 - mse: 0.2459 - val_loss: 0.2475 - val_accuracy: 0.5625 - val_mse: 0.2475 - lr: 1.0000e-05 - 321ms/epoch - 64ms/step\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2429 - accuracy: 0.5833 - mse: 0.2429\n",
      "2/2 [==============================] - 3s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_31_layer_call_fn, lstm_cell_31_layer_call_and_return_conditional_losses, lstm_cell_32_layer_call_fn, lstm_cell_32_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833\n",
      "Loss: 0.2429409623146057\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_34 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,490\n",
      "Trainable params: 57,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 15s - loss: 0.4238 - accuracy: 0.5255 - mse: 0.4238 - val_loss: 0.2646 - val_accuracy: 0.6875 - val_mse: 0.2646 - lr: 0.0010 - 15s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2652 - accuracy: 0.5912 - mse: 0.2652 - val_loss: 0.2318 - val_accuracy: 0.6875 - val_mse: 0.2318 - lr: 0.0010 - 276ms/epoch - 55ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2525 - accuracy: 0.5912 - mse: 0.2525 - val_loss: 0.2331 - val_accuracy: 0.6875 - val_mse: 0.2331 - lr: 0.0010 - 246ms/epoch - 49ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2532 - accuracy: 0.5912 - mse: 0.2532 - val_loss: 0.2183 - val_accuracy: 0.6875 - val_mse: 0.2183 - lr: 0.0010 - 252ms/epoch - 50ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2454 - accuracy: 0.5912 - mse: 0.2454 - val_loss: 0.2296 - val_accuracy: 0.6875 - val_mse: 0.2296 - lr: 0.0010 - 241ms/epoch - 48ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5912 - mse: 0.2426 - val_loss: 0.2312 - val_accuracy: 0.6875 - val_mse: 0.2312 - lr: 0.0010 - 245ms/epoch - 49ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2442 - accuracy: 0.5912 - mse: 0.2442 - val_loss: 0.2213 - val_accuracy: 0.6875 - val_mse: 0.2213 - lr: 0.0010 - 248ms/epoch - 50ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2434 - accuracy: 0.5912 - mse: 0.2434 - val_loss: 0.2232 - val_accuracy: 0.6875 - val_mse: 0.2232 - lr: 0.0010 - 311ms/epoch - 62ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2426 - accuracy: 0.5912 - mse: 0.2426 - val_loss: 0.2251 - val_accuracy: 0.6875 - val_mse: 0.2251 - lr: 0.0010 - 251ms/epoch - 50ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2227 - val_accuracy: 0.6875 - val_mse: 0.2227 - lr: 0.0010 - 245ms/epoch - 49ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2425 - accuracy: 0.5912 - mse: 0.2425 - val_loss: 0.2225 - val_accuracy: 0.6875 - val_mse: 0.2225 - lr: 0.0010 - 251ms/epoch - 50ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5912 - mse: 0.2418 - val_loss: 0.2252 - val_accuracy: 0.6875 - val_mse: 0.2252 - lr: 0.0010 - 300ms/epoch - 60ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.5912 - mse: 0.2409 - val_loss: 0.2252 - val_accuracy: 0.6875 - val_mse: 0.2252 - lr: 1.0000e-05 - 245ms/epoch - 49ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2427 - accuracy: 0.5912 - mse: 0.2427 - val_loss: 0.2251 - val_accuracy: 0.6875 - val_mse: 0.2251 - lr: 1.0000e-05 - 245ms/epoch - 49ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.5912 - mse: 0.2411 - val_loss: 0.2251 - val_accuracy: 0.6875 - val_mse: 0.2251 - lr: 1.0000e-05 - 253ms/epoch - 51ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5912 - mse: 0.2414 - val_loss: 0.2250 - val_accuracy: 0.6875 - val_mse: 0.2250 - lr: 1.0000e-05 - 239ms/epoch - 48ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2249 - val_accuracy: 0.6875 - val_mse: 0.2249 - lr: 1.0000e-05 - 245ms/epoch - 49ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2247 - val_accuracy: 0.6875 - val_mse: 0.2247 - lr: 1.0000e-05 - 253ms/epoch - 51ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2246 - val_accuracy: 0.6875 - val_mse: 0.2246 - lr: 1.0000e-05 - 256ms/epoch - 51ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2420 - accuracy: 0.5912 - mse: 0.2420 - val_loss: 0.2245 - val_accuracy: 0.6875 - val_mse: 0.2245 - lr: 1.0000e-05 - 270ms/epoch - 54ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5912 - mse: 0.2414 - val_loss: 0.2244 - val_accuracy: 0.6875 - val_mse: 0.2244 - lr: 1.0000e-05 - 262ms/epoch - 52ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.5912 - mse: 0.2406 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-05 - 247ms/epoch - 49ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5912 - mse: 0.2414 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 286ms/epoch - 57ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 288ms/epoch - 58ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 313ms/epoch - 63ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5912 - mse: 0.2418 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 413ms/epoch - 83ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5912 - mse: 0.2418 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 309ms/epoch - 62ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2406 - accuracy: 0.5912 - mse: 0.2406 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 369ms/epoch - 74ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 375ms/epoch - 75ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5912 - mse: 0.2418 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 326ms/epoch - 65ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2408 - accuracy: 0.5912 - mse: 0.2408 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 386ms/epoch - 77ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5912 - mse: 0.2412 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-07 - 335ms/epoch - 67ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2419 - accuracy: 0.5912 - mse: 0.2419 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 296ms/epoch - 59ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2416 - accuracy: 0.5912 - mse: 0.2416 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 315ms/epoch - 63ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2414 - accuracy: 0.5912 - mse: 0.2414 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 314ms/epoch - 63ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 362ms/epoch - 72ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2424 - accuracy: 0.5912 - mse: 0.2424 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 308ms/epoch - 62ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5912 - mse: 0.2412 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 323ms/epoch - 65ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2415 - accuracy: 0.5912 - mse: 0.2415 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 310ms/epoch - 62ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.5912 - mse: 0.2411 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 301ms/epoch - 60ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2418 - accuracy: 0.5912 - mse: 0.2418 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 319ms/epoch - 64ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2409 - accuracy: 0.5912 - mse: 0.2409 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-09 - 350ms/epoch - 70ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2423 - accuracy: 0.5912 - mse: 0.2423 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-11 - 318ms/epoch - 64ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2411 - accuracy: 0.5912 - mse: 0.2411 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-11 - 359ms/epoch - 72ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2410 - accuracy: 0.5912 - mse: 0.2410 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-11 - 306ms/epoch - 61ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2413 - accuracy: 0.5912 - mse: 0.2413 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-11 - 286ms/epoch - 57ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2417 - accuracy: 0.5912 - mse: 0.2417 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-11 - 418ms/epoch - 84ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2412 - accuracy: 0.5912 - mse: 0.2412 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-11 - 328ms/epoch - 66ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 1s - loss: 0.2417 - accuracy: 0.5912 - mse: 0.2417 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-11 - 553ms/epoch - 111ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2410 - accuracy: 0.5912 - mse: 0.2410 - val_loss: 0.2243 - val_accuracy: 0.6875 - val_mse: 0.2243 - lr: 1.0000e-11 - 341ms/epoch - 68ms/step\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2634 - accuracy: 0.4722 - mse: 0.2634\n",
      "2/2 [==============================] - 3s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_35_layer_call_fn, lstm_cell_35_layer_call_and_return_conditional_losses, lstm_cell_36_layer_call_fn, lstm_cell_36_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4722\n",
      "Loss: 0.26336947083473206\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_40 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,490\n",
      "Trainable params: 57,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 25s - loss: 0.4273 - accuracy: 0.4088 - mse: 0.4273 - val_loss: 0.2776 - val_accuracy: 0.6250 - val_mse: 0.2776 - lr: 0.0010 - 25s/epoch - 5s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2728 - accuracy: 0.5620 - mse: 0.2728 - val_loss: 0.2374 - val_accuracy: 0.6250 - val_mse: 0.2374 - lr: 0.0010 - 302ms/epoch - 60ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2542 - accuracy: 0.5620 - mse: 0.2542 - val_loss: 0.2451 - val_accuracy: 0.6250 - val_mse: 0.2451 - lr: 0.0010 - 298ms/epoch - 60ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2592 - accuracy: 0.5620 - mse: 0.2592 - val_loss: 0.2387 - val_accuracy: 0.6250 - val_mse: 0.2387 - lr: 0.0010 - 296ms/epoch - 59ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2592 - accuracy: 0.5620 - mse: 0.2592 - val_loss: 0.2348 - val_accuracy: 0.6250 - val_mse: 0.2348 - lr: 0.0010 - 278ms/epoch - 56ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2533 - accuracy: 0.5620 - mse: 0.2533 - val_loss: 0.2358 - val_accuracy: 0.6250 - val_mse: 0.2358 - lr: 0.0010 - 389ms/epoch - 78ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5620 - mse: 0.2471 - val_loss: 0.2364 - val_accuracy: 0.6250 - val_mse: 0.2364 - lr: 0.0010 - 281ms/epoch - 56ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5620 - mse: 0.2487 - val_loss: 0.2351 - val_accuracy: 0.6250 - val_mse: 0.2351 - lr: 0.0010 - 278ms/epoch - 56ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2505 - accuracy: 0.5620 - mse: 0.2505 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 0.0010 - 285ms/epoch - 57ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2504 - accuracy: 0.5620 - mse: 0.2504 - val_loss: 0.2346 - val_accuracy: 0.6250 - val_mse: 0.2346 - lr: 0.0010 - 298ms/epoch - 60ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5620 - mse: 0.2498 - val_loss: 0.2347 - val_accuracy: 0.6250 - val_mse: 0.2347 - lr: 0.0010 - 298ms/epoch - 60ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2496 - accuracy: 0.5620 - mse: 0.2496 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 0.0010 - 282ms/epoch - 56ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5620 - mse: 0.2483 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 284ms/epoch - 57ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 297ms/epoch - 59ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 295ms/epoch - 59ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5620 - mse: 0.2487 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 286ms/epoch - 57ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 352ms/epoch - 70ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2483 - accuracy: 0.5620 - mse: 0.2483 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 305ms/epoch - 61ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5620 - mse: 0.2485 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 294ms/epoch - 59ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5620 - mse: 0.2481 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 283ms/epoch - 57ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2494 - accuracy: 0.5620 - mse: 0.2494 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 295ms/epoch - 59ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5620 - mse: 0.2492 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-05 - 303ms/epoch - 61ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5620 - mse: 0.2481 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 301ms/epoch - 60ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2497 - accuracy: 0.5620 - mse: 0.2497 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 304ms/epoch - 61ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5620 - mse: 0.2484 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 282ms/epoch - 56ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5620 - mse: 0.2490 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 311ms/epoch - 62ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5620 - mse: 0.2489 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 303ms/epoch - 61ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5620 - mse: 0.2485 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 391ms/epoch - 78ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 300ms/epoch - 60ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2493 - accuracy: 0.5620 - mse: 0.2493 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 341ms/epoch - 68ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 301ms/epoch - 60ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5620 - mse: 0.2492 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-07 - 295ms/epoch - 59ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2487 - accuracy: 0.5620 - mse: 0.2487 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 310ms/epoch - 62ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 298ms/epoch - 60ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 304ms/epoch - 61ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5620 - mse: 0.2484 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 300ms/epoch - 60ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5620 - mse: 0.2491 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 289ms/epoch - 58ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2486 - accuracy: 0.5620 - mse: 0.2486 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 307ms/epoch - 61ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5620 - mse: 0.2490 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 391ms/epoch - 78ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2484 - accuracy: 0.5620 - mse: 0.2484 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 295ms/epoch - 59ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 292ms/epoch - 58ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2491 - accuracy: 0.5620 - mse: 0.2491 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-09 - 290ms/epoch - 58ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5620 - mse: 0.2485 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 313ms/epoch - 63ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2490 - accuracy: 0.5620 - mse: 0.2490 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 293ms/epoch - 59ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2481 - accuracy: 0.5620 - mse: 0.2481 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 306ms/epoch - 61ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 288ms/epoch - 58ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2489 - accuracy: 0.5620 - mse: 0.2489 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 322ms/epoch - 64ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2485 - accuracy: 0.5620 - mse: 0.2485 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 300ms/epoch - 60ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2488 - accuracy: 0.5620 - mse: 0.2488 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 302ms/epoch - 60ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2492 - accuracy: 0.5620 - mse: 0.2492 - val_loss: 0.2345 - val_accuracy: 0.6250 - val_mse: 0.2345 - lr: 1.0000e-11 - 367ms/epoch - 73ms/step\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2187 - accuracy: 0.6944 - mse: 0.2187\n",
      "2/2 [==============================] - 3s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_39_layer_call_fn, lstm_cell_39_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6944\n",
      "Loss: 0.21870705485343933\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_42 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_44 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,490\n",
      "Trainable params: 57,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 13s - loss: 0.4197 - accuracy: 0.4818 - mse: 0.4197 - val_loss: 0.2711 - val_accuracy: 0.5625 - val_mse: 0.2711 - lr: 0.0010 - 13s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2610 - accuracy: 0.5547 - mse: 0.2610 - val_loss: 0.2589 - val_accuracy: 0.5625 - val_mse: 0.2589 - lr: 0.0010 - 278ms/epoch - 56ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2599 - accuracy: 0.5547 - mse: 0.2599 - val_loss: 0.2564 - val_accuracy: 0.5625 - val_mse: 0.2564 - lr: 0.0010 - 268ms/epoch - 54ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 0.2541 - accuracy: 0.5547 - mse: 0.2541 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 0.0010 - 265ms/epoch - 53ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5547 - mse: 0.2476 - val_loss: 0.2505 - val_accuracy: 0.5625 - val_mse: 0.2505 - lr: 0.0010 - 269ms/epoch - 54ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2497 - accuracy: 0.5547 - mse: 0.2497 - val_loss: 0.2466 - val_accuracy: 0.5625 - val_mse: 0.2466 - lr: 0.0010 - 270ms/epoch - 54ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2469 - val_accuracy: 0.5625 - val_mse: 0.2469 - lr: 0.0010 - 268ms/epoch - 54ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2470 - val_accuracy: 0.5625 - val_mse: 0.2470 - lr: 0.0010 - 256ms/epoch - 51ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5547 - mse: 0.2478 - val_loss: 0.2461 - val_accuracy: 0.5625 - val_mse: 0.2461 - lr: 0.0010 - 267ms/epoch - 53ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5547 - mse: 0.2467 - val_loss: 0.2465 - val_accuracy: 0.5625 - val_mse: 0.2465 - lr: 0.0010 - 267ms/epoch - 53ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2464 - val_accuracy: 0.5625 - val_mse: 0.2464 - lr: 0.0010 - 262ms/epoch - 52ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 0.0010 - 259ms/epoch - 52ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 306ms/epoch - 61ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 259ms/epoch - 52ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 253ms/epoch - 51ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 255ms/epoch - 51ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 258ms/epoch - 52ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 255ms/epoch - 51ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 275ms/epoch - 55ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 255ms/epoch - 51ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 258ms/epoch - 52ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5547 - mse: 0.2465 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-05 - 260ms/epoch - 52ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 255ms/epoch - 51ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 252ms/epoch - 50ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 268ms/epoch - 54ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5547 - mse: 0.2467 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 297ms/epoch - 59ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 308ms/epoch - 62ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 416ms/epoch - 83ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 304ms/epoch - 61ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5547 - mse: 0.2478 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 310ms/epoch - 62ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-07 - 307ms/epoch - 61ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5547 - mse: 0.2480 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 352ms/epoch - 70ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 304ms/epoch - 61ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 319ms/epoch - 64ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 300ms/epoch - 60ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5547 - mse: 0.2478 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 330ms/epoch - 66ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 321ms/epoch - 64ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 331ms/epoch - 66ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2477 - accuracy: 0.5547 - mse: 0.2477 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 354ms/epoch - 71ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2464 - accuracy: 0.5547 - mse: 0.2464 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 326ms/epoch - 65ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2478 - accuracy: 0.5547 - mse: 0.2478 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-09 - 300ms/epoch - 60ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-11 - 342ms/epoch - 68ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-11 - 293ms/epoch - 59ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-11 - 320ms/epoch - 64ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-11 - 322ms/epoch - 64ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5547 - mse: 0.2463 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-11 - 320ms/epoch - 64ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-11 - 335ms/epoch - 67ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-11 - 322ms/epoch - 64ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2462 - val_accuracy: 0.5625 - val_mse: 0.2462 - lr: 1.0000e-11 - 440ms/epoch - 88ms/step\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2528 - accuracy: 0.5000 - mse: 0.2528\n",
      "2/2 [==============================] - 3s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_43_layer_call_fn, lstm_cell_43_layer_call_and_return_conditional_losses, lstm_cell_44_layer_call_fn, lstm_cell_44_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Loss: 0.2528437376022339\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_46 (LSTM)              (None, 19, 32)            16000     \n",
      "                                                                 \n",
      " lstm_47 (LSTM)              (None, 19, 64)            24832     \n",
      "                                                                 \n",
      " lstm_48 (LSTM)              (None, 19, 32)            12416     \n",
      "                                                                 \n",
      " lstm_49 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,490\n",
      "Trainable params: 57,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 13s - loss: 0.4319 - accuracy: 0.4526 - mse: 0.4319 - val_loss: 0.2781 - val_accuracy: 0.6250 - val_mse: 0.2781 - lr: 0.0010 - 13s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 0.2697 - accuracy: 0.5547 - mse: 0.2697 - val_loss: 0.2470 - val_accuracy: 0.6250 - val_mse: 0.2470 - lr: 0.0010 - 249ms/epoch - 50ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 0.2598 - accuracy: 0.5547 - mse: 0.2598 - val_loss: 0.2507 - val_accuracy: 0.6250 - val_mse: 0.2507 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 2s - loss: 0.2544 - accuracy: 0.5547 - mse: 0.2544 - val_loss: 0.2354 - val_accuracy: 0.6250 - val_mse: 0.2354 - lr: 0.0010 - 2s/epoch - 353ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 0.2494 - accuracy: 0.5547 - mse: 0.2494 - val_loss: 0.2417 - val_accuracy: 0.6250 - val_mse: 0.2417 - lr: 0.0010 - 228ms/epoch - 46ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 0.2517 - accuracy: 0.5474 - mse: 0.2517 - val_loss: 0.2464 - val_accuracy: 0.6250 - val_mse: 0.2464 - lr: 0.0010 - 241ms/epoch - 48ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.2498 - accuracy: 0.5547 - mse: 0.2498 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 0.0010 - 243ms/epoch - 49ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5547 - mse: 0.2480 - val_loss: 0.2375 - val_accuracy: 0.6250 - val_mse: 0.2375 - lr: 0.0010 - 239ms/epoch - 48ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.2480 - accuracy: 0.5547 - mse: 0.2480 - val_loss: 0.2383 - val_accuracy: 0.6250 - val_mse: 0.2383 - lr: 0.0010 - 240ms/epoch - 48ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.2482 - accuracy: 0.5547 - mse: 0.2482 - val_loss: 0.2401 - val_accuracy: 0.6250 - val_mse: 0.2401 - lr: 0.0010 - 298ms/epoch - 60ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5547 - mse: 0.2479 - val_loss: 0.2407 - val_accuracy: 0.6250 - val_mse: 0.2407 - lr: 0.0010 - 262ms/epoch - 52ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 0.0010 - 247ms/epoch - 49ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 254ms/epoch - 51ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.2479 - accuracy: 0.5547 - mse: 0.2479 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 253ms/epoch - 51ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 254ms/epoch - 51ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 249ms/epoch - 50ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 252ms/epoch - 50ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 245ms/epoch - 49ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 242ms/epoch - 48ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 265ms/epoch - 53ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 252ms/epoch - 50ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-05 - 263ms/epoch - 53ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 261ms/epoch - 52ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 308ms/epoch - 62ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.2461 - accuracy: 0.5547 - mse: 0.2461 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 287ms/epoch - 57ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5547 - mse: 0.2466 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 256ms/epoch - 51ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 249ms/epoch - 50ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 278ms/epoch - 56ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 267ms/epoch - 53ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 264ms/epoch - 53ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5547 - mse: 0.2476 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 266ms/epoch - 53ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5547 - mse: 0.2476 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-07 - 257ms/epoch - 51ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 263ms/epoch - 53ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.2463 - accuracy: 0.5547 - mse: 0.2463 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 312ms/epoch - 62ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 262ms/epoch - 52ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.2472 - accuracy: 0.5547 - mse: 0.2472 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 279ms/epoch - 56ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 251ms/epoch - 50ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.2474 - accuracy: 0.5547 - mse: 0.2474 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 267ms/epoch - 53ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.2473 - accuracy: 0.5547 - mse: 0.2473 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 293ms/epoch - 59ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 315ms/epoch - 63ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.2466 - accuracy: 0.5547 - mse: 0.2466 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 319ms/epoch - 64ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.2467 - accuracy: 0.5547 - mse: 0.2467 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-09 - 383ms/epoch - 77ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5547 - mse: 0.2476 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-11 - 356ms/epoch - 71ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.2476 - accuracy: 0.5547 - mse: 0.2476 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-11 - 330ms/epoch - 66ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.2468 - accuracy: 0.5547 - mse: 0.2468 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-11 - 340ms/epoch - 68ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.2475 - accuracy: 0.5547 - mse: 0.2475 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-11 - 323ms/epoch - 65ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.2470 - accuracy: 0.5547 - mse: 0.2470 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-11 - 374ms/epoch - 75ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.2469 - accuracy: 0.5547 - mse: 0.2469 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-11 - 371ms/epoch - 74ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.2471 - accuracy: 0.5547 - mse: 0.2471 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-11 - 356ms/epoch - 71ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.2465 - accuracy: 0.5547 - mse: 0.2465 - val_loss: 0.2399 - val_accuracy: 0.6250 - val_mse: 0.2399 - lr: 1.0000e-11 - 380ms/epoch - 76ms/step\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2385 - accuracy: 0.6389 - mse: 0.2385\n",
      "2/2 [==============================] - 4s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_47_layer_call_fn, lstm_cell_47_layer_call_and_return_conditional_losses, lstm_cell_48_layer_call_fn, lstm_cell_48_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6389\n",
      "Loss: 0.2385473996400833\n"
     ]
    }
   ],
   "source": [
    "def train_model_5_3( xTrain, yTrain, xValid , yValid):\n",
    "    random.seed(26)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM( 32 ,input_shape = (19,92), activation = 'tanh' , dropout = 0.3, recurrent_dropout = 0.3, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.3, return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.2, return_sequences=True))\n",
    "    model.add(LSTM(16))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(2, activation=\"tanh\"))\n",
    "    model.build()   \n",
    "    model.summary()\n",
    "    model.compile( optimizer = \"adam\" , loss = 'mean_squared_error' , metrics = ['accuracy', 'mse'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau( monitor = 'accuracy', factor = 0.01, patience=10, cooldown=0)\n",
    "    \n",
    "    callbacks = [ reduce_lr ]\n",
    "    train_history = model.fit( xTrain, yTrain , epochs = 50, shuffle=False, callbacks=callbacks, verbose = 2, validation_split = 0.1)\n",
    "\n",
    "    score = model.evaluate( xValid , yValid )\n",
    "    pred = model.predict(xValid)\n",
    "    model.save(\"LSTM_1\")\n",
    "    \n",
    "    print( \"Accuracy: {:0.4}\".format( score[1] ))\n",
    "    print( \"Loss:\", score[0] )\n",
    "    return score, pred, train_history\n",
    "\n",
    "results_2012, pred_2012, history_2012 = train_model_5_3(x_train_2012, y_train_2012_OHE, x_valid_2012, y_valid_2012_OHE) \n",
    "results_2013, pred_2013, history_2013 = train_model_5_3(x_train_2013, y_train_2013_OHE, x_valid_2013, y_valid_2013_OHE) \n",
    "results_2014, pred_2014, history_2014 = train_model_5_3(x_train_2014, y_train_2014_OHE, x_valid_2014, y_valid_2014_OHE) \n",
    "results_2015, pred_2015, history_2015 = train_model_5_3(x_train_2015, y_train_2015_OHE, x_valid_2015, y_valid_2015_OHE) \n",
    "results_2016, pred_2016, history_2016 = train_model_5_3(x_train_2016, y_train_2016_OHE, x_valid_2016, y_valid_2016_OHE) \n",
    "results_2017, pred_2017, history_2017 = train_model_5_3(x_train_2017, y_train_2017_OHE, x_valid_2017, y_valid_2017_OHE) \n",
    "results_2018, pred_2018, history_2018 = train_model_5_3(x_train_2018, y_train_2018_OHE, x_valid_2018, y_valid_2018_OHE) \n",
    "results_2019, pred_2019, history_2019 = train_model_5_3(x_train_2019, y_train_2019_OHE, x_valid_2019, y_valid_2019_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5590277723968029"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data = [results_2012[:2],results_2013[:2],results_2014[:2],results_2015[:2],results_2016[:2],\n",
    "                               results_2017[:2],results_2018[:2],results_2019[:2]],\n",
    "                            index = ['2012', '2013', '2014','2015','2016','2017','2018','2019'],\n",
    "                            columns = ['loss', 'accuracy'])\n",
    "sum(results['accuracy'])/8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afd8bbf76cc8f66cb6213c8ab916f8a134e63b6f70cbd0f147b7ecd8cc749dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
