{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,roc_auc_score,confusion_matrix,accuracy_score,f1_score,roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, LSTM\n",
    "from keras.utils import to_categorical\n",
    "import re\n",
    "from IPython.display import display\n",
    "import os\n",
    "import string\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Craig\\AppData\\Local\\Temp\\ipykernel_10468\\3458396436.py:5: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  games_2014 = pd.read_csv(games_folder_path + '2014.csv', index_col=False, parse_dates=['date'])\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "games_folder_path = \"C:/Users/Craig/Documents/Thesis/Thomas_Gallagher_Thesis/Data/AFL_Stats_sorted/Year/Games/\"\n",
    "games_2012 = pd.read_csv(games_folder_path + '2012.csv', index_col=False, parse_dates=['date'])\n",
    "games_2013 = pd.read_csv(games_folder_path + '2013.csv', index_col=False, parse_dates=['date'])\n",
    "games_2014 = pd.read_csv(games_folder_path + '2014.csv', index_col=False, parse_dates=['date'])\n",
    "games_2015 = pd.read_csv(games_folder_path + '2015.csv', index_col=False, parse_dates=['date'])\n",
    "games_2016 = pd.read_csv(games_folder_path + '2016.csv', index_col=False, parse_dates=['date'])\n",
    "games_2017 = pd.read_csv(games_folder_path + '2017.csv', index_col=False, parse_dates=['date'])\n",
    "games_2018 = pd.read_csv(games_folder_path + '2018.csv', index_col=False, parse_dates=['date'])\n",
    "games_2019 = pd.read_csv(games_folder_path + '2019.csv', index_col=False, parse_dates=['date'])\n",
    "games_2020 = pd.read_csv(games_folder_path + '2020.csv', index_col=False, parse_dates=['date'])\n",
    "games_2021 = pd.read_csv(games_folder_path + '2021.csv', index_col=False, parse_dates=['date'])\n",
    "\n",
    "\n",
    "all_games = pd.read_csv(games_folder_path + 'games_sorted.csv', index_col=False, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Teams\n",
    "encoding = LabelEncoder()\n",
    "encoding.fit(all_games[\"homeTeam\"].values)\n",
    "\n",
    "def OHE_Teams(games):\n",
    "    home_teams = encoding.transform(games[\"homeTeam\"].values)\n",
    "    away_teams = encoding.transform(games[\"awayTeam\"].values)\n",
    "\n",
    "    all_teams = np.vstack([home_teams, away_teams]).T\n",
    " \n",
    "    oneHot = OneHotEncoder()\n",
    "    X_teams = oneHot.fit_transform(all_teams).todense()\n",
    "    X_teams = pd.DataFrame(X_teams)\n",
    "    games = pd.concat([games, pd.DataFrame(X_teams)],axis=1)\n",
    "    return games\n",
    "\n",
    "games_2012 = OHE_Teams(games_2012)\n",
    "games_2013 = OHE_Teams(games_2013)\n",
    "games_2014 = OHE_Teams(games_2014)\n",
    "games_2015 = OHE_Teams(games_2015)\n",
    "games_2016 = OHE_Teams(games_2016)\n",
    "games_2017 = OHE_Teams(games_2017)\n",
    "games_2018 = OHE_Teams(games_2018)\n",
    "games_2019 = OHE_Teams(games_2019)\n",
    "games_2020 = OHE_Teams(games_2020)\n",
    "games_2021 = OHE_Teams(games_2021)\n",
    "\n",
    "all_games = OHE_Teams(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Venues\n",
    "encoding = LabelEncoder()\n",
    "encoding.fit(all_games[\"venue\"].values)\n",
    "all_venues = all_games[\"venue\"].values\n",
    "\n",
    "all_venues = all_venues.reshape(-1,1)\n",
    "\n",
    "def OHE_Venues(games):\n",
    "    venues = games['venue'].values\n",
    "    # all_venues = all_venues.reshape(-1,1)\n",
    "    venues = venues.reshape(-1,1)\n",
    "    oneHot = OneHotEncoder()\n",
    "\n",
    "    oneHot.fit(all_venues)\n",
    "    X_venues = oneHot.transform(venues).toarray()\n",
    "    X_venues = pd.DataFrame(X_venues, columns=oneHot.categories_[0])\n",
    "    games = pd.concat([games, X_venues], axis=1)\n",
    "    return games\n",
    "\n",
    "games_2012 = OHE_Venues(games_2012)\n",
    "games_2013 = OHE_Venues(games_2013)\n",
    "games_2014 = OHE_Venues(games_2014)\n",
    "games_2015 = OHE_Venues(games_2015)\n",
    "games_2016 = OHE_Venues(games_2016)\n",
    "games_2017 = OHE_Venues(games_2017)\n",
    "games_2018 = OHE_Venues(games_2018)\n",
    "games_2019 = OHE_Venues(games_2019)\n",
    "games_2020 = OHE_Venues(games_2020)\n",
    "games_2021 = OHE_Venues(games_2021)\n",
    "\n",
    "all_games = OHE_Venues(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_true_2012 = games_2012['homeWin']\n",
    "y_true_2013 = games_2013['homeWin']\n",
    "y_true_2014 = games_2014['homeWin']\n",
    "y_true_2015 = games_2015['homeWin']\n",
    "y_true_2016 = games_2016['homeWin']\n",
    "y_true_2017 = games_2017['homeWin']\n",
    "y_true_2018 = games_2018['homeWin']\n",
    "y_true_2019 = games_2019['homeWin']\n",
    "y_true_2020 = games_2020['homeWin']\n",
    "y_true_2021 = games_2021['homeWin']\n",
    "y_true = all_games['homeWin']\n",
    "\n",
    "drop_values = ['gameId', 'venue', 'homeWin', 'homeTeam', 'awayTeam', 'year','date','startTime', 'attendance', 'homeTeamScore', 'awayTeamScore', 'round']\n",
    "\n",
    "def set_columns(game_list):\n",
    "    game_list = game_list.drop(drop_values,axis=1)\n",
    "    game_list.columns = game_list.columns.astype(str)\n",
    "    return game_list\n",
    "\n",
    "games_2012 = set_columns(games_2012)\n",
    "games_2013 = set_columns(games_2013)\n",
    "games_2014 = set_columns(games_2014)\n",
    "games_2015 = set_columns(games_2015)\n",
    "games_2016 = set_columns(games_2016)\n",
    "games_2017 = set_columns(games_2017)\n",
    "games_2018 = set_columns(games_2018)\n",
    "games_2019 = set_columns(games_2019)\n",
    "games_2020 = set_columns(games_2020)\n",
    "games_2021 = set_columns(games_2021)\n",
    "\n",
    "all_games = set_columns(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "games_2012 = scaler.fit_transform(games_2012)\n",
    "games_2013 = scaler.fit_transform(games_2013)\n",
    "games_2014 = scaler.fit_transform(games_2014)\n",
    "games_2015 = scaler.fit_transform(games_2015)\n",
    "games_2016 = scaler.fit_transform(games_2016)\n",
    "games_2017 = scaler.fit_transform(games_2017)\n",
    "games_2018 = scaler.fit_transform(games_2018)\n",
    "games_2019 = scaler.fit_transform(games_2019)\n",
    "games_2020 = scaler.fit_transform(games_2020)\n",
    "games_2021 = scaler.fit_transform(games_2021)\n",
    "\n",
    "all_games = scaler.fit_transform(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2012 = games_2012[:171]\n",
    "y_train_2012 = y_true_2012[:171]\n",
    "x_valid_2012 = games_2012[171:]\n",
    "y_valid_2012 = y_true_2012[171:]\n",
    "\n",
    "x_train_2013 = games_2013[:171]\n",
    "y_train_2013 = y_true_2013[:171]\n",
    "x_valid_2013 = games_2013[171:]\n",
    "y_valid_2013 = y_true_2013[171:]\n",
    "\n",
    "x_train_2014 = games_2014[:171]\n",
    "y_train_2014 = y_true_2014[:171]\n",
    "x_valid_2014 = games_2014[171:]\n",
    "y_valid_2014 = y_true_2014[171:]\n",
    "\n",
    "x_train_2015 = games_2015[:170]\n",
    "y_train_2015 = y_true_2015[:170]\n",
    "x_valid_2015 = games_2015[170:]\n",
    "y_valid_2015 = y_true_2015[170:]\n",
    "\n",
    "x_train_2016 = games_2016[:171]\n",
    "y_train_2016 = y_true_2016[:171]\n",
    "x_valid_2016 = games_2016[171:]\n",
    "y_valid_2016 = y_true_2016[171:]\n",
    "\n",
    "x_train_2017 = games_2017[:171]\n",
    "y_train_2017 = y_true_2017[:171]\n",
    "x_valid_2017 = games_2017[171:]\n",
    "y_valid_2017 = y_true_2017[171:]\n",
    "\n",
    "x_train_2018 = games_2018[:171]\n",
    "y_train_2018 = y_true_2018[:171]\n",
    "x_valid_2018 = games_2018[171:]\n",
    "y_valid_2018 = y_true_2018[171:]\n",
    "\n",
    "x_train_2019 = games_2019[:171]\n",
    "y_train_2019 = y_true_2019[:171]\n",
    "x_valid_2019 = games_2019[171:]\n",
    "y_valid_2019 = y_true_2019[171:]\n",
    "\n",
    "x_train_2020 = games_2020[:127]\n",
    "y_train_2020 = y_true_2020[:127]\n",
    "x_valid_2020 = games_2020[127:]\n",
    "y_valid_2020 = y_true_2020[127:]\n",
    "\n",
    "x_train_2021 = games_2021[:171]\n",
    "y_train_2021 = y_true_2021[:171]\n",
    "x_valid_2021 = games_2021[171:]\n",
    "y_valid_2021 = y_true_2021[171:]\n",
    "\n",
    "x_train = all_games[:1447]\n",
    "y_train = y_true[:1447]\n",
    "x_valid = all_games[1447:1655]\n",
    "y_valid = y_true[1447:1655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE Y values\n",
    "oneHot = OneHotEncoder()\n",
    "def OHE_y_values(y_val):\n",
    "    y = np.vstack([y_val]).T\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1:\n",
    "            y[i] = 0\n",
    "\n",
    "    y_OHE = oneHot.fit_transform(y).toarray()\n",
    "\n",
    "    return y_OHE\n",
    "\n",
    "\n",
    "y_train_2012_OHE = OHE_y_values(y_train_2012)\n",
    "y_valid_2012_OHE = OHE_y_values(y_valid_2012)\n",
    "\n",
    "y_train_2013_OHE = OHE_y_values(y_train_2013)\n",
    "y_valid_2013_OHE = OHE_y_values(y_valid_2013)\n",
    "\n",
    "y_train_2014_OHE = OHE_y_values(y_train_2014)\n",
    "y_valid_2014_OHE = OHE_y_values(y_valid_2014)\n",
    "\n",
    "y_train_2015_OHE = OHE_y_values(y_train_2015)\n",
    "y_valid_2015_OHE = OHE_y_values(y_valid_2015)\n",
    "\n",
    "y_train_2016_OHE = OHE_y_values(y_train_2016)\n",
    "y_valid_2016_OHE = OHE_y_values(y_valid_2016)\n",
    "\n",
    "y_train_2017_OHE = OHE_y_values(y_train_2017)\n",
    "y_valid_2017_OHE = OHE_y_values(y_valid_2017)\n",
    "\n",
    "y_train_2018_OHE = OHE_y_values(y_train_2018)\n",
    "y_valid_2018_OHE = OHE_y_values(y_valid_2018)\n",
    "\n",
    "y_train_2019_OHE = OHE_y_values(y_train_2019)\n",
    "y_valid_2019_OHE = OHE_y_values(y_valid_2019)\n",
    "\n",
    "y_train_2020_OHE = OHE_y_values(y_train_2020)\n",
    "y_valid_2020_OHE = OHE_y_values(y_valid_2020)\n",
    "\n",
    "y_train_2021_OHE = OHE_y_values(y_train_2021)\n",
    "y_valid_2021_OHE = OHE_y_values(y_valid_2021)\n",
    "\n",
    "y_train_OHE = OHE_y_values(y_train)\n",
    "y_valid_OHE = OHE_y_values(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2012_OHE = OHE_y_values(y_true_2012)\n",
    "\n",
    "y_2012_OHE = y_2012_OHE.astype(int)\n",
    "y_2012_OHE.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_Train = x_train_2012.reshape(171, 1, 86)\n",
    "d_valid = x_valid_2012.reshape(36, 1, 86) \n",
    "\n",
    "d_y_t = y_train_2012_OHE.reshape(171, 1,2)\n",
    "d_y_v = y_valid_2012_OHE.reshape(36, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDs = map(lambda text, label: x_train_2012, y_train_2012)\n",
    "valDs = map(lambda text, label: x_valid_2012, y_valid_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x26aa3852400>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model():\n",
    "\t# input for variable-length sequences of integers\n",
    "\tinputs = keras.Input(shape=(86,), dtype=\"int32\")\n",
    "\t# embed the tokens in a 128-dimensional vector with masking\n",
    "\t# applied and apply dropout\n",
    "\tx = layers.Embedding(86, 128, mask_zero=False)(inputs)\n",
    "\tx = layers.Dropout(0.2)(x)\n",
    "\t# add 3 LSTMs\n",
    "\tx = layers.LSTM(64, return_sequences=True)(x)\n",
    "\tx = layers.LSTM(64, return_sequences=True)(x)\n",
    "\tx = layers.LSTM(64)(x)\n",
    "\t# add a classifier head\n",
    "\tx = layers.Dense(units=64, activation=\"tanh\")(x)\n",
    "\tx = layers.Dense(units=32, activation=\"tanh\")(x)\n",
    "\t# x = layers.Dropout(0.2)(x)\n",
    "\toutputs = layers.Dense(2, activation=\"tanh\")(x)\n",
    "\t\n",
    "\t# build the LSTM model\n",
    "\tmodel = keras.Model(inputs, outputs, name=\"LSTM\")\n",
    "\t\n",
    "\t# return the LSTM model\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss_accuracy(history, filepath):\n",
    "\t# plot the training and validation loss\n",
    "\tplt.style.use(\"ggplot\")\n",
    "\t(fig, axs) = plt.subplots(2, 1)\n",
    "\taxs[0].plot(history[\"loss\"], label=\"train_loss\")\n",
    "\taxs[0].plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "\taxs[0].set_xlabel(\"Epoch #\")\n",
    "\taxs[0].set_ylabel(\"Loss\")\n",
    "\taxs[0].legend()\n",
    "\taxs[1].plot(history[\"accuracy\"], label=\"train_accuracy\")\n",
    "\taxs[1].plot(history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "\taxs[1].set_xlabel(\"Epoch #\")\n",
    "\taxs[1].set_ylabel(\"Accuracy\")\n",
    "\taxs[1].legend()\n",
    "\tfig.savefig(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building the LSTM model...\n",
      "[INFO] training the LSTM model...\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 11s 653ms/step - loss: 2.4446 - accuracy: 0.4848 - val_loss: 0.1873 - val_accuracy: 0.5714\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.1776 - accuracy: 0.5333 - val_loss: 0.1805 - val_accuracy: 0.5714\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 157ms/step - loss: 0.1772 - accuracy: 0.5333 - val_loss: 0.1843 - val_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.1797 - accuracy: 0.5333 - val_loss: 0.1996 - val_accuracy: 0.5714\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 155ms/step - loss: 0.1914 - accuracy: 0.5333 - val_loss: 0.2074 - val_accuracy: 0.5714\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 0.1909 - accuracy: 0.5333 - val_loss: 0.1944 - val_accuracy: 0.5714\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.1870 - accuracy: 0.5333 - val_loss: 0.2032 - val_accuracy: 0.5714\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.1954 - accuracy: 0.5333 - val_loss: 0.1957 - val_accuracy: 0.5714\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 141ms/step - loss: 0.1869 - accuracy: 0.5333 - val_loss: 0.1935 - val_accuracy: 0.5714\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 0.1892 - accuracy: 0.5333 - val_loss: 0.1969 - val_accuracy: 0.5714\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] building the LSTM model...\")\n",
    "modelLSTM = get_lstm_model()\n",
    "modelLSTM.compile(metrics=[\"accuracy\"],\n",
    "\toptimizer=keras.optimizers.RMSprop(),\n",
    "\tloss=keras.losses.BinaryFocalCrossentropy(from_logits=False),\n",
    ")\n",
    "# train the LSTM model\n",
    "print(\"[INFO] training the LSTM model...\")\n",
    "historyLSTM = modelLSTM.fit(x=games_2012, y = y_2012_OHE, epochs=10,\n",
    "\tshuffle= False, validation_split = 0.2, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
