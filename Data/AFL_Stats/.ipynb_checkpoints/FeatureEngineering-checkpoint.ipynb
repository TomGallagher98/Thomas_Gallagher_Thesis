{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Activating ipynb\")\n",
    "print (\"Importing libs\")\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global\n",
    "years = [x for x in range (2012, 2022)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Initial Data\n",
    "print(\"Loading Initial Game Data\")\n",
    "games_folder_path = \"C:/Users/Craig/Documents/Thesis/Thomas_Gallagher_Thesis/Data/AFL_Stats_sorted/Year/Games/\"\n",
    "games_2012 = pd.read_csv(games_folder_path + '2012.csv', index_col=False, parse_dates=['date'])\n",
    "games_2013 = pd.read_csv(games_folder_path + '2013.csv', index_col=False, parse_dates=['date'])\n",
    "games_2014 = pd.read_csv(games_folder_path + '2014.csv', index_col=False, parse_dates=['date'])\n",
    "games_2015 = pd.read_csv(games_folder_path + '2015.csv', index_col=False, parse_dates=['date'])\n",
    "games_2016 = pd.read_csv(games_folder_path + '2016.csv', index_col=False, parse_dates=['date'])\n",
    "games_2017 = pd.read_csv(games_folder_path + '2017.csv', index_col=False, parse_dates=['date'])\n",
    "games_2018 = pd.read_csv(games_folder_path + '2018.csv', index_col=False, parse_dates=['date'])\n",
    "games_2019 = pd.read_csv(games_folder_path + '2019.csv', index_col=False, parse_dates=['date'])\n",
    "games_2020 = pd.read_csv(games_folder_path + '2020.csv', index_col=False, parse_dates=['date'])\n",
    "games_2021 = pd.read_csv(games_folder_path + '2021.csv', index_col=False, parse_dates=['date'])\n",
    "\n",
    "all_games_path = os.path.join(games_folder_path + \"games_sorted.csv\")\n",
    "# all_g = pd.concat([games_2014, games_2013, games_2014, games_2015, games_2016, games_2017, games_2018, games_2019, games_2020, games_2021])\n",
    "# all_g.to_csv(all_games_path, index=False)\n",
    "all_games = pd.read_csv(all_games_path, index_col=False, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Stats\n",
    "stats_folder_path = \"C:/Users/Craig/Documents/Thesis/Thomas_Gallagher_Thesis/Data/AFL_Stats_sorted/Year/Players/\"\n",
    "stats_2012 = pd.read_csv(stats_folder_path + '2012.csv', index_col=False)\n",
    "stats_2013 = pd.read_csv(stats_folder_path + '2013.csv', index_col=False)\n",
    "stats_2014 = pd.read_csv(stats_folder_path + '2014.csv', index_col=False)\n",
    "stats_2015 = pd.read_csv(stats_folder_path + '2015.csv', index_col=False)\n",
    "stats_2016 = pd.read_csv(stats_folder_path + '2016.csv', index_col=False)\n",
    "stats_2017 = pd.read_csv(stats_folder_path + '2017.csv', index_col=False)\n",
    "stats_2018 = pd.read_csv(stats_folder_path + '2018.csv', index_col=False)\n",
    "stats_2019 = pd.read_csv(stats_folder_path + '2019.csv', index_col=False)\n",
    "stats_2020 = pd.read_csv(stats_folder_path + '2020.csv', index_col=False)\n",
    "stats_2021 = pd.read_csv(stats_folder_path + '2021.csv', index_col=False)\n",
    "\n",
    "all_stats = \"C:/Users/Craig/Documents/Thesis/Thomas_Gallagher_Thesis/Data/AFL_Stats_sorted/Year/Players/stats_sorted.csv\"\n",
    "all_stats_raw = pd.read_csv(all_stats, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_list_year = [games_2012, games_2013, games_2014, games_2015, games_2016, games_2017, games_2018, games_2019, games_2020, games_2021]\n",
    "stats_list_year = [stats_2012, stats_2013, stats_2014, stats_2015, stats_2016, stats_2017, stats_2018, stats_2019, stats_2020, stats_2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Y value \n",
    "Result of game based on Home Team (Win = 2, Draw = 1, Lose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_2012 = games_2012['homeWin']\n",
    "y_true_2013 = games_2013['homeWin']\n",
    "y_true_2014 = games_2014['homeWin']\n",
    "y_true_2015 = games_2015['homeWin']\n",
    "y_true_2016 = games_2016['homeWin']\n",
    "y_true_2017 = games_2017['homeWin']\n",
    "y_true_2018 = games_2018['homeWin']\n",
    "y_true_2019 = games_2019['homeWin']\n",
    "y_true_2020 = games_2020['homeWin']\n",
    "y_true_2021 = games_2021['homeWin']\n",
    "y_true_all = all_games['homeWin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = {}\n",
    "\n",
    "def get_baseline(y, year):\n",
    "    # print(y.count())\n",
    "    baseline[year] = (y.sum() / (y.count()*2)) * 100\n",
    "\n",
    "get_baseline(y_true_2012, '2012')\n",
    "get_baseline(y_true_2013, '2013')\n",
    "get_baseline(y_true_2014, '2014')\n",
    "get_baseline(y_true_2015, '2015')\n",
    "get_baseline(y_true_2016, '2016')\n",
    "get_baseline(y_true_2017, '2017')\n",
    "get_baseline(y_true_2018, '2018')\n",
    "get_baseline(y_true_2019, '2019')\n",
    "get_baseline(y_true_2020, '2020')\n",
    "get_baseline(y_true_2021, '2021')\n",
    "\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Previous Game Result\n",
    "Set default dict to store results for each team\n",
    "Only a boolean value, draws only account for ~1% of all games \n",
    "Default to false\n",
    "If the last game was a win set to true\n",
    "# TODO \n",
    "add draws in and see if there is a difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computed Variables\n",
    "These variables did not appear in the original data set but were added later\n",
    "\n",
    "Travel Data: Used to determine the impact of travel on teams\n",
    "             Determined by comparing the venue of the upcoming match to the teams home location\n",
    "\n",
    "Break: Finds the break between a teams last and next game\n",
    "\n",
    "Team Changes: The number of players that are different in the from the previous match\n",
    "              The number of games lost/gained from these changes\n",
    "              The expected score lost/gained from the incoming players\n",
    "              Split games out and games in into separate variables\n",
    "\n",
    "Team Composition: The average/total score of all the selected players\n",
    "                  Done this way to reduce number of features\n",
    "\n",
    "TODO   \n",
    "Previous 5 games result: Totals each teams previous games results\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "The tree models used for feature engineering cannot take in string inputs\n",
    "Value encoding can be used to change teams to int values, but then the model will read this as distance i.e. the team with value 1 will be read as being closer to the team with value 2 than the team with value 18. \n",
    "One Hot Encoding creates a bool variable for each team which is 1 when the team is playing.\n",
    "\n",
    "# TODO\n",
    "See if the model performs better with the simple label encoding. \n",
    "One hot encoding creates an issue with decision trees as it creates lots of \"empty\" splits, there will now be 34 variables which the model will split on 0, which can skew the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Teams\n",
    "encoding = LabelEncoder()\n",
    "encoding.fit(all_games[\"homeTeam\"].values)\n",
    "\n",
    "def OHE_Teams(games):\n",
    "    home_teams = encoding.transform(games[\"homeTeam\"].values)\n",
    "    away_teams = encoding.transform(games[\"awayTeam\"].values)\n",
    "\n",
    "    all_teams = np.vstack([home_teams, away_teams]).T\n",
    " \n",
    "    oneHot = OneHotEncoder()\n",
    "    X_teams = oneHot.fit_transform(all_teams).todense()\n",
    "    X_teams = pd.DataFrame(X_teams)\n",
    "    games = pd.concat([games, pd.DataFrame(X_teams)],axis=1)\n",
    "    return games\n",
    "\n",
    "games_2012 = OHE_Teams(games_2012)\n",
    "games_2013 = OHE_Teams(games_2013)\n",
    "games_2014 = OHE_Teams(games_2014)\n",
    "games_2015 = OHE_Teams(games_2015)\n",
    "games_2016 = OHE_Teams(games_2016)\n",
    "games_2017 = OHE_Teams(games_2017)\n",
    "games_2018 = OHE_Teams(games_2018)\n",
    "games_2019 = OHE_Teams(games_2019)\n",
    "games_2020 = OHE_Teams(games_2020)\n",
    "games_2021 = OHE_Teams(games_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding Venues\n",
    "Same issues as above, but simplified slightly as there are only 23 stadiums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Venues\n",
    "encoding = LabelEncoder()\n",
    "encoding.fit(all_games[\"venue\"].values)\n",
    "all_venues = all_games[\"venue\"].values\n",
    "all_venues = all_venues.reshape(-1,1)\n",
    "\n",
    "def OHE_Venues(games):\n",
    "    venues = games['venue'].values\n",
    "    # all_venues = all_venues.reshape(-1,1)\n",
    "    \n",
    "    venues = venues.reshape(-1,1)\n",
    "\n",
    "    oneHot = OneHotEncoder()\n",
    "\n",
    "    oneHot.fit(all_venues)\n",
    "    X_venues = oneHot.transform(venues).toarray()\n",
    "    X_venues = pd.DataFrame(X_venues, columns=oneHot.categories_[0])\n",
    "    games = pd.concat([games, X_venues], axis=1)\n",
    "    return games\n",
    "\n",
    "games_2012 = OHE_Venues(games_2012)\n",
    "games_2013 = OHE_Venues(games_2013)\n",
    "games_2014 = OHE_Venues(games_2014)\n",
    "games_2015 = OHE_Venues(games_2015)\n",
    "games_2016 = OHE_Venues(games_2016)\n",
    "games_2017 = OHE_Venues(games_2017)\n",
    "games_2018 = OHE_Venues(games_2018)\n",
    "games_2019 = OHE_Venues(games_2019)\n",
    "games_2020 = OHE_Venues(games_2020)\n",
    "games_2021 = OHE_Venues(games_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dtypes(df):\n",
    "    for index in range(len(df.dtypes)):\n",
    "        print(f'{df.columns[index]} -> {df.dtypes[index]}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Variables\n",
    "drop_values = ['gameId', 'venue', 'homeTeam', 'homeWin','awayTeam', 'year','date','startTime', 'attendance', 'homeTeamScore', 'awayTeamScore']\n",
    "X_2012 = games_2012.drop(drop_values,axis=1)\n",
    "X_2013 = games_2013.drop(drop_values,axis=1)\n",
    "X_2014 = games_2014.drop(drop_values,axis=1)\n",
    "X_2015 = games_2015.drop(drop_values,axis=1)\n",
    "X_2016 = games_2016.drop(drop_values,axis=1)\n",
    "X_2017 = games_2017.drop(drop_values,axis=1)\n",
    "X_2018 = games_2018.drop(drop_values,axis=1)\n",
    "X_2019 = games_2019.drop(drop_values,axis=1)\n",
    "X_2020 = games_2020.drop(drop_values,axis=1)\n",
    "X_2021 = games_2021.drop(drop_values,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_2012.dtypes)\n",
    "def bool_to_int(row):\n",
    "    if str(row['homeTeamLastWin']) == \"True\":\n",
    "        row['homeTeamLastWin'] = 1\n",
    "    else:\n",
    "        row['homeTeamLastWin'] = 0\n",
    "    if str(row['awayTeamLastWin']) == \"True\":\n",
    "        row['awayTeamLastWin'] = 1\n",
    "    else:\n",
    "        row['awayTeamLastWin'] = 0\n",
    "    return row\n",
    "X_2012 = X_2012.apply(bool_to_int, axis = 1)\n",
    "X_2013 = X_2013.apply(bool_to_int, axis = 1)\n",
    "X_2014 = X_2014.apply(bool_to_int, axis = 1)\n",
    "X_2015 = X_2015.apply(bool_to_int, axis = 1)\n",
    "X_2016 = X_2016.apply(bool_to_int, axis = 1)\n",
    "X_2017 = X_2017.apply(bool_to_int, axis = 1)\n",
    "X_2018 = X_2018.apply(bool_to_int, axis = 1)\n",
    "X_2019 = X_2019.apply(bool_to_int, axis = 1)\n",
    "X_2020 = X_2020.apply(bool_to_int, axis = 1)\n",
    "X_2021 = X_2021.apply(bool_to_int, axis = 1)\n",
    "print(X_2012.dtypes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2012.columns = X_2012.columns.astype(str) \n",
    "X_2013.columns = X_2013.columns.astype(str) \n",
    "X_2014.columns = X_2014.columns.astype(str) \n",
    "X_2015.columns = X_2015.columns.astype(str) \n",
    "X_2016.columns = X_2016.columns.astype(str) \n",
    "X_2017.columns = X_2017.columns.astype(str) \n",
    "X_2018.columns = X_2018.columns.astype(str) \n",
    "X_2019.columns = X_2019.columns.astype(str) \n",
    "X_2020.columns = X_2020.columns.astype(str) \n",
    "X_2021.columns = X_2021.columns.astype(str) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "For each season I will create a different classifier, so that each season can be assessed individually\n",
    "These models will not include the 2021 season, even though the final model will be separate to the models created here the feature engineering means that information will possibly be extracted from the data. As such I will leave the final season out of feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_2012.isnull().sum().sum(),\n",
    "X_2013.isnull().sum().sum(),\n",
    "X_2014.isnull().sum().sum(),\n",
    "X_2015.isnull().sum().sum(),\n",
    "X_2016.isnull().sum().sum(),\n",
    "X_2017.isnull().sum().sum(),\n",
    "X_2018.isnull().sum().sum(),\n",
    "X_2019.isnull().sum().sum(),\n",
    "X_2020.isnull().sum().sum(),\n",
    "X_2021.isnull().sum().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = {}\n",
    "def build_dec_tree_scores(X, y, year):\n",
    "    clf = DecisionTreeClassifier(random_state=26)\n",
    "    scores_raw = clf.fit(X, y)\n",
    "    scores_raw = cross_val_score(clf, X, y)\n",
    "    scores[year] = np.mean(scores_raw)\n",
    "\n",
    "build_dec_tree_scores(X_2012, y_true_2012, '2012')\n",
    "build_dec_tree_scores(X_2013, y_true_2013, '2013')\n",
    "build_dec_tree_scores(X_2012, y_true_2012, '2014')\n",
    "build_dec_tree_scores(X_2013, y_true_2013, '2015')\n",
    "build_dec_tree_scores(X_2012, y_true_2012, '2016')\n",
    "build_dec_tree_scores(X_2013, y_true_2013, '2017')\n",
    "build_dec_tree_scores(X_2012, y_true_2012, '2018')\n",
    "build_dec_tree_scores(X_2013, y_true_2013, '2019')\n",
    "build_dec_tree_scores(X_2012, y_true_2012, '2020')\n",
    "build_dec_tree_scores(X_2013, y_true_2013, '2021')\n",
    "\n",
    "print(scores)\n",
    "# print(\"F1: {0:0.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory classifier on the original training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "m = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "m.fit(X_2012, y_true_2012)\n",
    "m.score(X_2012, y_true_2012)\n",
    "\n",
    "# m.score(X_train_orig, y_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2012 = X_2012[:171]\n",
    "y_train_2012 = y_true_2012[:171]\n",
    "\n",
    "x_valid_2012 = X_2012[171:]\n",
    "y_valid_2012 = y_true_2012[171:]\n",
    "\n",
    "x_train_2013 = X_2013[:171]\n",
    "y_train_2013 = y_true_2013[:171]\n",
    "x_valid_2013 = X_2013[171:]\n",
    "y_valid_2013 = y_true_2013[171:]\n",
    "\n",
    "x_train_2014 = X_2014[:171]\n",
    "y_train_2014 = y_true_2014[:171]\n",
    "x_valid_2014 = X_2014[171:]\n",
    "y_valid_2014 = y_true_2014[171:]\n",
    "\n",
    "x_train_2015 = X_2015[:170]\n",
    "y_train_2015 = y_true_2015[:170]\n",
    "x_valid_2015 = X_2015[170:]\n",
    "y_valid_2015 = y_true_2015[170:]\n",
    "\n",
    "x_train_2016 = X_2016[:171]\n",
    "y_train_2016 = y_true_2016[:171]\n",
    "x_valid_2016 = X_2016[171:]\n",
    "y_valid_2016 = y_true_2016[171:]\n",
    "\n",
    "x_train_2017 = X_2017[:171]\n",
    "y_train_2017 = y_true_2017[:171]\n",
    "x_valid_2017 = X_2017[171:]\n",
    "y_valid_2017 = y_true_2017[171:]\n",
    "\n",
    "x_train_2018 = X_2018[:171]\n",
    "y_train_2018 = y_true_2018[:171]\n",
    "x_valid_2018 = X_2018[171:]\n",
    "y_valid_2018 = y_true_2018[171:]\n",
    "\n",
    "x_train_2019 = X_2019[:171]\n",
    "y_train_2019 = y_true_2019[:171]\n",
    "x_valid_2019 = X_2019[171:]\n",
    "y_valid_2019 = y_true_2019[171:]\n",
    "\n",
    "x_train_2020 = X_2020[:127]\n",
    "y_train_2020 = y_true_2020[:127]\n",
    "x_valid_2020 = X_2020[127:]\n",
    "y_valid_2020 = y_true_2020[127:]\n",
    "\n",
    "x_train_2021 = X_2021[:171]\n",
    "y_train_2021 = y_true_2021[:171]\n",
    "x_valid_2021 = X_2021[171:]\n",
    "y_valid_2021 = y_true_2021[171:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(m, train, y_train, valid, y_valid, test=None):\n",
    "    # if test == None:\n",
    "        print([m.score(train, y_train), m.score(valid, y_valid)])\n",
    "        pred = m.predict(valid)\n",
    "        c_train = confusion_matrix(y_valid, pred)\n",
    "        disp = ConfusionMatrixDisplay(c_train)\n",
    "        return disp\n",
    "        # plt.show()\n",
    "        # ConfusionMatrixDisplay(m, valid, y_valid_2012)\n",
    "        \n",
    "    # else:\n",
    "    #     print(m.score(X_test, y_test))\n",
    "    #     plot_confusion_matrix(m, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_2012 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_1_2012.fit(x_train_2012, y_train_2012)\n",
    "m_2012 = print_score(model_1_2012, x_train_2012, y_train_2012, x_valid_2012, y_valid_2012)\n",
    "\n",
    "model_1_2013 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_1_2013.fit(x_train_2013, y_train_2013)\n",
    "m_2013 = print_score(model_1_2013, x_train_2013, y_train_2013, x_valid_2013, y_valid_2013)\n",
    "\n",
    "model_1_2014 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_1_2014.fit(x_train_2014, y_train_2014)\n",
    "m_2014 = print_score(model_1_2014, x_train_2014, y_train_2014, x_valid_2014, y_valid_2014)\n",
    "\n",
    "model_1_2015 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_1_2015.fit(x_train_2015, y_train_2015)\n",
    "m_2015 = print_score(model_1_2015, x_train_2015, y_train_2015, x_valid_2015, y_valid_2015)\n",
    "\n",
    "model_1_2016 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_1_2016.fit(x_train_2016, y_train_2016)\n",
    "m_2016 = print_score(model_1_2016, x_train_2016, y_train_2016, x_valid_2016, y_valid_2016)\n",
    "\n",
    "model_1_2017 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_1_2017.fit(x_train_2017, y_train_2017)\n",
    "m_2017 = print_score(model_1_2017, x_train_2017, y_train_2017, x_valid_2017, y_valid_2017)\n",
    "\n",
    "model_1_2018 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_1_2018.fit(x_train_2018, y_train_2018)\n",
    "m_2018 = print_score(model_1_2018, x_train_2018, y_train_2018, x_valid_2018, y_valid_2018)\n",
    "\n",
    "model_1_2019 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_1_2019.fit(x_train_2019, y_train_2019)\n",
    "m_2019 = print_score(model_1_2019, x_train_2019, y_train_2019, x_valid_2019, y_valid_2019)\n",
    "\n",
    "model_1_2020 = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model_1_2020.fit(x_train_2020, y_train_2020)\n",
    "m_2020 = print_score(model_1_2020, x_train_2020, y_train_2020, x_valid_2020, y_valid_2020)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3)\n",
    "\n",
    "m_2012.plot(ax=ax[0][0]), m_2013.plot(ax=ax[0][1]), m_2014.plot(ax=ax[0][2])\n",
    "m_2015.plot(ax=ax[1][0]), m_2016.plot(ax=ax[1][1]), m_2017.plot(ax=ax[1][2])\n",
    "m_2018.plot(ax=ax[2][0]), m_2019.plot(ax=ax[2][1]), m_2020.plot(ax=ax[2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# grid={\n",
    "#     'criterion':        ['entropy','gini'],\n",
    "#     'min_samples_split':[3, 5, 7, 9, 10],\n",
    "#     'min_samples_leaf': [8, 9, 10, 11, 12],\n",
    "#     'max_features':     [0.5, \"sqrt\", \"log2\", 0.8],\n",
    "#     'n_estimators':     [10, 20, 40],\n",
    "# }\n",
    "\n",
    "# model_2 = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
    "#                        param_distributions=grid,\n",
    "#                        n_iter=100,\n",
    "#                        cv=4,\n",
    "#                        verbose=1,\n",
    "#                        n_jobs=-1,\n",
    "#                        random_state=42)\n",
    "\n",
    "# model_2.fit(x_train_2012, y_train_2012)\n",
    "# m2_2012 = print_score(model_1_2012, x_train_2012, y_train_2012, x_valid_2012, y_valid_2012)\n",
    "# model_2.fit(x_train_2013, y_train_2013)\n",
    "# m2_2013 = print_score(model_1_2013, x_train_2013, y_train_2013, x_valid_2013, y_valid_2013)\n",
    "# model_2.fit(x_train_2014, y_train_2014)\n",
    "# m2_2014 = print_score(model_1_2014, x_train_2014, y_train_2014, x_valid_2014, y_valid_2014)\n",
    "# model_2.fit(x_train_2015, y_train_2015)\n",
    "# m2_2015 = print_score(model_1_2015, x_train_2015, y_train_2015, x_valid_2015, y_valid_2015)\n",
    "# model_2.fit(x_train_2016, y_train_2016)\n",
    "# m2_2016 = print_score(model_1_2016, x_train_2016, y_train_2016, x_valid_2016, y_valid_2016)\n",
    "# model_2.fit(x_train_2017, y_train_2017)\n",
    "# m2_2017 = print_score(model_1_2017, x_train_2017, y_train_2017, x_valid_2017, y_valid_2017)\n",
    "# model_2.fit(x_train_2018, y_train_2018)\n",
    "# m2_2018 = print_score(model_1_2018, x_train_2018, y_train_2018, x_valid_2018, y_valid_2018)\n",
    "# model_2.fit(x_train_2019, y_train_2019)\n",
    "# m2_2019 = print_score(model_1_2019, x_train_2019, y_train_2019, x_valid_2019, y_valid_2019)\n",
    "# model_2.fit(x_train_2020, y_train_2020)\n",
    "# m2_2020 = print_score(model_1_2020, x_train_2020, y_train_2020, x_valid_2020, y_valid_2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.best_estimator_\n",
    "bag_model = model_2.best_estimator_\n",
    "%time bag_model.fit(x_train_2012, y_train_2012)\n",
    "# print(bag_model)\n",
    "print_score(bag_model, x_train_2012, x_valid_2012)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "preds = np.stack([tree.predict(x_valid_2012) for tree in bag_model.estimators_])\n",
    "preds.shape\n",
    "\n",
    "\n",
    "# plt.plot([metrics.auc(y_valid_2012, np.mean(preds[:i+1], axis=0)) for i in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_2012_ohe = np.hstack([x_train_2012])\n",
    "a_valid = np.hstack([x_valid_2012])\n",
    "\n",
    "a_2012_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.best_estimator_\n",
    "s_model = model_2.best_estimator_\n",
    "%time s_model.fit(a_2012_ohe, y_train_2012)\n",
    "# print(bag_model)\n",
    "print_score(bag_model, a_2012_ohe, a_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "y_proba = model_2.predict_proba(x_valid_2012)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = x_valid_2012.values[None,0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastai\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(bag_model , x_train_2012)\n",
    "fi.plot('cols', 'imp', 'bar', figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fi[:15].cols\n",
    "cut_train_2012 = x_train_2012[f]\n",
    "cut_valid_2012 = x_valid_2012[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = model_2.best_estimator_\n",
    "%time model_3.fit(cut_train_2012, y_train_2012)\n",
    "print_score(model_3, cut_train_2012, cut_valid_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi2 = rf_feat_importance(model_3 , cut_train_2012)\n",
    "fi2.plot('cols', 'imp', 'bar', figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi2, fi[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, bias, contributions = ti.predict(m, row)\n",
    "prediction[0][0], bias[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.argsort(contributions[0][:,0])\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame( [o for o in zip(x_valid_2012.columns[idxs], x_valid_2012.iloc[0][idxs], contributions[0][:,0][idxs])] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "afd8bbf76cc8f66cb6213c8ab916f8a134e63b6f70cbd0f147b7ecd8cc749dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
